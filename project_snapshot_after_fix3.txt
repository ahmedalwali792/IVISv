### PROJECT SNAPSHOT (after P12)
ROOT: C:\Users\aialw\Downloads\IVISv_project\IVISv
FILES: 159

### FILE LIST
.gitignore
README.md
common\__init__.py
common\config\__init__.py
common\config\base.py
common\contracts\__init__.py
common\contracts\frame_contract.py
common\settings.py
dependencies\lock.txt
detection\__init__.py
detection\config.py
detection\errors\__init__.py
detection\errors\fatal.py
detection\frame\__init__.py
detection\frame\decoder.py
detection\ingest\__init__.py
detection\ingest\consumer.py
detection\main.py
detection\memory\__init__.py
detection\memory\reader.py
detection\metrics\__init__.py
detection\metrics\counters.py
detection\model\__init__.py
detection\model\base.py
detection\model\loader.py
detection\model\runner.py
detection\model\worker.py
detection\model\yolo11.py
detection\postprocess\__init__.py
detection\postprocess\parse.py
detection\preprocess\__init__.py
detection\preprocess\tensorize.py
detection\preprocess\validate.py
detection\publish\__init__.py
detection\publish\results.py
detection\runtime.py
detection\tracking\__init__.py
detection\tracking\reid_tracker.py
docs\architecture.md
docs\baseline_report.md
docs\contracts\frame_v1.md
docs\contracts\result_v1.md
docs\runbook.md
docs\status_after_p12.md
docs\v1_invariants.md
export_project_snapshot.py
fix_syntax_indentation.py
infrastructure\bus.py
infrastructure\bus_zmq.py
ingestion\__init__.py
ingestion\capture\__init__.py
ingestion\capture\decoder.py
ingestion\capture\frozen.py
ingestion\capture\reader.py
ingestion\capture\reconnect.py
ingestion\capture\rtsp_client.py
ingestion\config.py
ingestion\errors\__init__.py
ingestion\errors\fatal.py
ingestion\feedback\adaptive.py
ingestion\feedback\lag_controller.py
ingestion\frame\__init__.py
ingestion\frame\anchor.py
ingestion\frame\id.py
ingestion\frame\normalizer.py
ingestion\frame\roi.py
ingestion\frame\selector.py
ingestion\heartbeat.py
ingestion\ipc.py
ingestion\main.py
ingestion\memory\__init__.py
ingestion\memory\ref.py
ingestion\memory\shm_backend.py
ingestion\memory\writer.py
ingestion\metrics\__init__.py
ingestion\metrics\counters.py
ingestion\publish\__init__.py
ingestion\publish\heartbeat.py
ingestion\recording\buffer.py
ingestion\runtime.py
ivis\__init__.py
ivis\common\__init__.py
ivis\common\config\__init__.py
ivis\common\config\base.py
ivis\common\contracts\__init__.py
ivis\common\contracts\frame_contract.py
ivis\common\contracts\result_contract.py
ivis\common\contracts\validators.py
ivis\common\time_utils.py
ivis\legacy\detection_ingest_consumer_legacy.py
ivis\legacy\infrastructure_bus.py
ivis\legacy\infrastructure_bus_zmq.py
ivis\legacy\ingestion_ipc_legacy.py
ivis_health.py
ivis_logging.py
ivis_metrics.py
ivis_tracing.py
memory\__init__.py
memory\api\__init__.py
memory\api\health.py
memory\api\read.py
memory\api\write.py
memory\backend\__init__.py
memory\backend\base.py
memory\backend\ring.py
memory\buffer\__init__.py
memory\buffer\allocator.py
memory\buffer\index.py
memory\buffer\layout.py
memory\config.py
memory\errors\__init__.py
memory\errors\fatal.py
memory\metrics\__init__.py
memory\metrics\counters.py
memory\runtime.py
memory\server.py
memory\shm_ring.py
pyproject.toml
requirements.txt
run_system.original.py
run_system.py
scripts\create_sample_video.py
scripts\regression_smoke.py
scripts\shm_cleanup.py
src\ivis\__init__.py
src\ivis\common\__init__.py
src\ivis\detection\__init__.py
src\ivis\devtools.py
src\ivis\infrastructure\__init__.py
src\ivis\ingestion\__init__.py
src\ivis\legacy\detection_ingest_consumer_legacy.py
src\ivis\legacy\infrastructure_bus.py
src\ivis\legacy\infrastructure_bus_zmq.py
src\ivis\legacy\ingestion_ipc_legacy.py
src\ivis\memory\__init__.py
src\ivis\run_system.py
src\ivis\ui\__init__.py
src\ivisv.egg-info\SOURCES.txt
src\ivisv.egg-info\dependency_links.txt
src\ivisv.egg-info\entry_points.txt
src\ivisv.egg-info\requires.txt
src\ivisv.egg-info\top_level.txt
tests\contracts\test_ingestion_contract_version.py
tests\contracts\test_validators.py
tests\detection\test_track_id_mapping.py
tests\detection\test_zmq_consumer.py
tests\stress_shm.py
tests\test_color_standard.py
tests\test_detection_frame_decoder.py
tests\test_e2e_pipeline.py
tests\test_latency_ms.py
tests\test_monotonic_ms.py
tests\test_namespace_imports.py
tests\test_no_silent_excepts.py
tests\test_shm_ring_payload.py
tests\ui\test_results_cache.py
ui\__init__.py
ui\live_view.py
ui\results_cache.py

### FILE CONTENTS

========================================================================================================================
FILE: .gitignore
========================================================================================================================
__pycache__/
*.pyc
logs/
*.log

# Build / packaging
dist/
build/
*.egg-info/

# Test / cache
.pytest_cache/
.mypy_cache/
.ruff_cache/

# Byte-compiled / other
*.py[cod]
*$py.class

========================================================================================================================
FILE: README.md
========================================================================================================================
# IVISv - Local Developer Notes (عربي)

هدف هذا الدليل: خطوات سريعة لتجهيز المشروع وتشغيله محليًا.

المتطلبات الأساسية
- Python 3.8+ (موصى به 3.10+)
- مساحة تخزين للنموذج (يوجد ملف `yolo11n.pt` في جذر المشروع)

إعداد بيئة افتراضية وتثبيت الاعتمادات (Windows `cmd.exe`):
```bat
python -m venv .venv
.venv\Scripts\activate
python -m pip install --upgrade pip
pip install -r requirements.txt
pip install -e .
```

النماذج
- السكربت `run_system.py` يتوقع `models/yolo.pt` كمسار افتراضي.
- إذا لم يكن ذلك موجودًا، فسينظر تلقائيًا إلى الملف `yolo11n.pt` الموجود في جذر المشروع ويستخدمه كبديل.

تشغيل النظام محليًا (مكون من عدة خدمات):
```bat
python run_system.py
```

تشغيل الخدمات بشكل منفصل بعد التثبيت:
```bat
python -m ingestion.main
python -m detection.main
python -m ui.live_view
```

السجلات
- جميع مخارج الخدمات تُكتب إلى مجلد `logs/` (موجود أو يُنشأ تلقائيًا).
- لا تقم بعمل commit لملفات المخرجات المترجمة مثل `__pycache__/` و`*.pyc` وملفات السجل.

ملاحظات مهمة لتطوير الأداء والاحترافية
- أنشئ بيئة اختبار/CI لتشغيل flake8 وmypy وunit tests.
- النظر في استبدال `infrastructure/bus.py` بوسيلة IPC أكثر متانة (ZeroMQ أو gRPC) للبيئات الإنتاجية.
- على Windows، `signal.SIGALRM` غير متوفّر — الكود يتجاوز مهلات الإرسال تلقائيًا على الأنظمة غير الداعمة.

خطوات مقترحة تالية (يمكنني تنفيذها لك):
- إنشاء ملف `requirements-dev.txt` مع `flake8`, `mypy`, `pytest`.
- إضافة اختبار بسيط يغطي تدفق `memory` PUT/GET.
- تحسين إدارة التكوين (استبدال `sys.path.append` باستعمال حزم مُهيكلة أو استخدام pip install -e .).

========================================================================================================================
FILE: common\__init__.py
========================================================================================================================
# Shared common utilities and contracts.

========================================================================================================================
FILE: common\config\__init__.py
========================================================================================================================
# Shared configuration helpers.

========================================================================================================================
FILE: common\config\base.py
========================================================================================================================
# FILE: common/config/base.py
# ------------------------------------------------------------------------------
import os
import warnings
from typing import Any, Dict, Optional


class ConfigLoadError(Exception):
    pass


def _parse_bool(raw: str) -> bool:
    if raw.lower() in ("true", "1", "yes", "y"):
        return True
    if raw.lower() in ("false", "0", "no", "n"):
        return False
    raise ValueError(f"Invalid boolean value: {raw}")


_TYPE_PARSERS = {
    "str": str,
    "int": int,
    "float": float,
    "bool": _parse_bool,
}


class EnvLoader:
    def __init__(self, env: Optional[Dict[str, str]] = None):
        # Prefer an explicit env mapping; otherwise merge real env with centralized SETTINGS
        if env is not None:
            self.env = env
        else:
            # Start from the real process environment. Centralized SETTINGS
            # provide defaults only; explicit environment variables must take
            # precedence. Therefore we merge SETTINGS.as_env() into the
            # environment but do not overwrite existing keys.
            merged = dict(os.environ)
            try:
                from common.settings import SETTINGS

                defaults = SETTINGS.as_env()
                for k, v in defaults.items():
                    if k not in merged:
                        merged[k] = v
            except Exception as exc:
                warnings.warn(f"Failed to load SETTINGS defaults: {exc}", RuntimeWarning)
            self.env = merged

    def load(self, schema: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        values: Dict[str, Any] = {}
        for key, spec in schema.items():
            raw = self.env.get(key)
            typ = spec.get("type", "str")
            default = spec.get("default")
            required = bool(spec.get("required", False))
            parser = _TYPE_PARSERS.get(typ)
            if parser is None:
                raise ConfigLoadError(f"Unsupported type '{typ}' for {key}")
            if raw is None:
                if required and default is None:
                    raise ConfigLoadError(f"Missing required env var: {key}")
                values[key] = parser(str(default)) if default is not None else None
                continue
            try:
                values[key] = parser(raw)
            except Exception as exc:
                raise ConfigLoadError(f"Invalid {typ} env var {key}: {raw}") from exc
        return values


_REDACT_KEYS = {"POSTGRES_DSN"}
_REDACT_HINTS = ("PASSWORD", "SECRET", "TOKEN", "DSN")


def _should_redact(key: str) -> bool:
    if key in _REDACT_KEYS:
        return True
    upper = key.upper()
    return any(hint in upper for hint in _REDACT_HINTS)


def redact_config(values: Dict[str, Any]) -> Dict[str, Any]:
    sanitized: Dict[str, Any] = {}
    for key, value in values.items():
        if _should_redact(key) and value is not None:
            sanitized[key] = "****"
        else:
            sanitized[key] = value
    return sanitized

========================================================================================================================
FILE: common\contracts\__init__.py
========================================================================================================================
# Contract models shared across services.

========================================================================================================================
FILE: common\contracts\frame_contract.py
========================================================================================================================
# FILE: common/contracts/frame_contract.py
# ------------------------------------------------------------------------------
from dataclasses import dataclass
from typing import Any, Dict


@dataclass(frozen=True)
class FrameMemoryRef:
    backend: str
    key: str
    size: int
    generation: int

    @classmethod
    def from_dict(cls, payload: Dict[str, Any]) -> "FrameMemoryRef":
        if not isinstance(payload, dict):
            raise ValueError("memory must be a dict")
        backend = payload.get("backend")
        key = payload.get("key")
        size = payload.get("size")
        generation = payload.get("generation")
        if not isinstance(backend, str) or not backend:
            raise ValueError("memory.backend must be a non-empty string")
        if not isinstance(key, str) or not key:
            raise ValueError("memory.key must be a non-empty string")
        if not isinstance(size, int) or size < 0:
            raise ValueError("memory.size must be a non-negative int")
        if not isinstance(generation, int):
            raise ValueError("memory.generation must be an int")
        return cls(
            backend=backend,
            key=key,
            size=size,
            generation=generation,
        )


@dataclass(frozen=True)
class FrameContractV1:
    contract_version: int
    frame_id: str
    stream_id: str
    camera_id: str
    pts: float
    timestamp_ms: int
    mono_ms: int
    memory: FrameMemoryRef
    frame_width: int
    frame_height: int
    frame_channels: int
    frame_dtype: str
    frame_color_space: str

    @classmethod
    def from_dict(cls, payload: Dict[str, Any]) -> "FrameContractV1":
        if not isinstance(payload, dict):
            raise ValueError("contract must be a dict")
        contract_version = payload.get("contract_version")
        if isinstance(contract_version, bool):
            contract_version = None
        if isinstance(contract_version, str):
            normalized = contract_version.strip()
            if normalized.lower() == "v1":
                normalized = "1"
            if normalized.isdigit():
                contract_version = int(normalized)
        if contract_version != 1:
            raise ValueError("contract_version must be int 1")
        frame_id = payload.get("frame_id")
        stream_id = payload.get("stream_id")
        camera_id = payload.get("camera_id")
        if not isinstance(frame_id, str) or not frame_id:
            raise ValueError("frame_id must be a non-empty string")
        if not isinstance(stream_id, str) or not stream_id:
            raise ValueError("stream_id must be a non-empty string")
        if not isinstance(camera_id, str) or not camera_id:
            raise ValueError("camera_id must be a non-empty string")
        pts = payload.get("pts")
        if not isinstance(pts, (int, float)):
            raise ValueError("pts must be a number")
        timestamp_ms = payload.get("timestamp_ms")
        mono_ms = payload.get("mono_ms")
        if not isinstance(timestamp_ms, int):
            raise ValueError("timestamp_ms must be an int (ms)")
        if not isinstance(mono_ms, int):
            raise ValueError("mono_ms must be an int (ms)")
        memory = FrameMemoryRef.from_dict(payload.get("memory"))
        frame_width = payload.get("frame_width")
        frame_height = payload.get("frame_height")
        frame_channels = payload.get("frame_channels")
        frame_dtype = payload.get("frame_dtype")
        frame_color_space = payload.get("frame_color_space")
        if not isinstance(frame_width, int) or frame_width <= 0:
            raise ValueError("frame_width must be a positive int")
        if not isinstance(frame_height, int) or frame_height <= 0:
            raise ValueError("frame_height must be a positive int")
        if not isinstance(frame_channels, int) or frame_channels <= 0:
            raise ValueError("frame_channels must be a positive int")
        if not isinstance(frame_dtype, str) or not frame_dtype:
            raise ValueError("frame_dtype must be a non-empty string")
        if not isinstance(frame_color_space, str) or not frame_color_space:
            raise ValueError("frame_color_space must be a non-empty string")
        return cls(
            contract_version=contract_version,
            frame_id=frame_id,
            stream_id=stream_id,
            camera_id=camera_id,
            pts=float(pts),
            timestamp_ms=timestamp_ms,
            mono_ms=mono_ms,
            memory=memory,
            frame_width=frame_width,
            frame_height=frame_height,
            frame_channels=frame_channels,
            frame_dtype=frame_dtype,
            frame_color_space=frame_color_space,
        )

    def to_dict(self) -> Dict[str, Any]:
        return {
            "contract_version": self.contract_version,
            "frame_id": self.frame_id,
            "stream_id": self.stream_id,
            "camera_id": self.camera_id,
            "pts": self.pts,
            "timestamp_ms": self.timestamp_ms,
            "mono_ms": self.mono_ms,
            "memory": {
                "backend": self.memory.backend,
                "key": self.memory.key,
                "size": self.memory.size,
                "generation": self.memory.generation,
            },
            "frame_width": self.frame_width,
            "frame_height": self.frame_height,
            "frame_channels": self.frame_channels,
            "frame_dtype": self.frame_dtype,
            "frame_color_space": self.frame_color_space,
        }

========================================================================================================================
FILE: common\settings.py
========================================================================================================================
"""Centralized application settings using Pydantic (with graceful fallback).

This module exposes a single `SETTINGS` object with nested sections. It
prefers `pydantic-settings` when available, but will fall back to a small
compat shim that reads environment variables. It also implements the
FRAME_COLOR -> SOURCE_COLOR migration with a warning.
"""
from __future__ import annotations

import os
import warnings
from typing import Optional, Literal

try:
    from pydantic_settings import BaseSettings
    from pydantic import Field
except Exception:
    # Minimal fallback using pydantic BaseModel if pydantic-settings isn't installed.
    try:
        from pydantic import BaseModel as BaseSettings, Field
    except Exception:  # pragma: no cover - extremely unlikely in project env
        class BaseSettings(object):
            pass


class SystemSettings(BaseSettings):
    app_name: str = Field("ivis")
    env_file: Optional[str] = Field(".env")
    # FRAME_COLOR_SPACE is a fixed contract for v1 and must be 'bgr'
    frame_color_space: Literal["bgr"] = Field("bgr")


class IngestionSettings(BaseSettings):
    # SOURCE_COLOR: color of the source camera/input. Ingestion will convert
    # from SOURCE_COLOR -> FRAME_COLOR_SPACE before publishing frames.
    source_color: Literal["bgr", "rgb"] = Field("bgr")
    frame_width: int = Field(640)
    frame_height: int = Field(480)
    shm_name: str = Field("ivis_shm_data")
    shm_meta_name: str = Field("ivis_shm_meta")
    shm_buffer_bytes: int = Field(50000000)
    shm_cache_seconds: float = Field(30.0)
    target_fps: int = Field(15)
    video_loop: bool = Field(False)


class DetectionSettings(BaseSettings):
    frame_width: int = Field(640)
    frame_height: int = Field(480)
    # Downstream services should assume FRAME_COLOR_SPACE (bgr) and not
    # perform further conversions.


class UISettings(BaseSettings):
    frame_width: int = Field(640)
    frame_height: int = Field(480)


class PostgresSettings(BaseSettings):
    dsn: Optional[str] = Field(None)


class LoggingSettings(BaseSettings):
    level: str = Field("INFO")
    log_dir: Optional[str] = Field(None)


class MetricsSettings(BaseSettings):
    enabled: bool = Field(True)


class TracingSettings(BaseSettings):
    enabled: bool = Field(False)


class Settings(BaseSettings):
    system: SystemSettings = SystemSettings()
    ingestion: IngestionSettings = IngestionSettings()
    detection: DetectionSettings = DetectionSettings()
    ui: UISettings = UISettings()
    postgres: PostgresSettings = PostgresSettings()
    logging: LoggingSettings = LoggingSettings()
    metrics: MetricsSettings = MetricsSettings()
    tracing: TracingSettings = TracingSettings()

    # Legacy detection: if FRAME_COLOR is present in the environment, treat it
    # as the source color (for ingestion) but keep FRAME_COLOR_SPACE == bgr.
    def apply_legacy_migration(self):
        legacy = os.getenv("FRAME_COLOR")
        if legacy:
            leg = legacy.lower()
            if leg in ("rgb", "bgr"):
                warnings.warn(
                    "Environment variable FRAME_COLOR is deprecated; mapped to SOURCE_COLOR for ingestion. "
                    "Downstream FRAME_COLOR_SPACE remains 'bgr' (v1 contract).",
                    DeprecationWarning,
                )
                # Map legacy FRAME_COLOR to ingestion.source_color
                self.ingestion.source_color = leg  # type: ignore

    def as_env(self) -> dict:
        """Return a simple env mapping for backward-compatible EnvLoader use.

        Values are strings as environment variables would be.
        """
        env = {}
        env["FRAME_COLOR_SPACE"] = self.system.frame_color_space
        env["SOURCE_COLOR"] = self.ingestion.source_color
        env["FRAME_WIDTH"] = str(self.ingestion.frame_width)
        env["FRAME_HEIGHT"] = str(self.ingestion.frame_height)
        env["SHM_NAME"] = self.ingestion.shm_name
        env["SHM_META_NAME"] = self.ingestion.shm_meta_name
        env["SHM_BUFFER_BYTES"] = str(self.ingestion.shm_buffer_bytes)
        env["SHM_CACHE_SECONDS"] = str(self.ingestion.shm_cache_seconds)
        env["TARGET_FPS"] = str(self.ingestion.target_fps)
        env["VIDEO_LOOP"] = "1" if self.ingestion.video_loop else "0"
        return env


# instantiate global settings and apply migration
SETTINGS = Settings()
try:
    SETTINGS.apply_legacy_migration()
except Exception as exc:
    warnings.warn(f"Failed to apply legacy settings migration: {exc}", RuntimeWarning)

========================================================================================================================
FILE: dependencies\lock.txt
========================================================================================================================
# Dependencies lock (minimal) — reflect YAML decision
# PyYAML pinned so orchestrator can load YAML config files
PyYAML==6.0.3

# Other runtime deps remain managed via requirements.txt (unpinned in this project)

========================================================================================================================
FILE: detection\__init__.py
========================================================================================================================


========================================================================================================================
FILE: detection\config.py
========================================================================================================================
# FILE: detection/config.py
# ------------------------------------------------------------------------------
from ivis.common.config.base import ConfigLoadError, EnvLoader, redact_config
from detection.errors.fatal import FatalError


_SCHEMA = {
    "MODEL_NAME": {"type": "str", "required": True},
    "MODEL_VERSION": {"type": "str", "required": True},
    "MODEL_HASH": {"type": "str", "required": True},
    "MODEL_PATH": {"type": "str", "required": True},
    "INFERENCE_TIMEOUT": {"type": "int", "default": 5},
    "MODEL_DEVICE": {"type": "str", "default": "auto"},
    "MODEL_HALF": {"type": "bool", "default": False},
    "MODEL_IMG_SIZE": {"type": "int", "default": 640},
    "MODEL_CONF": {"type": "float", "default": 0.25},
    "MODEL_IOU": {"type": "float", "default": 0.5},
    "TRACKER_MAX_AGE": {"type": "int", "default": 8},
    "TRACKER_INIT_FRAMES": {"type": "int", "default": 3},
    "TRACKER_NN_BUDGET": {"type": "int", "default": 100},
    "TRACKER_MAX_IOU": {"type": "float", "default": 0.7},
    "REID_MODEL_NAME": {"type": "str", "default": "osnet_x0_25"},
    "REID_MODEL_PATH": {"type": "str", "default": None},
    "REID_ALLOW_FALLBACK": {"type": "bool", "default": True},
    "BUS_TRANSPORT": {"type": "str", "default": "zmq"},
    "ZMQ_PUB_ENDPOINT": {"type": "str", "default": "tcp://localhost:5555"},
    "ZMQ_SUB_ENDPOINT": {"type": "str", "default": "tcp://localhost:5555"},
    "ZMQ_RESULTS_PUB_ENDPOINT": {"type": "str", "default": "tcp://localhost:5557"},
    "ZMQ_CONFLATE": {"type": "bool", "default": False},
    "ZMQ_RCVHWM": {"type": "int", "default": 1000},
    "ZMQ_LINGER_MS": {"type": "int", "default": 0},
    "DECODER_ALLOW_CONFIG_FALLBACK": {"type": "bool", "default": False},
    "READY_MAX_IDLE_SEC": {"type": "int", "default": 30},
    "READY_MAX_NO_CONTRACT_SEC": {"type": "int", "default": 10},
    "POSTGRES_DSN": {"type": "str", "default": None},
    "FRAME_WIDTH": {"type": "int", "default": 640},
    "FRAME_HEIGHT": {"type": "int", "default": 480},
    "FRAME_COLOR": {"type": "str", "default": "bgr"},
    "MEMORY_BACKEND": {"type": "str", "default": "shm"},
    "SHM_NAME": {"type": "str", "default": "ivis_shm_data"},
    "SHM_META_NAME": {"type": "str", "default": "ivis_shm_meta"},
    "SHM_BUFFER_BYTES": {"type": "int", "default": 50000000},
    "SHM_CACHE_SECONDS": {"type": "float", "default": 0},
    "SHM_CACHE_FPS": {"type": "float", "default": 0},
    "MAX_FRAME_AGE_MS": {"type": "int", "default": 1000},
    "DEBUG": {"type": "bool", "default": False},
}


def _load_config() -> dict:
    loader = EnvLoader()
    try:
        values = loader.load(_SCHEMA)
    except ConfigLoadError as exc:
        raise FatalError("Invalid config", context={"error": str(exc)}) from exc
    if values["INFERENCE_TIMEOUT"] <= 0:
        raise FatalError("INFERENCE_TIMEOUT must be > 0")
    return values


class Config:
    _VALUES = _load_config()

    MODEL_NAME = _VALUES["MODEL_NAME"]
    MODEL_VERSION = _VALUES["MODEL_VERSION"]
    MODEL_HASH = _VALUES["MODEL_HASH"]
    MODEL_PATH = _VALUES["MODEL_PATH"]

    INFERENCE_TIMEOUT_SECONDS = _VALUES["INFERENCE_TIMEOUT"]

    # Device/runtime tuning
    MODEL_DEVICE = _VALUES["MODEL_DEVICE"]
    MODEL_HALF = _VALUES["MODEL_HALF"]
    MODEL_IMG_SIZE = _VALUES["MODEL_IMG_SIZE"]
    MODEL_CONF = _VALUES["MODEL_CONF"]
    MODEL_IOU = _VALUES["MODEL_IOU"]

    # Tracking / ReID
    TRACKER_MAX_AGE = _VALUES["TRACKER_MAX_AGE"]
    TRACKER_INIT_FRAMES = _VALUES["TRACKER_INIT_FRAMES"]
    TRACKER_NN_BUDGET = _VALUES["TRACKER_NN_BUDGET"]
    TRACKER_MAX_IOU = _VALUES["TRACKER_MAX_IOU"]
    REID_MODEL_NAME = _VALUES["REID_MODEL_NAME"]
    REID_MODEL_PATH = _VALUES["REID_MODEL_PATH"]
    REID_ALLOW_FALLBACK = _VALUES["REID_ALLOW_FALLBACK"]

    # Bus transport: zmq | tcp
    BUS_TRANSPORT = _VALUES["BUS_TRANSPORT"]
    ZMQ_PUB_ENDPOINT = _VALUES["ZMQ_PUB_ENDPOINT"]
    ZMQ_SUB_ENDPOINT = _VALUES["ZMQ_SUB_ENDPOINT"]
    ZMQ_RESULTS_PUB_ENDPOINT = _VALUES["ZMQ_RESULTS_PUB_ENDPOINT"]
    ZMQ_CONFLATE = _VALUES["ZMQ_CONFLATE"]
    ZMQ_RCVHWM = _VALUES["ZMQ_RCVHWM"]
    ZMQ_LINGER_MS = _VALUES["ZMQ_LINGER_MS"]

    # Persistence
    POSTGRES_DSN = _VALUES["POSTGRES_DSN"]

    # Blind Consumer Config (Decoupled from Orchestrator)
    FRAME_WIDTH = _VALUES["FRAME_WIDTH"]
    FRAME_HEIGHT = _VALUES["FRAME_HEIGHT"]
    FRAME_COLOR = _VALUES["FRAME_COLOR"].lower()

    MEMORY_BACKEND = _VALUES["MEMORY_BACKEND"]
    SHM_NAME = _VALUES["SHM_NAME"]
    SHM_META_NAME = _VALUES["SHM_META_NAME"]
    SHM_BUFFER_BYTES = _VALUES["SHM_BUFFER_BYTES"]
    SHM_CACHE_SECONDS = _VALUES["SHM_CACHE_SECONDS"]
    SHM_CACHE_FPS = _VALUES["SHM_CACHE_FPS"]
    MAX_FRAME_AGE_MS = _VALUES["MAX_FRAME_AGE_MS"]

    DEBUG = _VALUES["DEBUG"]

    @classmethod
    def summary(cls) -> dict:
        return redact_config(cls._VALUES)

========================================================================================================================
FILE: detection\errors\__init__.py
========================================================================================================================


========================================================================================================================
FILE: detection\errors\fatal.py
========================================================================================================================
# FILE: detection/errors/fatal.py
# ------------------------------------------------------------------------------
class FatalError(Exception):
    def __init__(self, message, context=None):
        self.message = message
        self.context = context or {}
        super().__init__(self.message)

class NonFatalError(Exception):
    pass

========================================================================================================================
FILE: detection\frame\__init__.py
========================================================================================================================


========================================================================================================================
FILE: detection\frame\decoder.py
========================================================================================================================
# FILE: detection/frame/decoder.py
# ------------------------------------------------------------------------------
import logging
from typing import Any, Dict, Optional, Tuple

import numpy as np

from detection.config import Config
from detection.errors.fatal import NonFatalError

class FrameDecoder:
    """
    Blind Consumer Knowledge Base.
    Uses LOCAL constants (Config) to understand bytes.
    """
    def __init__(self):
        self._logger = logging.getLogger("detection")

    def _resolve_metadata(self, contract: Dict[str, Any]) -> Tuple[int, int, int, str, bool]:
        width = contract.get("frame_width")
        height = contract.get("frame_height")
        channels = contract.get("frame_channels")
        dtype = contract.get("frame_dtype")
        if all(v is not None for v in (width, height, channels, dtype)):
            return int(width), int(height), int(channels), str(dtype), False

        if not Config.DECODER_ALLOW_CONFIG_FALLBACK:
            raise NonFatalError("Missing frame metadata in contract (Strict Mode). Enable DECODER_ALLOW_CONFIG_FALLBACK to bypass.")

        # Rate-limiter for warnings could be added here if desired, using a static set or similar.
        self._logger.warning("Contract missing frame metadata. Falling back to Config (DECODER_ALLOW_CONFIG_FALLBACK=True).")
        return Config.FRAME_WIDTH, Config.FRAME_HEIGHT, 3, "uint8", True

    def _dtype_bytes(self, dtype: str) -> int:
        dtype_norm = dtype.lower()
        if dtype_norm == "uint8":
            return 1
        if dtype_norm == "uint16":
            return 2
        if dtype_norm == "float32":
            return 4
        raise NonFatalError(f"Unsupported frame dtype: {dtype}")

    def decode(self, data_bytes: bytes, contract: Optional[Dict[str, Any]] = None) -> np.ndarray:
        if contract is None:
            contract = {}

        width, height, channels, dtype, _ = self._resolve_metadata(contract)

        if int(channels) != 3:
            raise NonFatalError(f"Unsupported channels={channels}. Expected 3 (BGR).")

        bytes_per_pixel = self._dtype_bytes(dtype)
        expected_size = int(width) * int(height) * 3 * bytes_per_pixel

        mem = contract.get("memory") if isinstance(contract, dict) else None
        if isinstance(mem, dict) and mem.get("size") is not None:
            mem_size = mem.get("size")
            if isinstance(mem_size, str) and mem_size.isdigit():
                mem_size = int(mem_size)
            if isinstance(mem_size, int) and mem_size != expected_size:
                raise NonFatalError(
                    f"Frame size mismatch. Expected {expected_size}, got {mem_size}. "
                    f"Check contract vs shared memory."
                )

        if len(data_bytes) != expected_size:
            raise NonFatalError(
                f"Frame size mismatch. Expected {expected_size}, got {len(data_bytes)}. "
                f"Check Config or contract vs shared memory."
            )

        try:
            arr = np.frombuffer(data_bytes, dtype=dtype)
            return arr.reshape((int(height), int(width), 3))
        except Exception as e:
            raise NonFatalError(f"Failed to decode frame bytes: {e}")

========================================================================================================================
FILE: detection\ingest\__init__.py
========================================================================================================================


========================================================================================================================
FILE: detection\ingest\consumer.py
========================================================================================================================
# FILE: detection/ingest/consumer.py
# ------------------------------------------------------------------------------
import json
import socket
import logging
import os

from detection.config import Config
from detection.errors.fatal import FatalError
import ivis_metrics


_logger = logging.getLogger("detection")
_warned = set()


def _log_once(key: str, message: str, exc: Exception = None) -> None:
    if key in _warned:
        return
    _warned.add(key)
    if exc is not None:
        _logger.warning("%s: %s", message, exc)
    else:
        _logger.warning("%s", message)


def _record_issue(reason: str, message: str, exc: Exception = None) -> None:
    _log_once(reason, message, exc)
    try:
        ivis_metrics.service_errors_total.labels(service="detection", reason=reason).inc()
    except Exception as metric_exc:
        _log_once(f"{reason}_metric", "Failed to record service error metric", metric_exc)


class TcpFrameConsumer:
    def __init__(self, host="localhost", port=5555):
        self.address = (host, port)
        self.sock = None
        self.buffer = ""

    def connect(self):
        if not self.sock:
            try:
                self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                self.sock.settimeout(5.0)
                self.sock.connect(self.address)
                self.sock.settimeout(None)
                print(f"[DETECTION] Connected to Bus at {self.address}")
            except Exception as e:
                raise FatalError(f"Failed to connect to Bus at {self.address}", context={"error": str(e)})

    def close(self):
        if self.sock:
            try:
                self.sock.close()
            except Exception as exc:
                print(f"[DETECTION] Error closing TCP socket: {exc}")
            self.sock = None

    def __iter__(self):
        # Implicit connect removed; must call connect() explicitly from main.

        while True:
            try:
                data = self.sock.recv(4096)
                if not data:
                    raise FatalError("Bus connection lost (EOF)")

                self.buffer += data.decode("utf-8")

                while "\n" in self.buffer:
                    line, self.buffer = self.buffer.split("\n", 1)
                    if line.strip():
                        try:
                            contract = json.loads(line)
                            yield contract
                        except json.JSONDecodeError:
                            print("[Warn] Received malformed JSON from Bus")
                            continue
            except FatalError:
                raise
            except Exception as e:
                raise FatalError("Bus Consumer Error", context={"error": str(e)})


class ZmqFrameConsumer:
    def __init__(self, endpoint: str):
        try:
            import zmq
        except Exception as exc:
            raise FatalError("Missing ZeroMQ dependency", context={"error": str(exc)}) from exc
        self.zmq = zmq
        self.endpoint = endpoint
        self.socket = None

    def connect(self):
        if self.socket:
            return  # Idempotent: already connected

        ctx = self.zmq.Context.instance()
        self.socket = ctx.socket(self.zmq.SUB)
        self.socket.setsockopt(self.zmq.SUBSCRIBE, b"")
        rcvhwm_env = os.getenv("ZMQ_RCVHWM")
        if rcvhwm_env is not None:
            try:
                rcvhwm = int(rcvhwm_env)
            except ValueError as exc:
                _log_once("zmq_rcvhwm_invalid", "Invalid ZMQ_RCVHWM value (expected int)", exc)
            else:
                self.socket.setsockopt(self.zmq.RCVHWM, rcvhwm)
        if Config.ZMQ_LINGER_MS:
            self.socket.setsockopt(self.zmq.LINGER, Config.ZMQ_LINGER_MS)
        
        conflate_env = os.getenv("ZMQ_CONFLATE")
        if conflate_env is not None:
            conflate_value = conflate_env.strip().lower()
            if conflate_value in ("1", "true", "yes", "on"):
                try:
                    self.socket.setsockopt(self.zmq.CONFLATE, 1)
                    print("[DETECTION] ZMQ CONFLATE enabled (processing latest frames only)")
                except Exception:
                    print("[DETECTION] ZMQ CONFLATE not supported (ignoring)")
            elif conflate_value not in ("0", "false", "no", "off", ""):
                _log_once("zmq_conflate_invalid", "Invalid ZMQ_CONFLATE value (expected boolean)")
        
        self.socket.connect(self.endpoint)
        print(f"[DETECTION] ZMQ SUB connected to {self.endpoint}")

    def reconnect(self, force=False):
        if force:
            self.close()
        self.connect()


    def close(self):
        if self.socket:
            try:
                self.socket.setsockopt(self.zmq.LINGER, 0)
                self.socket.close()
            except Exception as exc:
                print(f"[DETECTION] Error closing ZMQ socket: {exc}")
            self.socket = None
        # Note: We won't close ctx here as it might be shared or simply left for process exit

    def __iter__(self):
        if not self.socket:
            # We strictly require explicit connect() now, but to avoid instant crash if forgotten,
            # we raise a clear error or log warning. Given constraints, we'll raise fatal.
            raise FatalError("ZMQ Consumer not connected. Call connect() before iterating.")

        while True:
            try:
                payload = self.socket.recv()
                contract = json.loads(payload.decode("utf-8"))
                yield contract
            except Exception as e:
                raise FatalError("ZMQ Consumer Error", context={"error": str(e)})


class FrameConsumer:
    """
    Stage 2 Fix: No internal retry loops on startup. Fail Fast.
    """

    def __init__(self, host="localhost", port=5555):
        transport = Config.BUS_TRANSPORT.lower()
        if transport == "zmq":
            self._impl = ZmqFrameConsumer(Config.ZMQ_SUB_ENDPOINT)
        elif transport == "tcp":
            self._impl = TcpFrameConsumer(host=host, port=port)
        else:
            raise FatalError(f"Unsupported BUS_TRANSPORT: {Config.BUS_TRANSPORT}")

    def connect(self):
        if hasattr(self._impl, "connect"):
            self._impl.connect()

    def close(self):
        if hasattr(self._impl, "close"):
            self._impl.close()

    def __iter__(self):
        return iter(self._impl)

========================================================================================================================
FILE: detection\main.py
========================================================================================================================
#!/usr/bin/env python
import sys
import os
import time

from ivis_logging import setup_logging
logger = setup_logging("detection")

import ivis_metrics
import ivis_tracing
from ivis.common.time_utils import latency_ms, wall_clock_ms
from ivis_health import ServiceState, HealthServer

from detection.config import Config
from detection.errors.fatal import FatalError, NonFatalError
from detection.frame.decoder import FrameDecoder
from detection.ingest.consumer import FrameConsumer
from detection.memory.reader import MemoryReader
from detection.model.loader import load_model
from detection.model.runner import ModelRunner
from detection.postprocess.parse import parse_output
from detection.publish.results import ResultPublisher
from detection.runtime import Runtime
from detection.metrics.counters import metrics
from ivis.common.contracts.validators import validate_frame_contract_v1, ContractValidationError


_warned = set()


def _log_once(key: str, message: str, exc: Exception = None) -> None:
    if key in _warned:
        return
    _warned.add(key)
    if exc is not None:
        logger.warning("%s: %s", message, exc)
    else:
        logger.warning("%s", message)


def _record_issue(reason: str, message: str, exc: Exception = None) -> None:
    _log_once(reason, message, exc)
    try:
        ivis_metrics.service_errors_total.labels(service="detection", reason=reason).inc()
    except Exception as metric_exc:
        _log_once(f"{reason}_metric", "Failed to record service error metric", metric_exc)


def _safe_metric(reason: str, fn) -> None:
    try:
        fn()
    except Exception as exc:
        _record_issue(reason, "Metrics update failed", exc)


def main():
    logger.info(">>> Detection Service: Stage 3 (Blind Consumer) <<<")
    runtime = Runtime()
    logger.info("Config summary: %s", Config.summary())

    health_host = os.getenv("HEALTH_BIND", "127.0.0.1")
    health_port = int(os.getenv("DETECTION_HEALTH_PORT", "9002"))
    state = ServiceState("detection")
    HealthServer(state, host=health_host, port=health_port).start_in_thread()
    state.set_check("config_loaded", True, details={"model": Config.MODEL_NAME, "bus_transport": Config.BUS_TRANSPORT})

    # initialize tracing (best-effort)
    try:
        ivis_tracing.init_tracer(service_name=os.getenv("OTEL_SERVICE_NAME", "detection"))
    except Exception as exc:
        _record_issue("tracing_init_failed", "Tracing init failed", exc)

    # Start Prometheus metrics server (best-effort)
    try:
        port = int(os.getenv("DETECTION_METRICS_PORT", "8002"))
        ivis_metrics.start_metrics_http_server(port)
        logger.info("Prometheus metrics HTTP server started on port %s", port)
    except Exception as exc:
        _record_issue("metrics_server_failed", "Failed to start metrics server", exc)

    try:
        model = load_model()
        runner = ModelRunner(model)
        runner.warmup()
        state.set_check(
            "model_loaded",
            True,
            details={"name": Config.MODEL_NAME, "path": Config.MODEL_PATH, "device": Config.MODEL_DEVICE, "img_size": Config.MODEL_IMG_SIZE},
        )

        consumer = FrameConsumer()
        consumer.connect()
        state.set_check("bus_connected", True, details={"transport": Config.BUS_TRANSPORT, "endpoint": Config.ZMQ_SUB_ENDPOINT})
        reader = MemoryReader()
        ok, details, err = reader.ensure_ring()
        state.set_check("shm_ready", ok, details=details, reason=err)
        state.compute_ready(["model_loaded", "bus_connected", "shm_ready"])
        decoder = FrameDecoder()
        publisher = ResultPublisher()

        if hasattr(consumer, 'close'):
            logger.info("Consumer has close() method")
        if hasattr(publisher, 'close'):
            logger.info("Publisher has close() method")

        logger.info(">>> Detection Loop Running <<<")

        try:
            for frame_contract in consumer:
                if not runtime.running:
                    break

                state.touch_loop()
                # We stop manually computing ready state here, relying on ivis_health derived checks
                # state.compute_ready(...) -> removed to avoid overriding derived checks

                state.inc("contracts_received", 1)
                state.set_check("bus_active", True)
                state.set_meta("last_contract_ts", time.time())

                if not state.get_check_ok("shm_ready"):
                    ok, details, err = reader.ensure_ring()
                    state.set_check("shm_ready", ok, details=details, reason=err)

                    # state.compute_ready(...) REMOVED
                    if not ok:
                        metrics.inc_dropped_reason("shm_not_ready")
                        _safe_metric(
                            "metrics_frames_dropped_failed",
                            lambda: ivis_metrics.frames_dropped_total.labels(reason="shm_not_ready").inc(),
                        )
                        continue

                metrics.inc_received()
                try:
                    # frames in
                    _safe_metric("metrics_frames_in_failed", ivis_metrics.frames_in_total.inc)

                    # contract validation
                    try:
                        validate_frame_contract_v1(frame_contract)
                    except ContractValidationError as exc:
                        reason = getattr(exc, "reason_code", "validation_failed")
                        metrics.inc_dropped_reason(reason)
                        _safe_metric(
                            "metrics_frames_dropped_failed",
                            lambda: ivis_metrics.frames_dropped_total.labels(reason=reason).inc(),
                        )
                        logger.debug("Dropped frame due to contract validation: %s", getattr(exc, "message", str(exc)))
                        continue

                    # stale frame
                    if Config.MAX_FRAME_AGE_MS > 0:
                        now_ms = wall_clock_ms()
                        age_ms = latency_ms(now_ms, int(frame_contract.get("timestamp_ms", now_ms)))
                        if age_ms > Config.MAX_FRAME_AGE_MS:
                            metrics.inc_dropped()
                            _safe_metric(
                                "metrics_frames_dropped_failed",
                                lambda: ivis_metrics.frames_dropped_total.labels(reason="stale").inc(),
                            )
                            logger.debug("Dropped stale frame (age=%sms)", age_ms)
                            continue

                    # SHM read (observe)
                    try:
                        rr_start = time.time()
                        # trace SHM read
                        try:
                            with ivis_tracing.start_span("detection.shm_read", {"frame_id": frame_contract.get("frame_id"), "stream_id": frame_contract.get("stream_id")}):
                                raw_bytes = reader.read(frame_contract["memory"])
                        except Exception as exc:
                            _record_issue("tracing_span_shm_read_failed", "Tracing span failed (shm_read)", exc)
                            raw_bytes = reader.read(frame_contract["memory"])
                        rr_ms = (time.time() - rr_start) * 1000.0
                        _safe_metric("metrics_shm_read_latency_failed", lambda: ivis_metrics.shm_read_latency_ms.observe(rr_ms))
                    except Exception as e:
                        logger.debug("SHM read failed: %s", str(e))
                        raw_bytes = None

                    if raw_bytes is None:
                        metrics.inc_dropped()
                        _safe_metric(
                            "metrics_frames_dropped_failed",
                            lambda: ivis_metrics.frames_dropped_total.labels(reason="shm_read_failed").inc(),
                        )
                        continue

                    # decode + inference
                    frame = decoder.decode(raw_bytes, frame_contract)
                    frame_id = frame_contract.get("frame_id")
                    stream_id = frame_contract.get("stream_id")
                    try:
                        inf_start = time.time()
                        # inference span
                        try:
                            with ivis_tracing.start_span("detection.inference", {"frame_id": frame_id, "stream_id": stream_id}):
                                raw_results = runner.infer(frame)
                            state.set_meta("last_infer_ts", time.time())
                            state.inc("frames_inferred", 1)
                        except Exception as exc:
                            _record_issue("tracing_span_inference_failed", "Tracing span failed (inference)", exc)
                            raw_results = runner.infer(frame)
                        inf_ms = (time.time() - inf_start) * 1000.0
                        _safe_metric("metrics_inference_latency_failed", lambda: ivis_metrics.inference_latency_ms.observe(inf_ms))
                    except Exception:
                        raise

                    # publish
                    result = parse_output(frame_contract, raw_results)
                    # publish span
                    published = False
                    try:
                        with ivis_tracing.start_span("detection.publish", {"frame_id": frame_id, "stream_id": stream_id}):
                            publisher.publish(result)
                            published = True
                    except Exception as exc:
                        _record_issue("tracing_span_publish_failed", "Tracing span failed (publish)", exc)
                        if not published:
                            publisher.publish(result)
                            published = True
                    if published:
                        state.set_meta("last_publish_ts", time.time())
                        state.inc("results_published", 1)
                        # state.compute_ready(...) REMOVED
                    _safe_metric("metrics_frames_out_failed", ivis_metrics.frames_out_total.inc)

                    try:
                        ts = frame_contract.get("timestamp_ms")
                        if ts is not None:
                            now_ms = wall_clock_ms()
                            e2e = latency_ms(now_ms, int(ts))
                            _safe_metric("metrics_end_to_end_latency_failed", lambda: ivis_metrics.end_to_end_latency_ms.observe(e2e))
                    except Exception as exc:
                        _record_issue("end_to_end_latency_failed", "End-to-end latency calculation failed", exc)

                    metrics.inc_processed()

                except NonFatalError as e:
                    metrics.inc_dropped()
                    _safe_metric(
                        "metrics_frames_dropped_failed",
                        lambda: ivis_metrics.frames_dropped_total.labels(reason="nonfatal").inc(),
                    )
                    logger.debug("NonFatalError: %s", str(e))
                    continue

                except FatalError as e:
                    state.set_error("fatal_error", e, context=getattr(e, "context", None))
                    state.set_ready(False)
                    metrics.fatal_crashes += 1
                    logger.error("FATAL ERROR: %s | Context: %s", getattr(e, 'message', str(e)), getattr(e, 'context', None))
                    raise e

                except Exception as e:
                    state.set_error("unhandled_exception", e, context={"frame_id": frame_contract.get("frame_id")})
                    _safe_metric(
                        "metrics_frames_dropped_failed",
                        lambda: ivis_metrics.frames_dropped_total.labels(reason="unhandled_exception").inc(),
                    )
                    logger.error("Unhandled error processing frame (dropped): %s", str(e), exc_info=True)
                    continue

        finally:
            pass
    except FatalError as e:
        logger.error("FATAL ERROR: %s", getattr(e, 'message', str(e)))
        sys.exit(1)
    except KeyboardInterrupt:
        pass # Graceful exit
    except Exception as e:
        logger.critical("Unhandled exception during initialization: %s", str(e), exc_info=True)
        sys.exit(1)
    finally:
        logger.info("Cleaning up resources...")
        if 'consumer' in locals() and hasattr(consumer, 'close'):
            try:
                consumer.close()
                logger.info("Consumer closed.")
            except Exception as e:
                logger.warning("Error closing consumer: %s", e)
                
        if 'publisher' in locals() and hasattr(publisher, 'close'):
            try:
                publisher.close()
                logger.info("Publisher closed.")
            except Exception as e:
                logger.warning("Error closing publisher: %s", e)
        if 'reader' in locals() and hasattr(reader, 'close'):
            try:
                reader.close()
                logger.info("Reader closed.")
            except Exception as e:
                logger.warning("Error closing reader: %s", e)
                
        logger.info("Detection Service Stopped.")
        sys.exit(0)


if __name__ == "__main__":
    main()

========================================================================================================================
FILE: detection\memory\__init__.py
========================================================================================================================


========================================================================================================================
FILE: detection\memory\reader.py
========================================================================================================================
from detection.config import Config
from detection.errors.fatal import NonFatalError
from memory.shm_ring import ShmRing

class MemoryReader:
    """
    Stage 3: Reads Raw Bytes Only.
    No decoding, no reshaping here. Just bytes.
    """
    def __init__(self, host="localhost", port=6000):
        self._ring = None
        self._ring_info = {}

    def ensure_ring(self):
        if self._ring is not None:
            return True, dict(self._ring_info), None

        if Config.MEMORY_BACKEND != "shm":
            return False, {}, f"Unsupported memory backend: {Config.MEMORY_BACKEND}"

        slot_size = Config.FRAME_WIDTH * Config.FRAME_HEIGHT * 3
        if Config.SHM_CACHE_SECONDS > 0 and Config.SHM_CACHE_FPS > 0:
            slot_count = max(1, int(Config.SHM_CACHE_SECONDS * Config.SHM_CACHE_FPS))
        else:
            slot_count = max(1, Config.SHM_BUFFER_BYTES // slot_size)

        try:
            self._ring = ShmRing(
                Config.SHM_NAME,
                Config.SHM_META_NAME,
                slot_size,
                slot_count,
                create=False,
            )
            self._ring_info = {
                "shm_name": Config.SHM_NAME,
                "shm_meta_name": Config.SHM_META_NAME,
                "slot_size": slot_size,
                "slot_count": slot_count,
            }
            return True, dict(self._ring_info), None
        except FileNotFoundError:
            self._ring = None
            return False, {
                "shm_name": Config.SHM_NAME,
                "shm_meta_name": Config.SHM_META_NAME,
                "slot_size": slot_size,
                "slot_count": slot_count,
            }, "Shared memory not available yet"
        except Exception as exc:
            self._ring = None
            return False, {}, str(exc)

    def close(self):
        if self._ring is None:
            return
        try:
            self._ring.close()
        except Exception:
            pass
        self._ring = None
        self._ring_info = {}

    def read(self, memory_ref: dict) -> bytes:
        key = memory_ref.get("key")
        if not key:
            raise NonFatalError("Invalid memory reference: missing key")

        if memory_ref.get("backend", "").startswith("shm"):
            ok, _, err = self.ensure_ring()
            if not ok:
                raise NonFatalError(err or "Shared memory not ready")

            try:
                slot = int(key)
            except ValueError:
                raise NonFatalError("Invalid shared memory key")

            gen = memory_ref.get("generation", 0)
            data = self._ring.read(slot, gen)
            if data is None:
                raise NonFatalError("Shared memory miss (evicted or overwritten)")
            if len(data) == 0:
                raise NonFatalError("Empty data received from shared memory")
            return data

        raise NonFatalError("Unsupported memory backend")

========================================================================================================================
FILE: detection\metrics\__init__.py
========================================================================================================================


========================================================================================================================
FILE: detection\metrics\counters.py
========================================================================================================================
# FILE: detection/metrics/counters.py
# ------------------------------------------------------------------------------
class Metrics:
    def __init__(self):
        self.frames_received = 0
        self.frames_processed = 0
        self.frames_dropped = 0
        # keyed by reason string, e.g. {"bad_dtype": 3}
        self.frames_dropped_by_reason = {}
        self.fatal_crashes = 0
        self.last_inference_latency_ms = 0.0

    def inc_received(self): self.frames_received += 1
    def inc_processed(self): self.frames_processed += 1
    def inc_dropped(self): self.frames_dropped += 1
    def inc_dropped_reason(self, reason: str):
        """Increment dropped-frames counter with a reason label.

        This also increments the aggregate `frames_dropped`.
        """
        if not isinstance(reason, str) or not reason:
            reason = "unspecified"
        self.frames_dropped += 1
        self.frames_dropped_by_reason[reason] = self.frames_dropped_by_reason.get(reason, 0) + 1
    def log_latency(self, ms: float): self.last_inference_latency_ms = ms

metrics = Metrics()

========================================================================================================================
FILE: detection\model\__init__.py
========================================================================================================================


========================================================================================================================
FILE: detection\model\base.py
========================================================================================================================
# FILE: detection/model/base.py
# ------------------------------------------------------------------------------
from abc import ABC, abstractmethod
import numpy as np

class BaseModel(ABC):
    @abstractmethod
    def load(self):
        pass

    @abstractmethod
    def input_shape(self):
        pass

    @abstractmethod
    def predict(self, input_tensor: np.ndarray):
        pass

========================================================================================================================
FILE: detection\model\loader.py
========================================================================================================================
# FILE: detection/model/loader.py
# ------------------------------------------------------------------------------
import os

from detection.config import Config
from detection.model.base import BaseModel
from detection.model.yolo11 import Yolo11Model
from detection.errors.fatal import FatalError

def load_model() -> BaseModel:
    try:
        # Ensure MODEL_PATH exists and is readable
        model_path = Config.MODEL_PATH
        if not model_path:
            raise FatalError("MODEL_PATH is empty", context={"env": "MODEL_PATH"})

        if not os.path.isabs(model_path):
            # Resolve relative paths against project root
            model_path = os.path.abspath(model_path)

        if not os.path.exists(model_path):
            raise FatalError("Model file not found", context={"path": model_path})

        model = Yolo11Model(
            model_path=model_path,
            device=Config.MODEL_DEVICE,
            half=Config.MODEL_HALF,
            img_size=Config.MODEL_IMG_SIZE,
            conf=Config.MODEL_CONF,
            iou=Config.MODEL_IOU,
        )
        model.load()
        return model
    except Exception as e:
        # If already a FatalError, re-raise with context preserved
        if isinstance(e, FatalError):
            raise
        raise FatalError("Model load failed", context={"error": str(e)})

========================================================================================================================
FILE: detection\model\runner.py
========================================================================================================================
# FILE: detection/model/runner.py
# ------------------------------------------------------------------------------
import time
from typing import List, Dict, Any

import cv2
import numpy as np

from detection.metrics.counters import metrics
from detection.errors.fatal import FatalError
from detection.config import Config
from detection.tracking.reid_tracker import ReIDTracker


class ModelRunner:
    def __init__(self, model):
        self.model = model
        if not Config.REID_MODEL_PATH and not Config.REID_ALLOW_FALLBACK:
            raise FatalError(
                "REID_MODEL_PATH is required for visual fingerprint tracking",
                context={"env": "REID_MODEL_PATH"},
            )
        self.tracker = ReIDTracker(
            max_age=Config.TRACKER_MAX_AGE,
            init_frames=Config.TRACKER_INIT_FRAMES,
            nn_budget=Config.TRACKER_NN_BUDGET,
            max_iou=Config.TRACKER_MAX_IOU,
            model_name=Config.REID_MODEL_NAME,
            model_path=Config.REID_MODEL_PATH,
            allow_fallback=Config.REID_ALLOW_FALLBACK,
            half=Config.MODEL_HALF,
        )

    def warmup(self):
        dummy = np.zeros(self.model.input_shape(), dtype="uint8")
        self.model.predict(dummy)

    def infer(self, frame_bgr: np.ndarray) -> Dict[str, Any]:
        start = time.perf_counter()
        try:
            # Frames are expected to be in the contract color space (bgr) from ingestion.
            # Ingestion performs any needed source->bgr conversion, so do not
            # perform further color transforms here.
            model_start = time.perf_counter()
            raw_results = self.model.predict(frame_bgr)
            model_end = time.perf_counter()
            detections = self._parse_detections(raw_results)
            track_start = time.perf_counter()
            tracks = self.tracker.update(detections, frame_bgr)
            track_end = time.perf_counter()
            timing = {
                "inference_ms": (track_end - model_start) * 1000.0,
                "model_ms": (model_end - model_start) * 1000.0,
                "track_ms": (track_end - track_start) * 1000.0,
            }
            return {"detections": detections, "tracks": tracks, "timing": timing}
        except Exception as e:
            raise FatalError(f"Inference Engine Crash: {e}")
        finally:
            metrics.log_latency((time.perf_counter() - start) * 1000)

    def _parse_detections(self, raw_results) -> List[list]:
        detections = []
        try:
            if not raw_results:
                return detections
            result = raw_results[0]
            boxes = result.boxes
            if boxes is None:
                return detections
            for xyxy, conf, cls in zip(boxes.xyxy, boxes.conf, boxes.cls):
                x1, y1, x2, y2 = [float(v) for v in xyxy.tolist()]
                detections.append([[x1, y1, x2, y2], float(conf), int(cls)])
            return detections
        except Exception as exc:
            raise FatalError("Failed to parse model output", context={"error": str(exc)})

========================================================================================================================
FILE: detection\model\worker.py
========================================================================================================================
#!/usr/bin/env python
"""
Lightweight worker script for safe, killable model inference.

Usage: python worker.py <input_npy_path>

This script is intentionally simple: it loads the model, reads a numpy
array from the provided .npy file, runs `model.predict`, and prints the
JSON result to stdout.

The runner calls this script as a subprocess with a timeout so the OS
can kill it if it exceeds allowed time.
"""
import sys
import os
import json
import numpy as np

from detection.model.loader import load_model


def main():
    if len(sys.argv) < 2:
        print(json.dumps({"error": "missing input path"}))
        sys.exit(2)

    input_path = sys.argv[1]

    if not os.path.exists(input_path):
        print(json.dumps({"error": f"input file not found: {input_path}"}))
        sys.exit(3)

    try:
        model = load_model()
    except Exception as e:
        print(json.dumps({"error": f"model load failed: {e}"}))
        sys.exit(4)

    try:
        arr = np.load(input_path)
    except Exception as e:
        print(json.dumps({"error": f"failed to load npy: {e}"}))
        sys.exit(5)

    try:
        out = model.predict(arr)
        print(json.dumps(out))
        sys.exit(0)
    except Exception as e:
        print(json.dumps({"error": f"inference failed: {e}"}))
        sys.exit(6)


if __name__ == "__main__":
    main()

========================================================================================================================
FILE: detection\model\yolo11.py
========================================================================================================================
# FILE: detection/model/yolo11.py
# ------------------------------------------------------------------------------
import os
from typing import Optional

import numpy as np

from detection.errors.fatal import FatalError
from detection.model.base import BaseModel


class Yolo11Model(BaseModel):
    def __init__(
        self,
        model_path: str,
        device: str = "auto",
        half: bool = False,
        img_size: int = 640,
        conf: float = 0.25,
        iou: float = 0.5,
    ) -> None:
        self.model_path = model_path
        self.device = device
        self.half = half
        self.img_size = img_size
        self.conf = conf
        self.iou = iou
        self._model = None
        self._device_resolved: Optional[str] = None

    def load(self):
        if not self.model_path:
            raise FatalError("MODEL_PATH is empty", context={"env": "MODEL_PATH"})
        if not os.path.exists(self.model_path):
            raise FatalError("Model file not found", context={"path": self.model_path})

        try:
            import torch
            from ultralytics import YOLO
        except Exception as exc:
            raise FatalError("Missing Ultralytics/Torch dependency", context={"error": str(exc)}) from exc

        thread_count = os.getenv("TORCH_NUM_THREADS")
        interop_threads = os.getenv("TORCH_NUM_INTEROP_THREADS")
        if thread_count:
            try:
                torch.set_num_threads(int(thread_count))
            except ValueError:
                pass
        if interop_threads:
            try:
                torch.set_num_interop_threads(int(interop_threads))
            except ValueError:
                pass

        if self.device == "auto":
            self._device_resolved = "cuda:0" if torch.cuda.is_available() else "cpu"
        else:
            self._device_resolved = self.device

        self._model = YOLO(self.model_path)
        self._model.to(self._device_resolved)
        if self.half and self._device_resolved.startswith("cuda"):
            self._model.model.half()

    def input_shape(self):
        return (self.img_size, self.img_size, 3)

    def predict(self, input_tensor: np.ndarray):
        if self._model is None:
            raise FatalError("Model not loaded")

        return self._model.predict(
            source=input_tensor,
            imgsz=self.img_size,
            conf=self.conf,
            iou=self.iou,
            device=self._device_resolved,
            verbose=False,
        )

========================================================================================================================
FILE: detection\postprocess\__init__.py
========================================================================================================================


========================================================================================================================
FILE: detection\postprocess\parse.py
========================================================================================================================
# FILE: detection/postprocess/parse.py
# ------------------------------------------------------------------------------

def _iou(box_a, box_b):
    ax1, ay1, ax2, ay2 = box_a
    bx1, by1, bx2, by2 = box_b
    inter_x1 = max(ax1, bx1)
    inter_y1 = max(ay1, by1)
    inter_x2 = min(ax2, bx2)
    inter_y2 = min(ay2, by2)
    inter_w = max(0.0, inter_x2 - inter_x1)
    inter_h = max(0.0, inter_y2 - inter_y1)
    inter_area = inter_w * inter_h
    if inter_area <= 0:
        return 0.0
    area_a = max(0.0, ax2 - ax1) * max(0.0, ay2 - ay1)
    area_b = max(0.0, bx2 - bx1) * max(0.0, by2 - by1)
    denom = area_a + area_b - inter_area
    if denom <= 0:
        return 0.0
    return inter_area / denom


def _track_bbox_xyxy(track: dict):
    tb = track.get("bbox_xyxy")
    if tb and isinstance(tb, (list, tuple)) and len(tb) == 4:
        try:
            return [float(tb[0]), float(tb[1]), float(tb[2]), float(tb[3])]
        except Exception:
            return None
    tb = track.get("bbox")
    if tb and isinstance(tb, (list, tuple)) and len(tb) == 4:
        try:
            x, y, w, h = [float(v) for v in tb]
        except Exception:
            return None
        return [x, y, x + max(0.0, w), y + max(0.0, h)]
    return None


def _track_is_confirmed(track: dict) -> bool:
    if "confirmed" in track:
        return bool(track.get("confirmed"))
    if "is_confirmed" in track:
        return bool(track.get("is_confirmed"))
    return True


def _track_is_recent(track: dict) -> bool:
    if "time_since_update" not in track:
        return True
    try:
        return float(track.get("time_since_update", 0)) <= 1
    except Exception:
        return False


def parse_output(frame_contract: dict, raw_results: dict):
    """Construct ResultContractV1 from frame contract and raw model/tracker outputs.

    Detections list entries are normalized to include optional track_id when available.
    """
    timing = raw_results.get("timing") or {}
    timing.setdefault("inference_ms", 0.0)

    raw_dets = raw_results.get("detections", [])
    raw_tracks = raw_results.get("tracks", [])

    tracks = []
    for t in raw_tracks:
        if not _track_is_confirmed(t):
            continue
        if not _track_is_recent(t):
            continue
        track_id = t.get("track_id")
        if track_id is None:
            continue
        tb = _track_bbox_xyxy(t)
        if tb is not None:
            tracks.append((track_id, tb))

    dets = []
    # unused = set(range(len(tracks))) # Removed in global matching
    for det in raw_dets:
        try:
            (x1, y1, x2, y2), conf, cls_id = det
        except Exception:
            continue
        entry = {
            "bbox": [float(x1), float(y1), float(x2), float(y2)],
            "conf": float(conf),
            "class_id": int(cls_id),
        }
        # Greedy logic removed. Just valid detections list first.
        dets.append(entry)

    # Global 1-to-1 matching
    matches = []
    for d_idx, det_entry in enumerate(dets):
        det_bbox = det_entry["bbox"]
        for track_id, t_bbox in tracks:
            try:
                iou = _iou(det_bbox, t_bbox)
            except Exception:
                iou = 0.0
            
            if iou >= 0.3:
                 # Tie-break: IoU desc, track_id asc, det_idx asc
                 matches.append((iou, track_id, d_idx))
    
    # Sort matches: higher IoU first.
    matches.sort(key=lambda x: (-x[0], x[1], x[2]))

    used_tracks = set()
    used_dets = set()
    for _, track_id, d_idx in matches:
        if track_id in used_tracks or d_idx in used_dets:
            continue
        
        dets[d_idx]["track_id"] = track_id
        used_tracks.add(track_id)
        used_dets.add(d_idx)

    result = {
        "contract_version": 1,
        "frame_id": frame_contract["frame_id"],
        "stream_id": frame_contract["stream_id"],
        "camera_id": frame_contract["camera_id"],
        "timestamp_ms": frame_contract["timestamp_ms"],
        "mono_ms": frame_contract["mono_ms"],
        "detections": dets,
        "model": {},
        "timing": timing,
    }

    return result

========================================================================================================================
FILE: detection\preprocess\__init__.py
========================================================================================================================


========================================================================================================================
FILE: detection\preprocess\tensorize.py
========================================================================================================================
# FILE: detection/preprocess/tensorize.py
# ------------------------------------------------------------------------------
import numpy as np

def to_model_input(frame_data: np.ndarray) -> np.ndarray:
    tensor = frame_data.astype("float32") / 255.0
    return tensor[None, ...]

========================================================================================================================
FILE: detection\preprocess\validate.py
========================================================================================================================
# FILE: detection/preprocess/validate.py
# ------------------------------------------------------------------------------
from detection.errors.fatal import NonFatalError
from ivis.common.contracts.validators import ContractValidationError, validate_frame_contract_v1


def validate_frame(contract: dict):
    """Compatibility wrapper around the official contract validator."""
    try:
        validate_frame_contract_v1(contract)
    except ContractValidationError as exc:
        raise NonFatalError(f"Contract Violation: {exc.message}") from exc

========================================================================================================================
FILE: detection\publish\__init__.py
========================================================================================================================


========================================================================================================================
FILE: detection\publish\results.py
========================================================================================================================
# FILE: detection/publish/results.py
# ------------------------------------------------------------------------------
import json

from detection.config import Config
from detection.errors.fatal import FatalError
from ivis_logging import setup_logging
from ivis.common.contracts.result_contract import validate_result_contract_v1


class PostgresWriter:
    def __init__(self, dsn: str):
        self.dsn = dsn
        self.conn = None
        self._connect()

    def _connect(self):
        try:
            import psycopg2
        except Exception as exc:
            raise FatalError("Missing psycopg2 dependency", context={"error": str(exc)}) from exc

        self.conn = psycopg2.connect(self.dsn)
        self.conn.autocommit = True
        with self.conn.cursor() as cur:
            cur.execute(
                """
                CREATE TABLE IF NOT EXISTS detection_results (
                    id SERIAL PRIMARY KEY,
                    frame_id TEXT NOT NULL,
                    stream_id TEXT NOT NULL,
                    camera_id TEXT NOT NULL,
                    timestamp BIGINT NOT NULL,
                    payload JSONB NOT NULL,
                    created_at TIMESTAMPTZ DEFAULT NOW()
                )
                """
            )

    def write(self, result: dict):
        if not self.conn:
            return
        with self.conn.cursor() as cur:
            cur.execute(
                """
                INSERT INTO detection_results (frame_id, stream_id, camera_id, timestamp, payload)
                VALUES (%s, %s, %s, %s, %s)
                """,
                (
                    result.get("frame_id"),
                    result.get("stream_id"),
                    result.get("camera_id"),
                    result.get("timestamp_ms"),
                    json.dumps(result),
                ),
            )

    def close(self):
        if self.conn:
            try:
                self.conn.close()
            except Exception as exc:
                print(f"[DETECTION] Error closing Postgres connection: {exc}")
            self.conn = None


class ZmqResultWriter:
    def __init__(self, endpoint: str):
        try:
            import zmq
        except Exception as exc:
            raise FatalError("Missing ZeroMQ dependency", context={"error": str(exc)}) from exc
        self.zmq = zmq
        self.endpoint = endpoint
        self.socket = self.zmq.Context.instance().socket(self.zmq.PUB)
        self.socket.setsockopt(self.zmq.LINGER, Config.ZMQ_LINGER_MS)
        self.socket.bind(self.endpoint)

    def write(self, result: dict):
        payload = json.dumps(result).encode("utf-8")
        try:
            self.socket.send(payload)
        except Exception as exc:
            import logging
            logging.getLogger("detection").error("ZMQ results publish failed: %s", exc)
            return

    def close(self):
        if self.socket:
            try:
                self.socket.close()
            except Exception as exc:
                import logging
                logging.getLogger("detection").debug("Error closing ZMQ socket: %s", exc)
            self.socket = None


class ResultPublisher:
    def __init__(self):
        self.logger = setup_logging("detection")
        self.pg_writer = None
        self.zmq_writer = None
        if Config.POSTGRES_DSN:
            try:
                self.pg_writer = PostgresWriter(Config.POSTGRES_DSN)
                self.logger.info("Postgres writer enabled.")
            except Exception as exc:
                self.logger.error("Postgres writer disabled: %s", exc)
        if Config.ZMQ_RESULTS_PUB_ENDPOINT:
            try:
                self.zmq_writer = ZmqResultWriter(Config.ZMQ_RESULTS_PUB_ENDPOINT)
                self.logger.info("ZMQ results publisher enabled.")
            except Exception as exc:
                self.logger.error("ZMQ results publisher disabled: %s", exc)

    def publish(self, result: dict):
        # Populate model metadata
        model_meta = {
            "name": Config.MODEL_NAME,
            "version": Config.MODEL_VERSION,
            "threshold": Config.MODEL_CONF,
            "input_size": [Config.MODEL_IMG_SIZE, Config.MODEL_IMG_SIZE],
        }
        result["model"] = model_meta

        # Ensure timing present
        timing = result.get("timing")
        if timing is None or not isinstance(timing, dict):
            timing = {}
            result["timing"] = timing
        timing.setdefault("inference_ms", 0.0)

        # Validate result contract v1 before publishing
        try:
            validate_result_contract_v1(result)
        except Exception as exc:
            # Validation failure should not crash service; surface as Fatal to caller
            raise FatalError("ResultContractV1 validation failed", context={"error": str(exc)}) from exc

        try:
            payload = json.dumps(result)
            print(f"[RESULT] {payload}")
            if self.pg_writer:
                self.pg_writer.write(result)
            if self.zmq_writer:
                self.zmq_writer.write(result)
        except Exception as e:
            raise FatalError("Publish failed", context={"error": str(e)})

    def close(self):
        if self.zmq_writer:
            try:
                self.zmq_writer.close()
            except Exception as exc:
                self.logger.debug("Error closing ZMQ writer: %s", exc)
        if self.pg_writer:
            try:
                self.pg_writer.close()
            except Exception as exc:
                self.logger.debug("Error closing Postgres writer: %s", exc)

========================================================================================================================
FILE: detection\runtime.py
========================================================================================================================
# FILE: detection/runtime.py
# ------------------------------------------------------------------------------
import signal
import sys

class Runtime:
    def __init__(self):
        self.running = True
        self.stop_reason = ""
        signal.signal(signal.SIGINT, self.stop)
        signal.signal(signal.SIGTERM, self.stop)

    def stop(self, signum, frame):
        print("\n[Detection] Stopping (Signal received)...")
        self.running = False
        self.stop_reason = "signal"

    def request_stop(self, reason: str = ""):
        self.running = False
        self.stop_reason = reason

    def should_continue(self) -> bool:
        return self.running

========================================================================================================================
FILE: detection\tracking\__init__.py
========================================================================================================================
# FILE: detection/tracking/__init__.py
# ------------------------------------------------------------------------------

========================================================================================================================
FILE: detection\tracking\reid_tracker.py
========================================================================================================================
# FILE: detection/tracking/reid_tracker.py
# ------------------------------------------------------------------------------
import hashlib
from typing import List, Dict, Any

import numpy as np

from detection.errors.fatal import FatalError


class ReIDTracker:
    def __init__(
        self,
        max_age: int,
        init_frames: int,
        nn_budget: int,
        max_iou: float,
        model_name: str,
        model_path: str = None,
        allow_fallback: bool = False,
        half: bool = False,
    ) -> None:
        try:
            from deep_sort_realtime.deepsort_tracker import DeepSort
        except Exception as exc:
            raise FatalError("Missing DeepSORT dependency", context={"error": str(exc)}) from exc

        use_fallback = allow_fallback and not model_path
        if use_fallback:
            kwargs = {
                "max_age": max_age,
                "n_init": init_frames,
                "nn_budget": nn_budget,
                "max_iou_distance": max_iou,
                "embedder": "mobilenet",
                "half": half,
                "bgr": True,
            }
        else:
            kwargs = {
                "max_age": max_age,
                "n_init": init_frames,
                "nn_budget": nn_budget,
                "max_iou_distance": max_iou,
                "embedder": "torchreid",
                "embedder_model_name": model_name,
                "half": half,
                "bgr": True,
            }
            if model_path:
                kwargs["embedder_wts"] = model_path

        self._tracker = DeepSort(**kwargs)

    def update(self, detections: List[list], frame_bgr: np.ndarray) -> List[Dict[str, Any]]:
        tracks = self._tracker.update_tracks(detections, frame=frame_bgr)
        output = []
        for track in tracks:
            if not track.is_confirmed():
                continue
            if hasattr(track, "to_ltrb"):
                left, top, right, bottom = track.to_ltrb()
            elif hasattr(track, "to_tlbr"):
                left, top, right, bottom = track.to_tlbr()
            else:
                continue

            feature = getattr(track, "last_feature", None)
            appearance_hash = None
            if feature is not None:
                try:
                    digest = hashlib.sha1(np.asarray(feature).tobytes()).hexdigest()
                    appearance_hash = digest
                except Exception:
                    appearance_hash = None

            output.append(
                {
                    "track_id": track.track_id,
                    "bbox": [float(left), float(top), float(right - left), float(bottom - top)],
                    "bbox_xyxy": [float(left), float(top), float(right), float(bottom)],
                    "confidence": float(getattr(track, "det_conf", 0.0) or 0.0),
                    "class_id": int(getattr(track, "det_class", -1) or -1),
                    "appearance_hash": appearance_hash,
                }
            )
        return output

========================================================================================================================
FILE: docs\architecture.md
========================================================================================================================
# Architecture Notes — IVISv

Production message bus: Redis Streams

- Frames are produced by `ingestion` into the Redis stream `ivis:frames` using `XADD`.
- Detection runs as a consumer group `ivis:detection` and consumes frames using `XREADGROUP`.
- Results are written to `ivis:results` (XADD) and can be consumed by the UI or other services.

Why Redis Streams?

- Persistent log with consumer groups enables replay, monitoring of pending entries, and robust backpressure.
- Simpler operational model than managing a custom TCP bus or an always-running ZMQ proxy.

Legacy transports

- Legacy or developer-only transports have been moved to `ivis/legacy/` to keep the canonical production path clear. Examples:
  - TCP/simple Socket bus (dev-only)
  - ZeroMQ proxy (dev-only)
  - Redis PubSub helper code (kept for backward compatibility)
  - Local HTTP memory server used in early development

Contract: frames on `ivis:frames`

- Each stream entry contains a JSON `FrameContractV1` payload under a `payload` field.
- Downstream services assume frames are in the `FRAME_COLOR_SPACE` (v1 contract = `bgr`). Ingestion is responsible for converting the raw `SOURCE_COLOR` into the canonical `FRAME_COLOR_SPACE` before publishing.

========================================================================================================================
FILE: docs\baseline_report.md
========================================================================================================================
# تقرير الأساس (Baseline Report)

خلاصة سريعة:

- موقع المشروع: المشروع في جذر المستودع (ملفات مثل `run_system.py`).
- لم تُجرَ أي تغييرات سلوكية على النظام.

1) كيفية التشغيل الحالية

- لتشغيل النظام (مُنسّق):

```
python run_system.py [--source SOURCE] [--source-type auto|file|webcam|rtsp] [--config CONFIG]
[--bus zmq|tcp] [--loop|--no-loop]
```

- ما يفعله `run_system.py` عند التشغيل:
  - يبدأ ثلاث خدمات فرعية باستخدام نفس مفسّر بايثون:
    - `python ingestion/main.py`
    - `python detection/main.py`
    - `python ui/live_view.py`
  - السجلات تُكتب إلى مجلد `logs/` (يُنشأ تلقائياً).
  - الواجهة متوقعة على: http://127.0.0.1:8080

2) المتغيرات البيئية المستخدمة (مقتطف من `run_system.py`)

- إعدادات عامة:
  - `PYTHONPATH`

- متغيرات `ingestion` (مستخدمة عند بدء خدمة الاستيعاب):
  - `MEMORY_BACKEND`, `SHM_BUFFER_BYTES`, `SHM_OWNER`, `RTSP_URL`, `STREAM_ID`, `CAMERA_ID`,
    `TARGET_FPS`, `BUS_TRANSPORT`, `ZMQ_PUB_ENDPOINT`, `ZMQ_RESULTS_SUB_ENDPOINT`,
    `SHM_CACHE_SECONDS`, `SHM_CACHE_FPS`, `FRAME_WIDTH`, `FRAME_HEIGHT`, `FRAME_COLOR`,
    `SELECTOR_MODE`, `ADAPTIVE_FPS`, `ADAPTIVE_MIN_FPS`, `ADAPTIVE_MAX_FPS`,
    `ADAPTIVE_SAFETY`, `VIDEO_LOOP`, `SHM_NAME`, `SHM_META_NAME`

- متغيرات `detection` (مستخدمة عند بدء خدمة الكشف):
  - `MODEL_NAME`, `MODEL_VERSION`, `MODEL_HASH`, `MODEL_PATH`, `INFERENCE_TIMEOUT`, `DEBUG`,
    `MODEL_DEVICE`, `MODEL_HALF`, `MODEL_IMG_SIZE`, `MODEL_CONF`, `MODEL_IOU`,
    `REID_MODEL_PATH`, `REID_ALLOW_FALLBACK`, `BUS_TRANSPORT`, `ZMQ_SUB_ENDPOINT`,
    `ZMQ_RESULTS_PUB_ENDPOINT`, `MEMORY_BACKEND`, `SHM_OWNER`, `SHM_NAME`, `SHM_META_NAME`,
    `SHM_BUFFER_BYTES`, `SHM_CACHE_SECONDS`, `SHM_CACHE_FPS`, `FRAME_WIDTH`, `FRAME_HEIGHT`,
    `KMP_DUPLICATE_LIB_OK`, `FRAME_COLOR`, `MAX_FRAME_AGE_MS`, `TORCH_NUM_THREADS`,
    `TORCH_NUM_INTEROP_THREADS`

- متغيرات `ui` (مستخدمة عند بدء واجهة العرض):
  - `DEBUG`, `ZMQ_SUB_ENDPOINT`, `ZMQ_RESULTS_SUB_ENDPOINT`, `SHM_OWNER`, `STREAM_ID`,
    `CAMERA_ID`, `SHM_NAME`, `SHM_META_NAME`, `SHM_BUFFER_BYTES`, `SHM_CACHE_SECONDS`,
    `SHM_CACHE_FPS`, `FRAME_WIDTH`, `FRAME_HEIGHT`, `FRAME_COLOR`

ملاحظة: يمكن أن تُطبَّق قيم إضافية من ملف التكوين (`--config`) عبر مفتاح `env` أو عبر أقسام `ingestion`/`detection`/`ui`.

3) نتائج التشغيل والاختبارات (سجل)

- pytest:

```
2 passed in 0.48s
```

- تشغيلٍ تجريبي سريع لـ `run_system.py --help`:

```
تمّت طباعة واجهة الاستخدام بنجاح (usage/help) وسطر تسجيل يوضح المفسّر المستخدم.
```

- ملاحظات عن الأخطاء/التحذيرات:
  - لم تُسجّل أخطاء تشغيل أثناء تنفيذ الاختبارات أو عند طلب `--help`.
  - هناك تحذيرات/مسارات محتملة في الكود تشير إلى أن وزنات النماذج قد تكون مفقودة أثناء التشغيل الكامل
    (مثلاً: تحذير عند عدم وجود ملفات النماذج مثل `models/yolo.pt` أو ملفات ReID). هذه التحذيرات
    تظهر فقط عند بدء الخدمات الفعلية (لم تُشغَّل هنا).

4) معلومات بيئة التشغيل

- Python (المفسّر المستخدم للتشغيل التجريبي):

```
Python 3.11.14
```

- `pip freeze` (قائمة الحزم المثبتة):

```
absl-py==2.3.1
annotated-types==0.7.0
antlr4-python3-runtime==4.9.3
anyio==4.11.0
argon2-cffi==25.1.0
argon2-cffi-bindings==25.1.0
arrow==1.4.0
asttokens==3.0.0
async-lru==2.0.5
attrs==25.4.0
babel==2.17.0
backcall==0.2.0
beautifulsoup4==4.14.2
bleach==6.2.0
blinker==1.9.0
cachetools==6.2.1
certifi==2025.10.5
cffi==2.0.0
charset-normalizer==3.4.4
click==8.3.0
colorama==0.4.6
comm==0.2.3
contourpy==1.3.3
cvzone==1.6.1
cycler==0.12.1
Cython==3.1.5
dataclasses-json==0.6.7
debugpy==1.8.17
decorator==5.2.1
deep-sort-realtime==1.3.2
defusedxml==0.7.1
dlib @ file:///C:/bld/dlib-split_1761791650486/work
easydict==1.13
easyocr==1.7.2
executing==2.2.1
face-recognition==1.3.0
face_recognition_models==0.3.0
fastjsonschema==2.21.2
filelock==3.20.0
filterpy==1.4.5
Flask==3.1.2
fonttools==4.60.1
fqdn==1.5.1
fsspec==2025.9.0
google-auth==2.41.1
google-auth-oauthlib==1.2.2
grpcio==1.76.0
h11==0.16.0
h5py==3.15.1
httpcore==1.0.9
httpx==0.28.1
hydra-core==1.3.2
idna==3.11
imageio==2.37.0
importlib_metadata==8.7.0
importlib_resources==6.5.2
iniconfig==2.3.0
ipykernel==7.0.1
ipython==9.6.0
ipython-genutils==0.2.0
ipython_pygments_lexers==1.1.1
ipywidgets==8.1.7
isoduration==20.11.0
itsdangerous==2.2.0
jedi==0.19.2
Jinja2==3.1.6
joblib==1.5.2
json5==0.12.1
jsonpointer==3.0.0
jsonschema==4.25.1
jsonschema-specifications==2025.9.1
jupyter==1.1.1
jupyter-console==6.6.3
jupyter-events==0.12.0
jupyter-lsp==2.3.0
jupyter_client==8.6.3
jupyter_core==5.9.1
jupyter_server==2.17.0
jupyter_server_terminals==0.5.3
jupyterlab==4.4.10
jupyterlab_pygments==0.3.0
jupyterlab_server==2.28.0
jupyterlab_widgets==3.0.15
kiwisolver==1.4.9
labelImg==1.8.6
lap @ file:///D:/bld/lap_1756649018065/work
lark==1.3.0
lazy_loader==0.4
llvmlite==0.45.1
loguru==0.7.3
lxml==6.0.2
lz4==4.4.5
Markdown==3.9
MarkupSafe==3.0.3
marshmallow==3.26.1
matplotlib==3.10.7
matplotlib-inline==0.1.7
mistune==3.1.4
motmetrics==1.4.0
mpmath==1.3.0
mypy_extensions==1.1.0
nbclassic==1.3.3
nbclient==0.10.2
nbconvert==7.16.6
nbformat==5.10.4
nest-asyncio==1.6.0
networkx==3.5
ninja==1.13.0
notebook==7.4.7
notebook_shim==0.2.4
numba==0.62.1
numpy==2.2.6
oauthlib==3.3.1
omegaconf==2.3.0
onemetric==0.1.2
opencv-python==4.12.0.88
opencv-python-headless==4.12.0.88
overrides==7.7.0
packaging==25.0
pafy==0.5.5
pandas==2.3.3
pandocfilters==1.5.1
parso==0.8.5
pickleshare==0.7.5
pillow==12.0.0
platformdirs==4.5.0
pluggy==1.6.0
polars==1.34.0
polars-runtime-32==1.34.0
prometheus_client==0.23.1
prompt_toolkit==3.0.52
protobuf==6.33.0
psutil==7.1.1
pure_eval==0.2.3
pyasn1==0.6.1
pyasn1_modules==0.4.2
pyclipper==1.3.0.post6
pycocotools==2.0.10
pycparser==2.23
pydantic==2.12.5
pydantic_core==2.41.5
Pygments==2.19.2
pyparsing==3.2.5
PyQt5==5.15.11
PyQt5-Qt5==5.15.2
PyQt5_sip==12.17.1
pyrsistent==0.20.0
pytest==9.0.1
python-bidi==0.6.7
python-dateutil==2.9.0.post0
python-json-logger==4.0.0
pytube==15.0.0
pytz==2025.2
PyWavelets==1.9.0
pywin32==311
pywinpty==3.0.2
PyYAML==6.0.3
pyzmq==27.1.0
qtconsole==5.7.0
QtPy==2.4.3
referencing==0.37.0
requests==2.32.5
requests-oauthlib==2.0.0
rfc3339-validator==0.1.4
rfc3986-validator==0.1.1
rfc3987-syntax==1.1.0
rpds-py==0.28.0
rsa==4.9.1
Rx==3.2.0
scikit-image==0.25.2
scikit-learn==1.7.2
scipy==1.16.3
seaborn==0.13.2
Send2Trash==1.8.3
sentry-sdk==2.42.1
shapely==2.1.2
six==1.17.0
sniffio==1.3.1
soupsieve==2.8
stack-data==0.6.3
supervision==0.26.1
sympy==1.14.0
tabulate==0.9.0
tensorboard==2.20.0
tensorboard-data-server==0.7.2
terminado==0.18.1
thop==0.1.1.post2209072238
threadpoolctl==3.6.0
tifffile==2025.10.16
tinycss2==1.4.0
torch==2.9.0
torchaudio==2.9.0+cpu
torchvision==0.24.0
tornado==6.5.2
tqdm==4.67.1
traitlets==5.14.3
typing-inspect==0.9.0
typing-inspection==0.4.2
typing_extensions==4.15.0
tzdata==2025.2
ultralytics==8.3.220
ultralytics-thop==2.0.17
uri-template==1.3.0
urllib3==2.5.0
wcwidth==0.2.14
webcolors==24.11.1
webencodings==0.5.1
websocket-client==1.9.0
websockets==15.0.1
Werkzeug==3.1.3
widgetsnbextension==4.0.14
win32_setctime==1.2.0
xmltodict==1.0.2
youtube-dl==2021.12.17
zipp==3.23.0
```

ملاحظة أخيرة:
- قمت بتشغيل الاختبارات وتحققًا سريعًا من `run_system.py --help` فقط (لم أبدأ الخدمات الفعلية: `ingestion`, `detection`, `ui`).
- إذا أردت، أستطيع تشغيل النظام بالكامل (مع تسجيل كامل للمخرجات) لكن ذلك سيشغّل عمليات خلفية ويتطلب توفر خدماتٍ خارجية (مثل Redis) وملفات النماذج؛ هل ترغب أن أُجري تشغيلًا متكاملًا الآن؟

========================================================================================================================
FILE: docs\contracts\frame_v1.md
========================================================================================================================
# Frame Contract v1

This document defines the FrameContractV1 payload for ingestion -> detection -> UI.

## Fields

- contract_version (int): must be 1.
- frame_id (string): unique frame identifier derived from stream_id + pts + fingerprint.
- stream_id (string): stream identifier.
- camera_id (string): camera identifier.
- pts (float): presentation timestamp in milliseconds from the source when available.
- timestamp_ms (int): wall-clock epoch time in milliseconds at capture.
- mono_ms (int): monotonic clock time in milliseconds at capture (must not go backwards).
- memory (object):
  - backend (string): backend identifier (e.g., shm_ring_v1).
  - key (string): slot key in the backend.
  - size (int): payload size in bytes.
  - generation (int): slot generation for eviction safety.
- frame_width (int): width in pixels.
- frame_height (int): height in pixels.
- frame_channels (int): channel count (v1 expects 3).
- frame_dtype (string): data type (v1 expects uint8).
- frame_color_space (string): color space (v1 expects bgr).
- roi (object, optional): region-of-interest metadata.
  - boxes: list of [x1, y1, x2, y2].
  - polygons: list of point lists, each point is [x, y].

## Timestamp discipline

- timestamp_ms is wall clock and can jump if the system time changes.
- mono_ms is monotonic and must never decrease; use it for durations and latency.
- pts reflects the source timeline and can reset (e.g., file rewind).

========================================================================================================================
FILE: docs\contracts\result_v1.md
========================================================================================================================
# Result Contract V1

This document defines the ResultContractV1 emitted by the Detection service and consumed by UI.

Schema (JSON-like):

- `contract_version`: 1
- `frame_id`: string
- `stream_id`: string
- `camera_id`: string
- `timestamp_ms`: integer (ms)
- `mono_ms`: integer (ms)
- `detections`: array of objects {
  - `bbox`: [x1, y1, x2, y2] (numbers, XYXY)
  - `conf`: number (0.0 - 1.0)
  - `class_id`: integer
  - `class_name` (optional): string
  - `track_id` (optional): string or int
  }
- `model`: object {
  - `name`: string
  - `version`: string
  - `threshold`: number
  - `input_size`: [h, w]
  }
- `timing`: object {
  - `inference_ms`: number (required)
  - `ingest_ms` (optional): number
  - `total_ms` (optional): number
  }

Notes
- Consumers MUST validate the contract strictly. Any mismatch should be dropped and metrics incremented.
- The UI expects `detections` entries as objects (not positional tuples).

========================================================================================================================
FILE: docs\runbook.md
========================================================================================================================
**Prometheus Metrics**

This runbook documents the Prometheus metrics exposed by IVIS services (ingestion, detection, UI).

Default endpoints and ports:
- Ingestion: `http://<host>:8001/metrics` or set `INGESTION_METRICS_PORT` env var.
- Detection: `http://<host>:8002/metrics` or set `DETECTION_METRICS_PORT` env var.
- UI: `http://<host>:8080/metrics` (exposed on the Flask UI service port).

Metric names (available across services):
- Counters:
	- `frames_in_total`: total frames entering a service.
	- `frames_out_total`: total frames successfully processed/published.
	- `frames_dropped_total{reason="..."}`: frames dropped, labeled by reason (`lag`, `validation_failed`, `nonfatal`, `unhandled_exception`, ...).
- Histograms (values observed in milliseconds):
	- `shm_write_latency_ms`: latency to write frames into shared memory.
	- `shm_read_latency_ms`: latency to read frames from shared memory.
	- `inference_latency_ms`: model inference time.
	- `end_to_end_latency_ms`: best-effort end-to-end latency from capture timestamp_ms to processing time.
- Gauges:
	- `fps_in`: approximate input fps (ingest if available).
	- `fps_out`: output/display fps (UI sets this value).

Notes and usage:
- Each service runs its own Prometheus HTTP endpoint (or integrates into existing web server for UI). Configure your Prometheus scrape targets to collect metrics from these endpoints.
- Metric names and labels are intentionally short and consistent across services for easy aggregation.
- `frames_dropped_total` includes a `reason` label — useful for differentiating drops due to backpressure (`lag`) vs validation errors vs runtime exceptions.

Troubleshooting:
- If `/metrics` fails to bind, check the service logs for the "Prometheus metrics HTTP server started" message or exceptions about binding ports.
- The UI also provides a diagnostic JSON endpoint at `/json_metrics` with a quick snapshot of FPS and SHM status.

# Runbook — IVISv (Production Defaults)

Official bus: ZeroMQ (contracts) + Shared Memory (frames)

- Producer: ingestion publishes frame contracts over ZeroMQ and writes frame bytes to SHM ring.
- Consumer (detection): subscribes to contracts over ZeroMQ and reads frame bytes from SHM.
- UI: subscribes to contracts/results over ZeroMQ and renders frames from SHM.

Environment variables (important):

- `ZMQ_PUB_ENDPOINT` — publisher endpoint for frame contracts (ingestion).
- `ZMQ_SUB_ENDPOINT` — subscriber endpoint for frame contracts (detection/UI).
- `ZMQ_RESULTS_PUB_ENDPOINT` — publisher endpoint for results (detection).
- `ZMQ_RESULTS_SUB_ENDPOINT` — subscriber endpoint for results (UI/ingestion adaptive).
- `SHM_CACHE_SECONDS` — how many seconds to keep in the SHM ring cache.

Notes:

- The system defaults to ZeroMQ for contract delivery and SHM for frame bytes.
- Legacy transports (TCP socket, dev-only proxies) remain under `ivis/legacy/` and are not part of the default path.

Quick commands:

Run system (default production mode — ZMQ + SHM):

```bash
python run_system.py --source <rtsp-or-file>
```

Start a single service (example: detection):

```bash
python -m detection.main
```

========================================================================================================================
FILE: docs\status_after_p12.md
========================================================================================================================
# Status after P12

## pytest
- Command: `python -m pytest -q`
- Result: `5 passed in 0.67s`

## Local run (15s)
- Redis: running locally (redis-server process already active); publish failed with `MISCONF ... stop-writes-on-bgsave-error` (see `logs/ingestion.err`).
- Command: `python run_system.py --source sample.mp4` (note: `--rtsp-url` is not a recognized flag in `run_system.py`).
- Runtime: ~15s; UI health reachable.
- Streams:
  - Redis streams: `ivis:frames`, `ivis:results`
  - Contract stream_id: `cam_01_main` (camera_id `cam_01`)

## Contract validation drops
- Not observed in this run (no validation logs in `logs/ingestion.err`, `logs/detection.err`, `logs/ui.err`; detection metrics had no `frames_dropped_total{reason="validation_failed"}` samples).

## Health/Metrics snapshots (brief)
- Ingestion (`http://127.0.0.1:8001/metrics`):
  - `frames_in_total 238`
  - `frames_out_total 0`
  - `frames_dropped_total{reason="lag"} 31`
  - `shm_write_latency_ms_count 31` / `shm_write_latency_ms_sum 28.014421463012695`
  - `/health` not exposed
- Detection (`http://127.0.0.1:8002/metrics`):
  - `frames_in_total 0`
  - `frames_out_total 0`
  - `fps_in 0` / `fps_out 0`
  - `frames_dropped_total` has no samples
  - `/health` not exposed
- UI (`http://127.0.0.1:8080/health`):
  - `{"status":"ok"}`
- UI (`http://127.0.0.1:8080/metrics`):
  - `frames_in_total 0`
  - `frames_out_total 0`
  - `shm_read_latency_ms_count 1503` / `shm_read_latency_ms_sum 116.99652671813965`
  - `fps_out 346.37539272700997`

## Notes
- Ingestion could not publish to Redis due to `MISCONF` (RDB snapshot write failure), so detection saw 0 frames.

========================================================================================================================
FILE: docs\v1_invariants.md
========================================================================================================================
V1 Invariants (Frozen)

1. Frame Format invariant

V1 يدعم Frame واحد فقط بهذه المواصفات الحصرية:

Color Space: BGR (OpenCV native)

Data Type: uint8

Layout: Packed (H × W × 3)

❌ غير مدعوم في V1:

Grayscale

Float types

Planar layout

Multi-plane

2. Failure Policy

أي اختلاف في المواصفات أعلاه = Non-Fatal Drop داخل خدمة Detection.

لا محاولة للتحويل أو الإصلاح.

3. Versioning

تغيير هذا السلوك يتطلب الانتقال إلى V2 وتغيير العقد بالكامل.

Notes

The frame contract includes explicit metadata:
- frame_color_space: bgr
- frame_dtype: uint8
- frame_channels: 3

Non-Contractual Components

The following components are explicitly excluded from v1 invariants:

DEV message Bus

Local process orchestration scripts

Changes to these do not constitute a v1 violation.

========================================================================================================================
FILE: export_project_snapshot.py
========================================================================================================================
import os, pathlib, fnmatch, sys

ROOT = pathlib.Path(".").resolve()
OUT = ROOT / "project_snapshot_after_p12.txt"

INCLUDE_EXT = {
    ".py",".toml",".md",".yml",".yaml",".ini",".cfg",".json",".env",".sh",".txt",".sql"
}
INCLUDE_FILES = {
    "pyproject.toml","requirements.txt","requirements-dev.txt","README.md",
    "docker-compose.yml","Dockerfile",".gitignore"
}
EXCLUDE_DIRS = {
    ".git","__pycache__",".pytest_cache",".mypy_cache",".ruff_cache",
    ".venv","venv","env","dist","build",".idea",".vscode","logs"
}
EXCLUDE_GLOBS = [
    "*.pyc","*.pyo","*.pyd","*.so","*.dll","*.dylib","*.png","*.jpg","*.jpeg",
    "*.mp4","*.avi","*.mov","*.mkv","*.onnx","*.pt","*.pth","*.weights",
    "*.db","*.sqlite","*.bin"
]

def should_exclude(path: pathlib.Path) -> bool:
    rel = path.relative_to(ROOT)
    parts = rel.parts
    if any(p in EXCLUDE_DIRS for p in parts):
        return True
    name = path.name
    for g in EXCLUDE_GLOBS:
        if fnmatch.fnmatch(name, g):
            return True
    return False

def is_included_file(path: pathlib.Path) -> bool:
    if path.name in INCLUDE_FILES:
        return True
    if path.suffix.lower() in INCLUDE_EXT:
        return True
    return False

# Gather files
files = []
for p in ROOT.rglob("*"):
    if p.is_dir():
        continue
    if should_exclude(p):
        continue
    if is_included_file(p):
        files.append(p)

files = sorted(files, key=lambda x: str(x.relative_to(ROOT)))

# Write snapshot
with OUT.open("w", encoding="utf-8") as f:
    f.write("### PROJECT SNAPSHOT (after P12)\n")
    f.write(f"ROOT: {ROOT}\n")
    f.write(f"FILES: {len(files)}\n\n")

    # Tree-ish listing
    f.write("### FILE LIST\n")
    for p in files:
        f.write(str(p.relative_to(ROOT)) + "\n")
    f.write("\n")

    # File contents
    f.write("### FILE CONTENTS\n\n")
    for p in files:
        rel = p.relative_to(ROOT)
        f.write("="*120 + "\n")
        f.write(f"FILE: {rel}\n")
        f.write("="*120 + "\n")
        try:
            text = p.read_text(encoding="utf-8")
        except UnicodeDecodeError:
            # fallback
            text = p.read_text(encoding="utf-8", errors="replace")
        f.write(text)
        if not text.endswith("\n"):
            f.write("\n")
        f.write("\n")

print(f"✅ Wrote snapshot to: {OUT}")

# import os
# import sys
# from pathlib import Path

# def is_binary_file(path, chunk_size=8192):
#     try:
#         with open(path, 'rb') as f:
#             chunk = f.read(chunk_size)
#         if b'\x00' in chunk:
#             return True
#         # Heuristic: try decode as utf-8, fallback to latin-1 for detection
#         try:
#             chunk.decode('utf-8')
#             return False
#         except UnicodeDecodeError:
#             return False
#     except OSError:
#         return True

# def iter_files(root):
#     for dirpath, dirnames, filenames in os.walk(root):
#         # Skip common non-code folders.
#         dirnames[:] = [d for d in dirnames if d not in {'.git', 'logs'}]
#         for name in sorted(filenames):
#             yield Path(dirpath) / name

# def write_tree(root, out):
#     root = Path(root).resolve()
#     out.write(f"PROJECT ROOT: {root}\n")
#     out.write("\nTREE:\n")
#     for path in sorted(iter_files(root)):
#         rel = path.relative_to(root)
#         out.write(str(rel).replace('\\', '/') + "\n")
#     out.write("\n")

# def write_contents(root, out):
#     root = Path(root).resolve()
#     out.write("FILES:\n")
#     for path in sorted(iter_files(root)):
#         rel = path.relative_to(root)
#         out.write("=" * 80 + "\n")
#         out.write(f"FILE: {str(rel).replace('\\', '/')}\n")
#         out.write("=" * 80 + "\n")
#         try:
#             if is_binary_file(path):
#                 out.write("[SKIPPED: binary or unreadable]\n\n")
#                 continue
#             text = path.read_text(encoding='utf-8')
#         except UnicodeDecodeError:
#             text = path.read_text(encoding='latin-1')
#         except Exception as e:
#             out.write(f"[SKIPPED: {e}]\n\n")
#             continue
#         out.write(text)
#         if not text.endswith("\n"):
#             out.write("\n")
#         out.write("\n")

# def main():
#     root = Path(__file__).resolve().parent
#     output = root / 'project_snapshot.txt'
#     with output.open('w', encoding='utf-8', newline='\n') as out:
#         write_tree(root, out)
#         write_contents(root, out)
#     print(f"Wrote snapshot to {output}")

# if __name__ == '__main__':
#     main()

========================================================================================================================
FILE: fix_syntax_indentation.py
========================================================================================================================
import os

def fix_ingestion():
    path = "ingestion/main.py"
    with open(path, "r") as f:
        lines = f.readlines()
    
    new_lines = []
    # Ingestion needs indentation for loop body lines
    # Loop body starts roughly after "while runtime.should_continue():" and "try:"
    # In my last view, "try:" was line 227 (0-indexed 226). 
    # But I might have file version from disk which has line numbers? No I read raw.
    
    # Logic:
    # 1. Ensure "try:" (4 spaces) opens the block.
    # 2. Ensure "while" (8 spaces) is inside.
    # 3. Ensure "try:" (12 spaces) is inside while.
    # 4. Indent everything from there until "except FatalError" (which should be 12 spaces).
    
    # Actually, simpler: just read the file, identify the range, and indent.
    # Range: 228 (1-based) to 356 (1-based).
    # "state.touch_loop()" is start.
    # "metrics.adaptive_fps_current.set" is end.
    
    in_loop_body = False
    in_except_block = False
    
    for i, line in enumerate(lines):
        if "state.touch_loop()" in line and "try:" not in line:
            in_loop_body = True
        
        if "except FatalError as e:" in line:
            in_loop_body = False
            in_except_block = True
            
        if "finally:" in line and "logger.info" not in line: # Main finally
            in_except_block = False

        # Indent inner body to 16 spaces (currently 12)
        if in_loop_body:
            # Check current indent
            stripped = line.lstrip()
            if stripped:
                current_indent = len(line) - len(stripped)
                if current_indent == 12:
                    new_lines.append("    " + line)
                else:
                    new_lines.append(line) # Assume already correct or empty
            else:
                new_lines.append(line)
        # Indent inner excepts to 12 spaces (currently 8)
        elif in_except_block:
             stripped = line.lstrip()
             if stripped:
                current_indent = len(line) - len(stripped)
                if current_indent == 8:
                    new_lines.append("    " + line)
                else:
                     new_lines.append(line)
             else:
                new_lines.append(line)
        else:
            # Fix the outer structure
            if "while runtime.should_continue():" in line:
                # Ensure while is at 8 spaces
                new_lines.append("        while runtime.should_continue():\n")
            elif "try:" in line and "import" not in line:
                # Identify which try
                # If it's the one before while...
                if i < 227 and i > 220: # Rough check
                    new_lines.append("    try:\n")
                # If it's the one inside while...
                elif i > 225 and i < 230:
                     new_lines.append("            try:\n")
                else:
                    new_lines.append(line)
            else:
                new_lines.append(line)

    with open(path, "w") as f:
        f.writelines(new_lines)
    print(f"Fixed {path}")

def fix_detection():
    path = "detection/main.py"
    with open(path, "r") as f:
        lines = f.readlines()
        
    new_lines = []
    # Detection: Revert "for" to "try...for" and add valid close
    # Current state: "        for frame_contract in consumer:" (8 spaces)
    # Body: 16 spaces (mostly)
    # We want:
    # "        try:"
    # "            for..." (12 spaces)
    # Body (16 spaces) - this matches!
    # Ending: add "        finally: pass" before "    except FatalError:"
    
    for i, line in enumerate(lines):
        if "for frame_contract in consumer:" in line:
            new_lines.append("        try:\n")
            new_lines.append("            for frame_contract in consumer:\n")
        elif "except FatalError:" in line and "as e" not in line:
            # This is the outer except (line 261 approx)
            # We need to close the inner try (8 spaces) before this (4 spaces)
            new_lines.append("        finally:\n")
            new_lines.append("            pass\n")
            new_lines.append(line)
        else:
            new_lines.append(line)
            
    with open(path, "w") as f:
        f.writelines(new_lines)
    print(f"Fixed {path}")

if __name__ == "__main__":
    fix_ingestion()
    fix_detection()

========================================================================================================================
FILE: infrastructure\bus.py
========================================================================================================================
# ------------------------------------------------------------------------------
# FILE: infrastructure/bus.py
# ------------------------------------------------------------------------------
import socket
import threading

# ==============================================================================
# DEV-ONLY MESSAGE BUS
#
# ⚠️ This Bus is NOT part of v1 architecture invariants.
# It is non-contractual infrastructure used for local development only.
# Any changes here do NOT affect Frozen v1 guarantees.
# ==============================================================================

class SimpleBus:
    """
    TCP Message Broker بسيط جداً لمرحلة التطوير.
    """
    def __init__(self, host='0.0.0.0', port=5555):
        self.server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.server.bind((host, port))
        self.server.listen(5)
        self.clients = []
        self.running = True
        try:
            from ivis_logging import setup_logging
            self.logger = setup_logging("bus")
        except Exception:
            import logging
            self.logger = logging.getLogger("bus")
        self.logger.info("[BUS] Listening on %s:%s", host, port)

    def broadcast(self, sender_socket, message):
        for client in self.clients:
            if client != sender_socket:
                try:
                    client.sendall(message)
                except:
                    self.remove(client)

    def remove(self, connection):
        if connection in self.clients:
            self.clients.remove(connection)

    def handle_client(self, conn, addr):
        self.logger.info("[BUS] New connection: %s", addr)
        self.clients.append(conn)
        while self.running:
            try:
                data = conn.recv(4096)
                if not data:
                    break
                self.broadcast(conn, data)
            except:
                break
        self.remove(conn)
        conn.close()

    def start(self):
        while self.running:
            try:
                conn, addr = self.server.accept()
                thread = threading.Thread(target=self.handle_client, args=(conn, addr))
                thread.daemon = True
                thread.start()
            except KeyboardInterrupt:
                self.stop()
                break

    def stop(self):
        self.running = False
        self.server.close()
        self.logger.info("[BUS] Stopped")

if __name__ == "__main__":
    bus = SimpleBus()
    bus.start()

========================================================================================================================
FILE: infrastructure\bus_zmq.py
========================================================================================================================
# ------------------------------------------------------------------------------
# FILE: infrastructure/bus_zmq.py
# ------------------------------------------------------------------------------
import os
import sys

from ivis_logging import setup_logging


def main():
    logger = setup_logging("bus")
    try:
        import zmq
    except Exception as exc:
        logger.error("Missing ZeroMQ dependency: %s", exc)
        sys.exit(1)

    xsub_endpoint = os.getenv("ZMQ_XSUB_ENDPOINT", "tcp://*:5555")
    xpub_endpoint = os.getenv("ZMQ_XPUB_ENDPOINT", "tcp://*:5556")

    ctx = zmq.Context.instance()
    xsub = ctx.socket(zmq.XSUB)
    xsub.bind(xsub_endpoint)
    xpub = ctx.socket(zmq.XPUB)
    xpub.bind(xpub_endpoint)

    logger.info("[BUS-ZMQ] XSUB %s | XPUB %s", xsub_endpoint, xpub_endpoint)
    try:
        zmq.proxy(xsub, xpub)
    except KeyboardInterrupt:
        logger.info("[BUS-ZMQ] Stopped")
    finally:
        xsub.close(0)
        xpub.close(0)
        ctx.term()


if __name__ == "__main__":
    main()

========================================================================================================================
FILE: ingestion\__init__.py
========================================================================================================================


========================================================================================================================
FILE: ingestion\capture\__init__.py
========================================================================================================================


========================================================================================================================
FILE: ingestion\capture\decoder.py
========================================================================================================================
# FILE: ingestion/capture/decoder.py
# ------------------------------------------------------------------------------
class Decoder:
    def decode(self, packet):
        if packet is None or packet.payload is None:
            return None
        if packet.payload.size == 0:
            return None
        return packet.payload

========================================================================================================================
FILE: ingestion\capture\frozen.py
========================================================================================================================
# FILE: ingestion/capture/frozen.py
# ------------------------------------------------------------------------------
from typing import Optional, Union

from ivis.common.time_utils import monotonic_ms


class FrozenStreamDetector:
    def __init__(
        self,
        no_frame_timeout_sec: float,
        repeat_hash_count: int,
        pts_stuck_count: int,
        timestamp_stuck_count: int,
    ):
        self.no_frame_timeout_ms = max(0.0, float(no_frame_timeout_sec)) * 1000.0
        self.repeat_hash_count = max(0, int(repeat_hash_count))
        self.pts_stuck_count = max(0, int(pts_stuck_count))
        self.timestamp_stuck_count = max(0, int(timestamp_stuck_count))
        self.reset()

    def reset(self) -> None:
        self.last_frame_mono = None
        self.last_hash = None
        self.repeat_hash_runs = 0
        self.last_pts = None
        self.pts_stuck_runs = 0
        self.last_timestamp_ms = None
        self.timestamp_stuck_runs = 0

    def note_frame(
        self,
        pts: Optional[Union[float, int]],
        timestamp_ms: Optional[int],
        fingerprint: Optional[str],
        mono_ms: Optional[int],
    ) -> None:
        self.last_frame_mono = int(mono_ms) if mono_ms is not None else monotonic_ms()

        if fingerprint:
            if self.last_hash == fingerprint:
                self.repeat_hash_runs += 1
            else:
                self.repeat_hash_runs = 0
                self.last_hash = fingerprint

        if pts is not None:
            if self.last_pts is not None and pts <= self.last_pts:
                self.pts_stuck_runs += 1
            else:
                self.pts_stuck_runs = 0
                self.last_pts = pts

        if timestamp_ms is not None:
            if self.last_timestamp_ms is not None and timestamp_ms <= self.last_timestamp_ms:
                self.timestamp_stuck_runs += 1
            else:
                self.timestamp_stuck_runs = 0
                self.last_timestamp_ms = timestamp_ms

    def check(self, now_mono_ms: Optional[int] = None) -> Optional[str]:
        now = int(now_mono_ms) if now_mono_ms is not None else monotonic_ms()
        if self.last_frame_mono is not None and self.no_frame_timeout_ms > 0:
            if (now - self.last_frame_mono) > self.no_frame_timeout_ms:
                return "no_frames"
        if self.repeat_hash_count and self.repeat_hash_runs >= self.repeat_hash_count:
            return "repeat_hash"
        if self.pts_stuck_count and self.pts_stuck_runs >= self.pts_stuck_count:
            return "pts_stuck"
        if self.timestamp_stuck_count and self.timestamp_stuck_runs >= self.timestamp_stuck_count:
            return "timestamp_stuck"
        return None

========================================================================================================================
FILE: ingestion\capture\reader.py
========================================================================================================================
# FILE: ingestion/capture/reader.py
# ------------------------------------------------------------------------------
import cv2

from ivis.common.time_utils import monotonic_ms, wall_clock_ms

class FramePacket:
    def __init__(self, payload, pts, timestamp_ms, mono_ms):
        self.payload = payload
        self.pts = pts
        self.timestamp_ms = timestamp_ms
        self.mono_ms = mono_ms

class Reader:
    def __init__(self, rtsp_client):
        self.client = rtsp_client
        self._last_pts = 0.0

    def next_packet(self):
        cap = self.client.get_raw_handle()
        try:
            ret, raw_data = cap.read()
        except Exception:
            return None
        
        if not ret:
            return None

        wall_clock = wall_clock_ms()
        mono_clock = monotonic_ms()
        pts_ms = cap.get(cv2.CAP_PROP_POS_MSEC)
        if pts_ms <= 0:
            pts_ms = wall_clock
        if pts_ms <= 0:
            pts_ms = self._last_pts + 1.0
        self._last_pts = pts_ms
        
        return FramePacket(payload=raw_data, pts=pts_ms, timestamp_ms=wall_clock, mono_ms=mono_clock)

========================================================================================================================
FILE: ingestion\capture\reconnect.py
========================================================================================================================
# FILE: ingestion/capture/reconnect.py
# ------------------------------------------------------------------------------
import random
import time
from typing import Optional


class ReconnectController:
    def __init__(
        self,
        min_delay: float,
        max_delay: float,
        factor: float = 2.0,
        jitter: float = 0.1,
        max_retries: int = 0,
    ):
        self.min_delay = max(0.0, float(min_delay))
        self.max_delay = max(self.min_delay, float(max_delay))
        self.factor = max(1.0, float(factor))
        self.jitter = max(0.0, float(jitter))
        self.max_retries = int(max_retries)
        self._attempts = 0

    def reset(self) -> None:
        self._attempts = 0

    @property
    def attempts(self) -> int:
        return self._attempts

    def _next_delay(self) -> Optional[float]:
        if self.max_retries > 0 and self._attempts >= self.max_retries:
            return None
        base = self.min_delay * (self.factor ** self._attempts)
        base = min(self.max_delay, base)
        self._attempts += 1
        if self.jitter:
            base += random.uniform(-self.jitter, self.jitter) * base
        return max(0.0, base)

    def wait(self) -> Optional[float]:
        delay = self._next_delay()
        if delay is None:
            return None
        time.sleep(delay)
        return delay

========================================================================================================================
FILE: ingestion\capture\rtsp_client.py
========================================================================================================================
# FILE: ingestion/capture/rtsp_client.py
# ------------------------------------------------------------------------------
import os
import cv2
from ingestion.errors.fatal import FatalError  # ✅ FIX: Missing Import Added

class RTSPClient:
    def __init__(self, url):
        self.url = url
        self.cap = None
        self.is_file = False
        self.last_error = None

    def connect(self):
        try:
            url_int = int(self.url)
            self.cap = cv2.VideoCapture(url_int)
            self.is_file = False
        except ValueError:
            self.cap = cv2.VideoCapture(self.url)
            self.is_file = os.path.isfile(self.url)
        
        if not self.cap.isOpened():
            self.last_error = "open_failed"
            raise FatalError("Failed to open RTSP stream", context={"url": self.url})
        
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 0)
        self.last_error = None
    
    def get_raw_handle(self):
        if not self.cap:
            raise FatalError("Client not connected")
        return self.cap

    def close(self):
        if self.cap:
            self.cap.release()
            self.cap = None

    def reconnect(self) -> bool:
        self.close()
        try:
            self.connect()
            return True
        except FatalError:
            return False

    def rewind(self):
        if self.cap and self.is_file:
            self.cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            self.cap.set(cv2.CAP_PROP_POS_MSEC, 0)

# ---------

========================================================================================================================
FILE: ingestion\config.py
========================================================================================================================
# ------------------------------------------------------------------------------
# FILE: ingestion/config.py
# ------------------------------------------------------------------------------
import os

from ivis.common.config.base import ConfigLoadError, EnvLoader, redact_config
from ingestion.errors.fatal import ConfigError


class Config:
    def __init__(self):
        schema = {
            "RTSP_URL": {"type": "str", "required": True},
            "STREAM_ID": {"type": "str", "required": True},
            "CAMERA_ID": {"type": "str", "required": True},
            "TARGET_FPS": {"type": "int", "required": True},
            "FRAME_WIDTH": {"type": "int", "required": True},
            "FRAME_HEIGHT": {"type": "int", "required": True},
            "MEMORY_BACKEND": {"type": "str", "required": True},
            "BUS_TRANSPORT": {"type": "str", "default": "zmq"},
            "ZMQ_PUB_ENDPOINT": {"type": "str", "default": "tcp://localhost:5555"},
            "ZMQ_RESULTS_SUB_ENDPOINT": {"type": "str", "default": "tcp://localhost:5557"},
            # SOURCE_COLOR is the color of the raw source (camera/file). Ingestion
            # will convert from SOURCE_COLOR -> FRAME_COLOR_SPACE for downstream.
            "SOURCE_COLOR": {"type": "str", "default": None},
            "FRAME_COLOR": {"type": "str", "default": "bgr"},
            "SHM_NAME": {"type": "str", "default": "ivis_shm_data"},
            "SHM_META_NAME": {"type": "str", "default": "ivis_shm_meta"},
            "SHM_BUFFER_BYTES": {"type": "int", "default": 50000000},
            "SHM_CACHE_SECONDS": {"type": "float", "default": 30.0},
            "SELECTOR_MODE": {"type": "str", "default": "clock"},
            "ADAPTIVE_FPS": {"type": "bool", "default": False},
            "ADAPTIVE_MIN_FPS": {"type": "float", "default": 5},
            "ADAPTIVE_MAX_FPS": {"type": "float", "default": None},
            "ADAPTIVE_SAFETY": {"type": "float", "default": 1.3},
            "VIDEO_LOOP": {"type": "bool", "default": False},
            "RTSP_MAX_RETRIES": {"type": "int", "default": 0},
            "RTSP_RETRY_BACKOFF_SEC": {"type": "float", "default": 1.0},
            "RTSP_RECONNECT_MIN_SEC": {"type": "float", "default": 0.5},
            "RTSP_RECONNECT_MAX_SEC": {"type": "float", "default": 30.0},
            "RTSP_RECONNECT_FACTOR": {"type": "float", "default": 2.0},
            "RTSP_RECONNECT_JITTER": {"type": "float", "default": 0.2},
            "RTSP_FROZEN_TIMEOUT_SEC": {"type": "float", "default": 30.0},
            "RTSP_FROZEN_HASH_COUNT": {"type": "int", "default": 300},
            "RTSP_FROZEN_PTS_COUNT": {"type": "int", "default": 30},
            "RTSP_FROZEN_TIMESTAMP_COUNT": {"type": "int", "default": 30},
            "HEALTH_INTERVAL_SEC": {"type": "float", "default": 5.0},
            "ADAPTIVE_LAG_THRESHOLD": {"type": "int", "default": 2000},
            "ADAPTIVE_LAG_HYSTERESIS": {"type": "float", "default": 0.2},
            "ROI_BOXES": {"type": "str", "default": None},
            "ROI_POLYGONS": {"type": "str", "default": None},
            "RECORD_BUFFER_SECONDS": {"type": "float", "default": 0},
            "RECORD_JPEG_QUALITY": {"type": "int", "default": 85},
            "RECORD_BUFFER_MAX_FRAMES": {"type": "int", "default": None},
        }
        loader = EnvLoader()
        try:
            values = loader.load(schema)
        except ConfigLoadError as exc:
            raise ConfigError("Invalid config", context={"error": str(exc)}) from exc
        self._values = values

        self.rtsp_url = values["RTSP_URL"]
        self.stream_id = values["STREAM_ID"]
        self.camera_id = values["CAMERA_ID"]
        self.target_fps = values["TARGET_FPS"]

        self.frame_width = values["FRAME_WIDTH"]
        self.frame_height = values["FRAME_HEIGHT"]

        self.memory_backend = values["MEMORY_BACKEND"]
        self.bus_transport = values["BUS_TRANSPORT"]
        self.zmq_pub_endpoint = values["ZMQ_PUB_ENDPOINT"]
        self.zmq_results_sub_endpoint = values["ZMQ_RESULTS_SUB_ENDPOINT"]
        # Prefer SOURCE_COLOR (new); fall back to FRAME_COLOR legacy variable.
        src_col = values.get("SOURCE_COLOR")
        if src_col:
            src = src_col.lower()
        else:
            # migration from legacy FRAME_COLOR
            src = values["FRAME_COLOR"].lower() if values.get("FRAME_COLOR") else "bgr"
            if os.getenv("FRAME_COLOR"):
                import warnings

                warnings.warn(
                    "Environment variable FRAME_COLOR is deprecated; mapped to SOURCE_COLOR for ingestion.",
                    DeprecationWarning,
                )

        if src not in ("bgr", "rgb"):
            src = "bgr"
        self.frame_color = src
        self.shm_name = values["SHM_NAME"]
        self.shm_meta_name = values["SHM_META_NAME"]
        self.shm_buffer_bytes = values["SHM_BUFFER_BYTES"]
        self.shm_cache_seconds = values["SHM_CACHE_SECONDS"]
        if os.getenv("SHM_BUFFER_BYTES") is None and self.shm_cache_seconds > 0:
            slot_size = self.frame_width * self.frame_height * 3
            slots = max(1, int(self.target_fps * self.shm_cache_seconds))
            self.shm_buffer_bytes = slot_size * slots
        self.selector_mode = values["SELECTOR_MODE"].lower()
        self.adaptive_fps = values["ADAPTIVE_FPS"]
        self.adaptive_min_fps = values["ADAPTIVE_MIN_FPS"]
        self.adaptive_max_fps = values["ADAPTIVE_MAX_FPS"] or float(self.target_fps)
        self.adaptive_safety = values["ADAPTIVE_SAFETY"]
        self.video_loop = values["VIDEO_LOOP"]
        self.rtsp_max_retries = values["RTSP_MAX_RETRIES"]
        self.rtsp_retry_backoff_sec = values["RTSP_RETRY_BACKOFF_SEC"]
        if os.getenv("RTSP_RECONNECT_MIN_SEC") is None:
            self.rtsp_reconnect_min_sec = self.rtsp_retry_backoff_sec
        else:
            self.rtsp_reconnect_min_sec = values["RTSP_RECONNECT_MIN_SEC"]
        if os.getenv("RTSP_RECONNECT_MAX_SEC") is None:
            self.rtsp_reconnect_max_sec = max(self.rtsp_reconnect_min_sec, self.rtsp_retry_backoff_sec * 10.0)
        else:
            self.rtsp_reconnect_max_sec = values["RTSP_RECONNECT_MAX_SEC"]
        self.rtsp_reconnect_factor = values["RTSP_RECONNECT_FACTOR"]
        self.rtsp_reconnect_jitter = values["RTSP_RECONNECT_JITTER"]
        self.rtsp_frozen_timeout_sec = values["RTSP_FROZEN_TIMEOUT_SEC"]
        self.rtsp_frozen_hash_count = values["RTSP_FROZEN_HASH_COUNT"]
        self.rtsp_frozen_pts_count = values["RTSP_FROZEN_PTS_COUNT"]
        self.rtsp_frozen_timestamp_count = values["RTSP_FROZEN_TIMESTAMP_COUNT"]
        self.health_interval_sec = values["HEALTH_INTERVAL_SEC"]
        self.adaptive_lag_threshold = values["ADAPTIVE_LAG_THRESHOLD"]
        self.adaptive_lag_hysteresis = values["ADAPTIVE_LAG_HYSTERESIS"]
        self.roi_boxes = values["ROI_BOXES"]
        self.roi_polygons = values["ROI_POLYGONS"]
        self.record_buffer_seconds = values["RECORD_BUFFER_SECONDS"]
        self.record_jpeg_quality = values["RECORD_JPEG_QUALITY"]
        self.record_buffer_max_frames = values["RECORD_BUFFER_MAX_FRAMES"]

        self._validate()

    def _validate(self):
        if self.target_fps <= 0:
            raise ConfigError("Invalid TARGET_FPS", context={"value": self.target_fps})
        if self.frame_width <= 0 or self.frame_height <= 0:
            raise ConfigError("Invalid resolution", context={"w": self.frame_width, "h": self.frame_height})
        if self.memory_backend not in ("shm",):
            raise ConfigError("Unsupported MEMORY_BACKEND", context={"value": self.memory_backend})
        if self.shm_buffer_bytes <= 0:
            raise ConfigError("Invalid SHM_BUFFER_BYTES", context={"value": self.shm_buffer_bytes})
        if self.selector_mode not in ("clock", "pts"):
            raise ConfigError("Invalid SELECTOR_MODE", context={"value": self.selector_mode})
        if self.shm_cache_seconds < 0:
            raise ConfigError("Invalid SHM_CACHE_SECONDS", context={"value": self.shm_cache_seconds})
        if self.rtsp_max_retries < 0:
            raise ConfigError("Invalid RTSP_MAX_RETRIES", context={"value": self.rtsp_max_retries})
        if self.rtsp_retry_backoff_sec < 0:
            raise ConfigError("Invalid RTSP_RETRY_BACKOFF_SEC", context={"value": self.rtsp_retry_backoff_sec})
        if self.rtsp_reconnect_min_sec < 0 or self.rtsp_reconnect_max_sec < 0:
            raise ConfigError("Invalid RTSP_RECONNECT_MIN_SEC/RTSP_RECONNECT_MAX_SEC")
        if self.rtsp_reconnect_factor < 1.0:
            raise ConfigError("Invalid RTSP_RECONNECT_FACTOR", context={"value": self.rtsp_reconnect_factor})
        if self.rtsp_reconnect_jitter < 0:
            raise ConfigError("Invalid RTSP_RECONNECT_JITTER", context={"value": self.rtsp_reconnect_jitter})
        if self.rtsp_frozen_timeout_sec < 0:
            raise ConfigError("Invalid RTSP_FROZEN_TIMEOUT_SEC", context={"value": self.rtsp_frozen_timeout_sec})
        if self.health_interval_sec <= 0:
            raise ConfigError("Invalid HEALTH_INTERVAL_SEC", context={"value": self.health_interval_sec})
        if self.adaptive_lag_threshold < 0:
            raise ConfigError("Invalid ADAPTIVE_LAG_THRESHOLD", context={"value": self.adaptive_lag_threshold})
        if self.adaptive_lag_hysteresis < 0:
            raise ConfigError("Invalid ADAPTIVE_LAG_HYSTERESIS", context={"value": self.adaptive_lag_hysteresis})
        if self.record_buffer_seconds < 0:
            raise ConfigError("Invalid RECORD_BUFFER_SECONDS", context={"value": self.record_buffer_seconds})
        if self.record_jpeg_quality <= 0 or self.record_jpeg_quality > 100:
            raise ConfigError("Invalid RECORD_JPEG_QUALITY", context={"value": self.record_jpeg_quality})

    @property
    def resolution(self):
        return (self.frame_width, self.frame_height)

    def summary(self) -> dict:
        return redact_config(self._values)

========================================================================================================================
FILE: ingestion\errors\__init__.py
========================================================================================================================


========================================================================================================================
FILE: ingestion\errors\fatal.py
========================================================================================================================
# ------------------------------------------------------------------------------
# FILE: ingestion/errors/fatal.py
# ------------------------------------------------------------------------------
class FatalError(Exception):
    def __init__(self, message, context=None):
        self.message = message
        self.context = context or {}
        super().__init__(self.message)

class ConfigError(FatalError):
    pass

class MemoryWriteError(FatalError):
    pass

========================================================================================================================
FILE: ingestion\feedback\adaptive.py
========================================================================================================================
# FILE: ingestion/feedback/adaptive.py
# ------------------------------------------------------------------------------
import json
import threading
import time


class AdaptiveRateController:
    def __init__(
        self,
        selector,
        min_fps: float,
        max_fps: float,
        safety_factor: float,
        ema_alpha: float = 0.2,
        hysteresis_ratio: float = 0.1,
        min_update_interval: float = 0.5,
        fps_smoothing: float = 0.3,
    ):
        self.selector = selector
        self.min_fps = max(1.0, float(min_fps))
        self.max_fps = max(self.min_fps, float(max_fps))
        self.safety = max(1.0, float(safety_factor))
        self.ema_alpha = min(1.0, max(0.01, float(ema_alpha)))
        self.hysteresis_ratio = min(0.5, max(0.0, float(hysteresis_ratio)))
        self.min_update_interval = max(0.0, float(min_update_interval))
        self.fps_smoothing = min(1.0, max(0.0, float(fps_smoothing)))
        self._last_update = 0.0
        self._ema_ms = None
        self._last_target_fps = None
        self._lock = threading.Lock()

    def _update_from_inference(self, inference_ms: float):
        if inference_ms <= 0:
            return
        now = time.perf_counter()
        with self._lock:
            if self._ema_ms is None:
                self._ema_ms = inference_ms
            else:
                self._ema_ms = (self.ema_alpha * inference_ms) + ((1.0 - self.ema_alpha) * self._ema_ms)

            target = 1000.0 / (self._ema_ms * self.safety)
            target = max(self.min_fps, min(self.max_fps, target))

            if self._last_target_fps is not None:
                target = self._last_target_fps + (target - self._last_target_fps) * self.fps_smoothing
                delta = abs(target - self._last_target_fps)
                if delta / max(self._last_target_fps, 1e-6) < self.hysteresis_ratio:
                    return
                if (now - self._last_update) < self.min_update_interval:
                    return

            self.selector.set_target_fps(target)
            self._last_target_fps = target
            self._last_update = now

    def _run_zmq(self, endpoint: str):
        try:
            import zmq
        except Exception:
            return
        ctx = zmq.Context.instance()
        socket = ctx.socket(zmq.SUB)
        socket.connect(endpoint)
        socket.setsockopt(zmq.SUBSCRIBE, b"")
        while True:
            try:
                payload = socket.recv()
            except Exception:
                continue
            try:
                result = json.loads(payload.decode("utf-8"))
            except Exception:
                continue
            inference_ms = result.get("timing", {}).get("inference_ms")
            if inference_ms is not None:
                self._update_from_inference(float(inference_ms))

    def start(self, endpoint: str):
        if not endpoint:
            return
        thread = threading.Thread(target=self._run_zmq, args=(endpoint,), daemon=True)
        thread.start()

========================================================================================================================
FILE: ingestion\feedback\lag_controller.py
========================================================================================================================
# FILE: ingestion/feedback/lag_controller.py
# ------------------------------------------------------------------------------


class LagBasedRateController:
    def __init__(
        self,
        selector,
        min_fps: float,
        max_fps: float,
        lag_threshold: int,
        hysteresis_ratio: float = 0.2,
    ):
        self.selector = selector
        self.min_fps = max(1.0, float(min_fps))
        self.max_fps = max(self.min_fps, float(max_fps))
        self.lag_threshold = max(0, int(lag_threshold))
        self.hysteresis_ratio = max(0.0, min(0.9, float(hysteresis_ratio)))
        self._lagged = False

    def update(self, lag_value: int) -> bool:
        if self.lag_threshold <= 0:
            return False
        try:
            lag = int(lag_value)
        except (TypeError, ValueError):
            return False

        if self._lagged:
            recover_at = int(self.lag_threshold * (1.0 - self.hysteresis_ratio))
            if lag <= recover_at:
                self.selector.set_lag_cap(None)
                self._lagged = False
                return True
            self.selector.set_lag_cap(self.min_fps)
            return False

        if lag >= self.lag_threshold:
            self.selector.set_lag_cap(self.min_fps)
            self._lagged = True
            return True
        return False

========================================================================================================================
FILE: ingestion\frame\__init__.py
========================================================================================================================


========================================================================================================================
FILE: ingestion\frame\anchor.py
========================================================================================================================
# FILE: ingestion/frame/anchor.py
# ------------------------------------------------------------------------------
import cv2
import numpy as np

class Anchor:
    def generate(self, frame, frame_color: str = "bgr"):
        thumb = cv2.resize(frame, (8, 8), interpolation=cv2.INTER_NEAREST)
        color = (frame_color or "bgr").lower()
        if color == "rgb":
            gray = cv2.cvtColor(thumb, cv2.COLOR_RGB2GRAY)
        else:
            gray = cv2.cvtColor(thumb, cv2.COLOR_BGR2GRAY)
        avg = gray.mean()
        bits = (gray > avg).flatten()
        pack = np.packbits(bits)
        hex_fingerprint = pack.tobytes().hex()
        return hex_fingerprint

========================================================================================================================
FILE: ingestion\frame\id.py
========================================================================================================================
# FILE: ingestion/frame/id.py
# ------------------------------------------------------------------------------
import hashlib

class FrameIdentity:
    def __init__(self, stream_id, pts, fingerprint):
        self.stream_id = stream_id
        self.pts = pts
        self.fingerprint = fingerprint
        raw_key = f"{stream_id}_{pts:.6f}_{fingerprint}"
        self.frame_id = hashlib.md5(raw_key.encode()).hexdigest()

    def to_dict(self):
        return {
            "id": self.frame_id,
            "stream": self.stream_id,
            "pts": self.pts,
            "anchor": self.fingerprint
        }

========================================================================================================================
FILE: ingestion\frame\normalizer.py
========================================================================================================================
# FILE: ingestion/frame/normalizer.py
# ------------------------------------------------------------------------------
import cv2


class Normalizer:
    def __init__(self, target_resolution, frame_color: str = "bgr"):
        self.target_size = target_resolution
        self.input_color = frame_color

    def process(self, raw_frame):
        frame = raw_frame
        if (frame.shape[1], frame.shape[0]) != self.target_size:
            frame = cv2.resize(frame, self.target_size, interpolation=cv2.INTER_NEAREST)
        if self.input_color == "rgb":
            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
        return frame

========================================================================================================================
FILE: ingestion\frame\roi.py
========================================================================================================================
# FILE: ingestion/frame/roi.py
# ------------------------------------------------------------------------------
from typing import List, Optional, Tuple

import cv2
import numpy as np


def _parse_ints(values: List[str]) -> List[int]:
    parsed = []
    for val in values:
        if val is None:
            continue
        v = val.strip()
        if not v:
            continue
        parsed.append(int(float(v)))
    return parsed


def parse_boxes(raw: Optional[str]) -> List[Tuple[int, int, int, int]]:
    if not raw:
        return []
    boxes = []
    for part in raw.split(";"):
        nums = _parse_ints(part.split(","))
        if len(nums) != 4:
            continue
        x1, y1, x2, y2 = nums
        if x2 <= x1 or y2 <= y1:
            continue
        boxes.append((x1, y1, x2, y2))
    return boxes


def parse_polygons(raw: Optional[str]) -> List[List[Tuple[int, int]]]:
    if not raw:
        return []
    polygons = []
    for poly_raw in raw.split("|"):
        points = []
        for point_raw in poly_raw.split(";"):
            nums = _parse_ints(point_raw.split(","))
            if len(nums) != 2:
                continue
            points.append((nums[0], nums[1]))
        if len(points) >= 3:
            polygons.append(points)
    return polygons


def build_mask(width: int, height: int, boxes, polygons):
    if not boxes and not polygons:
        return None
    mask = np.zeros((height, width), dtype=np.uint8)
    for x1, y1, x2, y2 in boxes:
        cv2.rectangle(mask, (x1, y1), (x2, y2), 255, thickness=-1)
    for polygon in polygons:
        pts = np.array(polygon, dtype=np.int32)
        cv2.fillPoly(mask, [pts], 255)
    return mask


def apply_mask(frame, mask):
    if mask is None:
        return frame
    return cv2.bitwise_and(frame, frame, mask=mask)

========================================================================================================================
FILE: ingestion\frame\selector.py
========================================================================================================================
# FILE: ingestion/frame/selector.py
# ------------------------------------------------------------------------------
import time
from typing import Optional


class Selector:
    def __init__(self, target_fps, mode: str = "clock"):
        self._base_target_fps = max(1.0, float(target_fps))
        self._lag_cap_fps = None
        self.target_fps = self._base_target_fps
        self.frame_duration_ms = (1.0 / self.target_fps) * 1000.0
        self.last_pts = -1.0
        self.last_emit_ms = -1.0
        self.mode = mode

    def allow(self, pts):
        if self.mode == "pts" and pts > 0:
            if self.last_pts < 0:
                self.last_pts = pts
                return True
            if pts <= self.last_pts:
                return False
            delta = pts - self.last_pts
            if delta >= self.frame_duration_ms:
                self.last_pts = pts
                return True
            return False

        now_ms = time.perf_counter() * 1000.0
        if self.last_emit_ms < 0:
            self.last_emit_ms = now_ms
            return True
        if (now_ms - self.last_emit_ms) >= self.frame_duration_ms:
            self.last_emit_ms = now_ms
            if pts > 0:
                self.last_pts = pts
            return True
        return False

    def set_target_fps(self, fps: float):
        if fps <= 0:
            return
        self._base_target_fps = float(fps)
        self._apply_effective_fps()

    def set_lag_cap(self, fps: Optional[float]):
        if fps is None:
            self._lag_cap_fps = None
        else:
            self._lag_cap_fps = max(1.0, float(fps))
        self._apply_effective_fps()

    def _apply_effective_fps(self) -> None:
        effective = self._base_target_fps
        if self._lag_cap_fps is not None:
            effective = min(effective, self._lag_cap_fps)
        effective = max(1.0, float(effective))
        self.target_fps = effective
        self.frame_duration_ms = (1.0 / effective) * 1000.0

========================================================================================================================
FILE: ingestion\heartbeat.py
========================================================================================================================
import time
from typing import Optional

from ivis_logging import setup_logging

logger = setup_logging("ingestion")


class Heartbeat:
    def __init__(self, stream_id, camera_id=None, interval_sec=5.0):
        self.stream_id = stream_id
        self.camera_id = camera_id
        self.last_beat = 0
        self.interval = max(0.5, float(interval_sec))

    def tick(self, status: str = "ok", reason: Optional[str] = None):
        now = time.time()
        if now - self.last_beat > self.interval:
            logger.info(
                "ingestion.heartbeat",
                extra={
                    "stream_id": self.stream_id,
                    "camera_id": self.camera_id,
                    "status": status,
                    "reason": reason,
                },
            )
            self.last_beat = now

========================================================================================================================
FILE: ingestion\ipc.py
========================================================================================================================
# FILE: ingestion/ipc.py
# ------------------------------------------------------------------------------
import json
import socket
import logging

from ingestion.memory.ref import MemoryReference
from ivis.common.contracts.frame_contract import FrameContractV1, FrameMemoryRef
import ivis_metrics


_logger = logging.getLogger("ingestion")
_warned = set()


def _log_once(key: str, message: str, exc: Exception = None) -> None:
    if key in _warned:
        return
    _warned.add(key)
    if exc is not None:
        _logger.warning("%s: %s", message, exc)
    else:
        _logger.warning("%s", message)


def _record_issue(reason: str, message: str, exc: Exception = None) -> None:
    _log_once(reason, message, exc)
    try:
        ivis_metrics.service_errors_total.labels(service="ingestion", reason=reason).inc()
    except Exception as metric_exc:
        _log_once(f"{reason}_metric", "Failed to record service error metric", metric_exc)


class SocketPublisher:
    """
    TCP publisher (legacy).
    """

    def __init__(self, config, host="localhost", port=5555):
        self.stream_id = config.stream_id
        self.camera_id = config.camera_id
        self.frame_width = config.frame_width
        self.frame_height = config.frame_height
        self.frame_color = config.frame_color
        self.address = (host, port)
        self.sock = None
        self._connect()

    def _connect(self):
        try:
            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.sock.connect(self.address)
        except (OSError, ConnectionError) as exc:
            _record_issue("socket_connect_failed", "Socket connect failed", exc)
            self.sock = None

    def publish(self, frame_identity, packet_timestamp_ms, packet_mono_ms, memory_ref, roi_meta=None):
        gen = getattr(memory_ref, "generation", 0)
        contract = _build_contract(
            self.stream_id,
            self.camera_id,
            frame_identity,
            packet_timestamp_ms,
            packet_mono_ms,
            memory_ref,
            gen,
            self.frame_width,
            self.frame_height,
            self.frame_color,
            roi_meta=roi_meta,
        )
        payload = json.dumps(contract) + "\n"

        if self.sock:
            try:
                self.sock.sendall(payload.encode())
                return True
            except (OSError, ConnectionError) as exc:
                _record_issue("socket_send_failed", "Socket send failed", exc)
                _logger.warning("[PUB] Transport lost. Dropping msg.")
                self.sock.close()
                self._connect()
                return False
        self._connect()
        return False

    def close(self):
        if self.sock:
            try:
                self.sock.close()
            except Exception as exc:
                _logger.debug("Error closing socket: %s", exc)
            self.sock = None


class ZmqPublisher:
    def __init__(self, config, endpoint: str):
        try:
            import zmq
        except Exception as exc:
            raise RuntimeError(f"Missing ZeroMQ dependency: {exc}") from exc

        self.stream_id = config.stream_id
        self.camera_id = config.camera_id
        self.frame_width = config.frame_width
        self.frame_height = config.frame_height
        self.frame_color = config.frame_color
        self.endpoint = endpoint
        self.zmq = zmq
        self.socket = self.zmq.Context.instance().socket(self.zmq.PUB)
        self.socket.bind(self.endpoint)

    def publish(self, frame_identity, packet_timestamp_ms, packet_mono_ms, memory_ref, roi_meta=None):
        gen = getattr(memory_ref, "generation", 0)
        contract = _build_contract(
            self.stream_id,
            self.camera_id,
            frame_identity,
            packet_timestamp_ms,
            packet_mono_ms,
            memory_ref,
            gen,
            self.frame_width,
            self.frame_height,
            self.frame_color,
            roi_meta=roi_meta,
        )
        payload = json.dumps(contract).encode("utf-8")
        try:
            self.socket.send(payload)
            return True
        except Exception as exc:
            _record_issue("zmq_send_failed", "ZMQ send failed", exc)
            return False

    def close(self):
        if self.socket:
            try:
                self.socket.close()
            except Exception as exc:
                _logger.debug("Error closing socket: %s", exc)
            self.socket = None


def _build_contract(
    stream_id,
    camera_id,
    frame_identity,
    packet_timestamp_ms,
    packet_mono_ms,
    memory_ref,
    gen,
    frame_width,
    frame_height,
    frame_color,
    roi_meta=None,
):
    backend = getattr(memory_ref, "backend_type", "shm_ring_v1")
    memory = FrameMemoryRef(
        backend=backend,
        key=memory_ref.location,
        size=memory_ref.size,
        generation=gen,
    )
    output_color = "bgr"
    contract = FrameContractV1(
        contract_version=1,
        frame_id=frame_identity.frame_id,
        stream_id=stream_id,
        camera_id=camera_id,
        pts=frame_identity.pts,
        timestamp_ms=packet_timestamp_ms,
        mono_ms=packet_mono_ms,
        memory=memory,
        frame_width=frame_width,
        frame_height=frame_height,
        frame_channels=3,
        frame_dtype="uint8",
        frame_color_space=output_color,
    )
    payload = contract.to_dict()
    if roi_meta:
        payload["roi"] = roi_meta
    return payload


def get_publisher(config):
    transport = getattr(config, "bus_transport", "zmq").lower()
    if transport == "zmq":
        try:
            from ivis.legacy.ingestion_ipc_legacy import ZmqPublisher as LegacyZmqPublisher

            return LegacyZmqPublisher(config, getattr(config, "zmq_pub_endpoint", "tcp://localhost:5555"))
        except Exception as exc:
            _record_issue("legacy_zmq_import_failed", "Legacy ZMQ publisher import failed; falling back", exc)
            # fallback to module-local ZmqPublisher if legacy package missing
            return ZmqPublisher(config, getattr(config, "zmq_pub_endpoint", "tcp://localhost:5555"))
    # Legacy TCP publisher (socket) - co-locate under ivis.legacy when used.
    try:
        from ivis.legacy.ingestion_ipc_legacy import SocketPublisher as LegacySocketPublisher

        return LegacySocketPublisher(config)
    except Exception as exc:
        _record_issue("legacy_socket_import_failed", "Legacy Socket publisher import failed; falling back", exc)
        return SocketPublisher(config)

========================================================================================================================
FILE: ingestion\main.py
========================================================================================================================
# FILE: ingestion/main.py
# ------------------------------------------------------------------------------
import sys
import os
import time

from ivis_logging import setup_logging

logger = setup_logging("ingestion")
import ivis_metrics
import ivis_tracing
from ivis.common.time_utils import latency_ms, wall_clock_ms, monotonic_ms
from ivis_health import ServiceState, HealthServer

from ingestion.capture.decoder import Decoder
from ingestion.capture.frozen import FrozenStreamDetector
from ingestion.capture.reader import Reader
from ingestion.capture.reconnect import ReconnectController
from ingestion.capture.rtsp_client import RTSPClient
from ingestion.config import Config
from ingestion.errors.fatal import ConfigError, FatalError
from ingestion.frame.anchor import Anchor
from ingestion.frame.id import FrameIdentity
from ingestion.frame.normalizer import Normalizer
from ingestion.frame.roi import apply_mask, build_mask, parse_boxes, parse_polygons
from ingestion.frame.selector import Selector
from ingestion.heartbeat import Heartbeat
from ingestion.memory.writer import Writer
from ingestion.metrics.counters import Metrics
from ingestion.recording.buffer import RecordingBuffer
from ingestion.runtime import Runtime
from ingestion.feedback.adaptive import AdaptiveRateController

from ingestion.memory.shm_backend import ShmRingBackend

try:
    from ingestion.ipc import get_publisher
    IPC_AVAILABLE = True
except ImportError:
    IPC_AVAILABLE = False

_warned = set()


def _log_once(key: str, message: str, exc: Exception = None) -> None:
    if key in _warned:
        return
    _warned.add(key)
    if exc is not None:
        logger.warning("%s: %s", message, exc)
    else:
        logger.warning("%s", message)


def _record_issue(reason: str, message: str, exc: Exception = None) -> None:
    _log_once(reason, message, exc)
    try:
        ivis_metrics.service_errors_total.labels(service="ingestion", reason=reason).inc()
    except Exception as metric_exc:
        _log_once(f"{reason}_metric", "Failed to record service error metric", metric_exc)


def _safe_metric(reason: str, fn) -> None:
    try:
        fn()
    except Exception as exc:
        _record_issue(reason, "Metrics update failed", exc)

def main():
    logger.info(">>> Ingestion Service: Initializing (Frozen v1.0) <<<")
    
    try:
        conf = Config()
    except ConfigError as e:
        logger.error("FATAL: Config Error - %s", getattr(e, 'message', str(e)))
        sys.exit(1)
    logger.info("Config summary: %s", conf.summary())

    health_host = os.getenv("HEALTH_BIND", "127.0.0.1")
    health_port = int(os.getenv("INGESTION_HEALTH_PORT", "9001"))
    state = ServiceState("ingestion")
    HealthServer(state, host=health_host, port=health_port).start_in_thread()
    state.set_check("config_loaded", True, details={"stream_id": conf.stream_id, "camera_id": conf.camera_id})

    runtime = Runtime()
    metrics = Metrics()
    # initialize tracing (best-effort)
    try:
        ivis_tracing.init_tracer(service_name=os.getenv("OTEL_SERVICE_NAME", "ingestion"))
    except Exception as exc:
        _record_issue("tracing_init_failed", "Tracing init failed", exc)
    # Start prometheus metrics server for ingestion
    try:
        port = int(os.getenv("INGESTION_METRICS_PORT", "8001"))
        ivis_metrics.start_metrics_http_server(port)
        logger.info("Prometheus metrics HTTP server started on port %s", port)
    except Exception as exc:
        _record_issue("metrics_server_failed", "Failed to start metrics server", exc)
    
    try:
        rtsp = RTSPClient(conf.rtsp_url)
        reader = Reader(rtsp)
        decoder = Decoder()
        selector = Selector(conf.target_fps, mode=conf.selector_mode)
        normalizer = Normalizer(conf.resolution, frame_color=conf.frame_color)
        anchor = Anchor()

        roi_boxes = parse_boxes(conf.roi_boxes)
        roi_polygons = parse_polygons(conf.roi_polygons)
        roi_mask = build_mask(conf.frame_width, conf.frame_height, roi_boxes, roi_polygons)
        roi_meta = None
        if roi_mask is not None:
            roi_meta = {}
            if roi_boxes:
                roi_meta["boxes"] = roi_boxes
            if roi_polygons:
                roi_meta["polygons"] = roi_polygons
            logger.info("ROI enabled (boxes=%s, polygons=%s).", len(roi_boxes), len(roi_polygons))
        
        # --- Backend Selection (Strict) ---
        if conf.memory_backend == "shm":
            slot_size = conf.frame_width * conf.frame_height * 3
            if conf.shm_cache_seconds and conf.shm_cache_seconds > 0:
                slot_count = max(1, int(conf.target_fps * conf.shm_cache_seconds))
            else:
                slot_count = max(1, conf.shm_buffer_bytes // slot_size)
            logger.info(
                "[Topology] Using Shared Memory Ring (slots=%s, size=%s)",
                slot_count,
                slot_size,
            )
            backend_impl = ShmRingBackend(conf.shm_name, conf.shm_meta_name, slot_size, slot_count)
            state.set_check(
                "shm_ready",
                True,
                details={"shm_name": conf.shm_name, "shm_meta_name": conf.shm_meta_name, "slot_size": slot_size, "slot_count": slot_count},
            )
        else:
            raise FatalError(f"Unsupported MEMORY_BACKEND for Stage 3: {conf.memory_backend}")

        writer = Writer(backend_impl)
        
        # --- Publisher Selection ---
        if IPC_AVAILABLE:
            logger.info("[Topology] Using Publisher transport: %s", conf.bus_transport)
            publisher = get_publisher(conf)
            state.set_check(
                "bus_ready",
                True,
                details={"transport": conf.bus_transport, "endpoint": getattr(conf, "zmq_pub_endpoint", None)},
            )
        else:
            raise FatalError("IPC modules missing, cannot start Publisher")

        if conf.adaptive_fps:
            controller = AdaptiveRateController(
                selector,
                conf.adaptive_min_fps,
                conf.adaptive_max_fps,
                conf.adaptive_safety,
            )
            controller.start(conf.zmq_results_sub_endpoint)
            logger.info("Adaptive FPS enabled (results endpoint=%s).", conf.zmq_results_sub_endpoint)

        heartbeat = Heartbeat(conf.stream_id, conf.camera_id, conf.health_interval_sec)

        reconnect = ReconnectController(
            conf.rtsp_reconnect_min_sec,
            conf.rtsp_reconnect_max_sec,
            conf.rtsp_reconnect_factor,
            conf.rtsp_reconnect_jitter,
            conf.rtsp_max_retries,
        )
        frozen = FrozenStreamDetector(
            conf.rtsp_frozen_timeout_sec,
            conf.rtsp_frozen_hash_count,
            conf.rtsp_frozen_pts_count,
            conf.rtsp_frozen_timestamp_count,
        )

        record_buffer = None
        record_buffer_drops = 0
        if conf.record_buffer_seconds and conf.record_buffer_seconds > 0:
            max_frames = conf.record_buffer_max_frames
            if max_frames is None:
                max_frames = max(1, int(conf.record_buffer_seconds * conf.adaptive_max_fps * 1.2))
            record_buffer = RecordingBuffer(
                conf.record_buffer_seconds,
                max_frames,
                conf.record_jpeg_quality,
            )
            logger.info("Recording buffer enabled (seconds=%s, max_frames=%s).", conf.record_buffer_seconds, max_frames)
        
        rtsp.connect()
        state.set_check("source_ready", True, details={"rtsp_url": conf.rtsp_url})
        state.compute_ready(["config_loaded", "shm_ready", "bus_ready", "source_ready"])

    except FatalError as e:
        logger.error("FATAL: Startup Failed - %s", e.message)
        sys.exit(1)

    logger.info(f">>> Ingestion Running | Stream: {conf.stream_id} <<<")

    def _attempt_reconnect(reason: str) -> bool:
        _record_issue(f"rtsp_{reason}", "RTSP reconnect triggered", None)
        heartbeat.tick(status="degraded", reason=reason)
        while runtime.should_continue():
            delay = reconnect.wait()
            if delay is None:
                return False
            logger.warning(
                "Attempting reconnect in %.2fs (reason=%s, attempt=%s).",
                delay,
                reason,
                reconnect.attempts,
            )
            if rtsp.reconnect():
                reconnect.reset()
                frozen.reset()
                logger.info("Source reconnected (reason=%s).", reason)
                heartbeat.tick(status="ok", reason="reconnected")
                return True
        return False

    try:
        while runtime.should_continue():
            try:
                state.touch_loop()
                heartbeat.tick()

                packet = reader.next_packet()

                if packet is None:
                    if conf.video_loop and rtsp.is_file:
                        logger.warning("Source EOF reached. Rewinding file input.")
                        rtsp.rewind()
                        # avoid tight rewind loop when VideoCapture doesn't
                        # return frames immediately after seeking
                        time.sleep(0.05)
                        continue
                    if rtsp.is_file:
                        raise FatalError("Source EOF or Connection Lost")
                    freeze_reason = frozen.check(monotonic_ms())
                    if freeze_reason:
                        if not _attempt_reconnect(f"frozen_{freeze_reason}"):
                            raise FatalError("Source reconnect failed")
                    else:
                        time.sleep(0.05)
                    continue

                reconnect.reset()

                if packet.pts <= 0:
                    metrics.inc_dropped_pts()
                    continue

                try:
                    raw_frame = decoder.decode(packet)
                    # capture span: decoding/capture
                    try:
                        with ivis_tracing.start_span("ingestion.capture", {"stream_id": conf.stream_id}):
                            pass
                    except Exception as exc:
                        _record_issue("tracing_span_capture_failed", "Tracing span failed (capture)", exc)
                except Exception as exc:
                    metrics.inc_dropped_corrupt()
                    logger.debug("Decode error: %s", exc)
                    continue
                if raw_frame is None:
                    metrics.inc_dropped_corrupt()
                    continue
                
                metrics.inc_captured()
                _safe_metric("metrics_frames_in_failed", ivis_metrics.frames_in_total.inc)

                if not selector.allow(packet.pts):
                    metrics.inc_dropped_fps()
                    continue

                clean_frame = normalizer.process(raw_frame)
                if roi_mask is not None:
                    clean_frame = apply_mask(clean_frame, roi_mask)
                # normalization span
                try:
                    with ivis_tracing.start_span("ingestion.normalize", {"stream_id": conf.stream_id}):
                        pass
                except Exception as exc:
                    _record_issue("tracing_span_normalize_failed", "Tracing span failed (normalize)", exc)
                fingerprint = anchor.generate(clean_frame)
                frozen.note_frame(packet.pts, packet.timestamp_ms, fingerprint, packet.mono_ms)
                freeze_reason = frozen.check(packet.mono_ms)
                if freeze_reason and not rtsp.is_file:
                    if not _attempt_reconnect(f"frozen_{freeze_reason}"):
                        raise FatalError("Source reconnect failed")
                    continue
                identity = FrameIdentity(conf.stream_id, packet.pts, fingerprint)
                if record_buffer is not None:
                    if record_buffer.add_frame(clean_frame, packet.timestamp_ms):
                        _safe_metric("record_buffer_size_failed", lambda: ivis_metrics.record_buffer_size.set(record_buffer.size()))
                        if record_buffer.drops > record_buffer_drops:
                            _safe_metric(
                                "record_buffer_drops_failed",
                                lambda: ivis_metrics.record_buffer_drops.inc(record_buffer.drops - record_buffer_drops),
                            )
                            record_buffer_drops = record_buffer.drops
                # Write to SHM
                try:
                    # SHM write span
                    ref = None
                    try:
                        with ivis_tracing.start_span("ingestion.shm_write", {"frame_id": identity.frame_id, "stream_id": identity.stream_id}):
                            ref = writer.write(clean_frame, identity)
                    except Exception as exc:
                        _record_issue("tracing_span_shm_write_failed", "Tracing span failed (shm_write)", exc)
                        # fallback to direct write if tracing wrapper failed
                        ref = writer.write(clean_frame, identity)
                except Exception:
                    ref = None

                if ref is not None:
                    state.inc("frames_written", 1)
                    state.set_meta("last_frame_id", identity.frame_id)
                    state.set_meta("last_shm_write_ts", time.time())

                # publish span
                try:
                    with ivis_tracing.start_span("ingestion.publish", {"frame_id": identity.frame_id, "stream_id": identity.stream_id}):
                        published = publisher.publish(identity, packet.timestamp_ms, packet.mono_ms, ref, roi_meta=roi_meta)
                except Exception as exc:
                    _record_issue("tracing_span_publish_failed", "Tracing span failed (publish)", exc)
                    # if tracing wrapper fails, attempt publish anyway
                    published = publisher.publish(identity, packet.timestamp_ms, packet.mono_ms, ref, roi_meta=roi_meta)
                if not published:
                    state.set_check("bus_active", False, reason="publish_failed")
                    # Frame dropped due to backpressure/lag
                    metrics.inc_dropped_reason("lag")
                    _safe_metric("metrics_frames_dropped_failed", lambda: ivis_metrics.frames_dropped_total.labels(reason="lag").inc())
                    _safe_metric("metrics_drops_total_failed", lambda: ivis_metrics.drops_total.labels(reason="lag").inc())
                    logger.debug("Dropped frame due to backpressure/lag (stream length exceeded)")
                else:
                    state.inc("frames_published", 1)
                    state.set_check("bus_active", True)
                    state.set_meta("last_publish_ts", time.time())
                    metrics.inc_processed()
                    _safe_metric("metrics_frames_out_failed", ivis_metrics.frames_out_total.inc)
                # end-to-end: best-effort observe latency from capture timestamp to now
                try:
                    if packet.timestamp_ms:
                        now_ms = wall_clock_ms()
                        end_ms = latency_ms(now_ms, int(packet.timestamp_ms))
                        _safe_metric("metrics_end_to_end_latency_failed", lambda: ivis_metrics.end_to_end_latency_ms.observe(end_ms))
                except Exception as exc:
                    _record_issue("end_to_end_latency_failed", "End-to-end latency calculation failed", exc)
                # No external lag source when running without a broker
                _safe_metric("metrics_adaptive_fps_failed", lambda: ivis_metrics.adaptive_fps_current.set(selector.target_fps))
        
            except FatalError as e:
                state.set_error("fatal_error", e, context=getattr(e, "context", None))
                state.set_ready(False)
                logger.error("!!! FATAL ERROR !!! %s | Context: %s", getattr(e, 'message', str(e)), getattr(e, 'context', None))
                break

            except Exception as e:
                logger.exception("!!! UNHANDLED CRASH !!! %s", str(e))
                break

    finally:
        logger.info("Cleaning up resources...")
        rtsp.close()
        try:
            if 'publisher' in locals() and hasattr(publisher, 'close'):
                publisher.close()
                logger.info("Publisher closed.")
        except Exception as e:
            logger.warning("Error closing publisher: %s", e)
        
        runtime.shutdown()
        logger.info("Ingestion Service Stopped.")
        sys.exit(0) # clean exit

if __name__ == "__main__":
    main()

========================================================================================================================
FILE: ingestion\memory\__init__.py
========================================================================================================================


========================================================================================================================
FILE: ingestion\memory\ref.py
========================================================================================================================
# FILE: ingestion/memory/ref.py
# ------------------------------------------------------------------------------
class MemoryReference:
    def __init__(self, location, size, backend_type, generation=0):
        self.location = location
        self.size = size
        self.backend_type = backend_type
        self.generation = generation

    def __repr__(self):
        return f"Ref(loc={self.location}, sz={self.size}, gen={self.generation}, type={self.backend_type})"

========================================================================================================================
FILE: ingestion\memory\shm_backend.py
========================================================================================================================
# FILE: ingestion/memory/shm_backend.py
# ------------------------------------------------------------------------------
import atexit
import os
import sys

from ingestion.memory.ref import MemoryReference
from memory.shm_ring import ShmRing


class ShmRingBackend:
    name = "shm_ring_v1"

    def __init__(self, shm_name: str, meta_name: str, slot_size: int, slot_count: int):
        self._owner = os.getenv("SHM_OWNER", "1").lower() in ("1", "true", "yes")
        self.ring = ShmRing(
            shm_name,
            meta_name,
            slot_size,
            slot_count,
            create=True,
            recreate_on_mismatch=True,
        )
        atexit.register(self.close)

    def put(self, key, data):
        slot, gen = self.ring.write(data)
        import logging
        logging.getLogger("ingestion").debug("Wrote to SHM: key=%s slot=%s gen=%s bytes=%s", key, slot, gen, len(data))
        return MemoryReference(
            location=str(slot),
            size=len(data),
            backend_type=self.name,
            generation=gen,
        )

    def put_frame(self, key, frame_data):
        slot, gen = self.ring.write(frame_data)
        import logging
        logging.getLogger("ingestion").debug(
            "Wrote frame to SHM: key=%s slot=%s gen=%s bytes=%s", key, slot, gen, frame_data.nbytes
        )
        return MemoryReference(
            location=str(slot),
            size=frame_data.nbytes,
            backend_type=self.name,
            generation=gen,
        )

    def close(self):
        try:
            self.ring.close_unlink(unlink=self._owner)
        except Exception as exc:
            import logging
            logging.getLogger("ingestion").warning("Failed to close SHM ring: %s", exc)

========================================================================================================================
FILE: ingestion\memory\writer.py
========================================================================================================================
# FILE: ingestion/memory/writer.py
# ------------------------------------------------------------------------------
from ingestion.errors.fatal import MemoryWriteError
from ingestion.memory.ref import MemoryReference


class Writer:
    def __init__(self, storage_backend):
        self.backend = storage_backend
    
    def write(self, frame_data, identity):
        try:
            key = identity.frame_id
            if hasattr(self.backend, "put_frame"):
                ref = self.backend.put_frame(key, frame_data)
            else:
                data_bytes = frame_data.tobytes()
                ref = self.backend.put(key, data_bytes)
            
            if not isinstance(ref, MemoryReference):
                 raise MemoryWriteError(
                     f"Backend violation: Expected MemoryReference, got {type(ref)}", 
                     context={"id": key}
                 )
            return ref
        except Exception as e:
            if isinstance(e, MemoryWriteError): raise e
            raise MemoryWriteError(f"Write Exception: {str(e)}", context={"id": identity.frame_id})

========================================================================================================================
FILE: ingestion\metrics\__init__.py
========================================================================================================================


========================================================================================================================
FILE: ingestion\metrics\counters.py
========================================================================================================================
# ------------------------------------------------------------------------------
# FILE: ingestion/metrics/counters.py
# ------------------------------------------------------------------------------
class Metrics:
    def __init__(self):
        self.frames_captured = 0
        self.dropped_fps = 0       
        self.dropped_corrupt = 0   
        self.dropped_pts = 0       
        self.frames_processed = 0  
        self.write_failures = 0
        # per-reason drops
        self.frames_dropped_by_reason = {}

    def inc_captured(self): self.frames_captured += 1
    def inc_dropped_fps(self): self.dropped_fps += 1
    def inc_dropped_corrupt(self): self.dropped_corrupt += 1
    def inc_dropped_pts(self): self.dropped_pts += 1
    def inc_processed(self): self.frames_processed += 1
    def inc_write_failure(self): self.write_failures += 1
    def inc_dropped_reason(self, reason: str):
        if not isinstance(reason, str) or not reason:
            reason = "unspecified"
        self.frames_dropped_by_reason[reason] = self.frames_dropped_by_reason.get(reason, 0) + 1

========================================================================================================================
FILE: ingestion\publish\__init__.py
========================================================================================================================


========================================================================================================================
FILE: ingestion\publish\heartbeat.py
========================================================================================================================


========================================================================================================================
FILE: ingestion\recording\buffer.py
========================================================================================================================
# FILE: ingestion/recording/buffer.py
# ------------------------------------------------------------------------------
from collections import deque

import cv2


class RecordingBuffer:
    def __init__(self, max_seconds: float, max_frames: int, jpeg_quality: int = 85):
        self.max_seconds = max(0.0, float(max_seconds))
        self.max_frames = max(1, int(max_frames))
        self.jpeg_quality = max(1, min(100, int(jpeg_quality)))
        self._frames = deque(maxlen=self.max_frames)
        self.drops = 0

    def _prune_by_time(self, now_ms: int) -> None:
        if self.max_seconds <= 0:
            return
        cutoff = now_ms - int(self.max_seconds * 1000.0)
        while self._frames and self._frames[0][0] < cutoff:
            self._frames.popleft()

    def add_frame(self, frame_bgr, timestamp_ms: int) -> bool:
        params = [int(cv2.IMWRITE_JPEG_QUALITY), self.jpeg_quality]
        ok, jpeg = cv2.imencode(".jpg", frame_bgr, params)
        if not ok:
            return False
        if len(self._frames) == self._frames.maxlen:
            self.drops += 1
        self._frames.append((int(timestamp_ms), jpeg.tobytes()))
        self._prune_by_time(int(timestamp_ms))
        return True

    def get_clip_frames(self, start_ms: int, end_ms: int):
        start = int(start_ms)
        end = int(end_ms)
        return [payload for ts, payload in self._frames if start <= ts <= end]

    def size(self) -> int:
        return len(self._frames)

========================================================================================================================
FILE: ingestion\runtime.py
========================================================================================================================

# FILE: ingestion/runtime.py
import signal

class Runtime:
    def __init__(self):
        self.is_running = True
        self._setup_signals()

    def _setup_signals(self):
        signal.signal(signal.SIGINT, self._handle_exit)
        signal.signal(signal.SIGTERM, self._handle_exit)

    def _handle_exit(self, signum, frame):
        print(f"\n[Runtime] Received signal {signum}. Stopping loop...")
        self.is_running = False

    def should_continue(self):
        return self.is_running

    def shutdown(self):
        print("[Runtime] Shutdown sequence complete.")

========================================================================================================================
FILE: ivis\__init__.py
========================================================================================================================
"""IVIS top-level package marker (minimal)."""

========================================================================================================================
FILE: ivis\common\__init__.py
========================================================================================================================
"""ivis.common package marker."""

========================================================================================================================
FILE: ivis\common\config\__init__.py
========================================================================================================================
"""ivis.common.config package marker."""

========================================================================================================================
FILE: ivis\common\config\base.py
========================================================================================================================
# FILE: ivis/common/config/base.py
# ------------------------------------------------------------------------------
from common.config.base import ConfigLoadError, EnvLoader, redact_config

__all__ = ["ConfigLoadError", "EnvLoader", "redact_config"]

========================================================================================================================
FILE: ivis\common\contracts\__init__.py
========================================================================================================================
"""ivis.common.contracts package marker."""

========================================================================================================================
FILE: ivis\common\contracts\frame_contract.py
========================================================================================================================
# FILE: ivis/common/contracts/frame_contract.py
# ------------------------------------------------------------------------------
from common.contracts.frame_contract import FrameContractV1, FrameMemoryRef

__all__ = ["FrameContractV1", "FrameMemoryRef"]

========================================================================================================================
FILE: ivis\common\contracts\result_contract.py
========================================================================================================================
"""Result contract v1 schema and validator.
"""
import warnings
from typing import Any, Dict, List

from ivis.common.contracts.validators import ContractValidationError


def _is_number(x):
    return isinstance(x, (int, float))


def validate_result_contract_v1(result: Dict[str, Any]) -> None:
    if not isinstance(result, dict):
        raise ContractValidationError("not_a_dict", "result must be a dict")

    cv = result.get("contract_version")
    if isinstance(cv, bool):
        cv = None
    warning_msg = None
    if isinstance(cv, str):
        normalized = cv.strip()
        if normalized.lower() == "v1":
            warning_msg = "result contract_version 'v1' is deprecated; use int 1"
            cv = 1
        elif normalized == "1":
            warning_msg = "result contract_version '1' (string) is deprecated; use int 1"
            cv = 1
    if cv != 1:
        raise ContractValidationError("contract_version_mismatch", "unsupported result contract_version")
    if warning_msg:
        warnings.warn(warning_msg, DeprecationWarning, stacklevel=2)
    if result.get("contract_version") != 1:
        result["contract_version"] = 1

    for field in ("frame_id", "stream_id", "camera_id"):
        if field not in result or not isinstance(result.get(field), str):
            raise ContractValidationError("missing_id_field", f"{field} must be a non-empty string")

    if "timestamp_ms" not in result or not isinstance(result.get("timestamp_ms"), int):
        raise ContractValidationError("bad_timestamp_ms", "timestamp_ms must be int (ms)")
    if "mono_ms" not in result or not isinstance(result.get("mono_ms"), int):
        raise ContractValidationError("bad_mono_ms", "mono_ms must be int (ms)")

    # detections
    dets = result.get("detections")
    if dets is None:
        raise ContractValidationError("missing_detections", "detections must be present as a list")
    if not isinstance(dets, list):
        raise ContractValidationError("bad_detections", "detections must be a list")
    for i, d in enumerate(dets):
        if not isinstance(d, dict):
            raise ContractValidationError("bad_detection_entry", f"detection[{i}] must be a dict")
        bbox = d.get("bbox")
        if not isinstance(bbox, (list, tuple)) or len(bbox) != 4 or not all(_is_number(v) for v in bbox):
            raise ContractValidationError("bad_bbox", f"detection[{i}].bbox must be [x1,y1,x2,y2]")
        conf = d.get("conf")
        if not _is_number(conf) or conf < 0 or conf > 1:
            raise ContractValidationError("bad_confidence", f"detection[{i}].conf must be 0..1")
        if "class_id" not in d:
            raise ContractValidationError("missing_class_id", f"detection[{i}] missing class_id")

    # model sub-schema
    model = result.get("model")
    if not isinstance(model, dict):
        raise ContractValidationError("missing_model", "model metadata must be present")
    if not model.get("name") or not isinstance(model.get("name"), str):
        raise ContractValidationError("bad_model_name", "model.name must be a non-empty string")
    if not model.get("version"):
        # allow empty version but require field presence
        model["version"] = str(model.get("version", ""))
    if "threshold" in model and not _is_number(model.get("threshold")):
        raise ContractValidationError("bad_model_threshold", "model.threshold must be numeric")
    if "input_size" in model:
        ins = model.get("input_size")
        if not isinstance(ins, (list, tuple)) or len(ins) not in (2, 3):
            raise ContractValidationError("bad_model_input_size", "model.input_size must be [h,w] or [h,w,c]")

    # timing
    timing = result.get("timing")
    if timing is None or not isinstance(timing, dict):
        raise ContractValidationError("missing_timing", "timing must be present")
    if "inference_ms" not in timing or not _is_number(timing.get("inference_ms")):
        raise ContractValidationError("bad_timing", "timing.inference_ms must be present and numeric")

    return None

========================================================================================================================
FILE: ivis\common\contracts\validators.py
========================================================================================================================
"""Frame contract validators for IVIS v1 contracts.

Provides a strict, fail-fast validator used by Detection and UI.
"""
import warnings
from typing import Any, Dict


class ContractValidationError(Exception):
    """Raised when a contract fails validation.

    Attributes:
        reason_code: short machine-friendly reason string
        message: human-friendly message
    """
    def __init__(self, reason_code: str, message: str):
        super().__init__(message)
        self.reason_code = reason_code
        self.message = message


def validate_frame_contract_v1(contract: Dict[str, Any]) -> None:
    """Validate a v1 frame contract strictly.

    Raises ContractValidationError on any violation with a clear reason_code.
    """
    if not isinstance(contract, dict):
        raise ContractValidationError("not_a_dict", "contract must be a dict")

    # contract_version must be int 1 (temporary migration accepts "v1"/"1" strings)
    cv = contract.get("contract_version")
    if isinstance(cv, bool):
        cv = None
    warning_msg = None
    if isinstance(cv, str):
        normalized = cv.strip()
        if normalized.lower() == "v1":
            warning_msg = "contract_version 'v1' is deprecated; use int 1"
            cv = 1
        elif normalized == "1":
            warning_msg = "contract_version '1' (string) is deprecated; use int 1"
            cv = 1
    if cv != 1:
        raise ContractValidationError("contract_version_mismatch", f"unsupported contract_version={cv}")
    if warning_msg:
        warnings.warn(warning_msg, DeprecationWarning, stacklevel=2)
    if contract.get("contract_version") != 1:
        contract["contract_version"] = 1

    # Memory reference required
    mem = contract.get("memory")
    if not isinstance(mem, dict):
        raise ContractValidationError("missing_memory", "memory must be a dict")
    for field in ("backend", "key", "size", "generation"):
        if field not in mem:
            raise ContractValidationError("missing_memory_field", f"memory missing field '{field}'")
    if not isinstance(mem.get("backend"), str) or not mem.get("backend"):
        raise ContractValidationError("bad_memory_backend", "memory.backend must be a non-empty string")
    if not isinstance(mem.get("key"), str) or not mem.get("key"):
        raise ContractValidationError("bad_memory_key", "memory.key must be a non-empty string")
    if not isinstance(mem.get("size"), int) or mem.get("size") < 0:
        raise ContractValidationError("bad_memory_size", "memory.size must be a non-negative int")
    if not isinstance(mem.get("generation"), int):
        raise ContractValidationError("bad_memory_generation", "memory.generation must be an int")

    # Basic metadata
    width = contract.get("frame_width")
    height = contract.get("frame_height")
    channels = contract.get("frame_channels")
    dtype = contract.get("frame_dtype")
    color = contract.get("frame_color_space")

    for nm, val in (("frame_width", width), ("frame_height", height)):
        if not isinstance(val, int) or val <= 0:
            raise ContractValidationError("bad_dimensions", f"{nm} must be a positive int")
    # Reasonable bounds
    MIN_DIM = 16
    MAX_DIM = 10000
    if not (MIN_DIM <= width <= MAX_DIM) or not (MIN_DIM <= height <= MAX_DIM):
        raise ContractValidationError("dimension_out_of_range", f"width/height out of range: {width}x{height}")

    if not isinstance(channels, int) or channels <= 0:
        raise ContractValidationError("bad_channels", "frame_channels must be a positive int")
    if channels != 3:
        raise ContractValidationError("unsupported_channels", f"only 3 channels supported in v1; got {channels}")

    if not isinstance(dtype, str) or not dtype:
        raise ContractValidationError("bad_dtype", "frame_dtype must be a non-empty string")
    if dtype.lower() != "uint8":
        raise ContractValidationError("unsupported_dtype", f"only uint8 supported in v1; got {dtype}")

    if not isinstance(color, str) or not color:
        raise ContractValidationError("bad_color_space", "frame_color_space must be a non-empty string")
    if color.lower() != "bgr":
        raise ContractValidationError("unsupported_color_space", f"only bgr supported in v1; got {color}")

    # Verify memory size matches expected frame layout for uint8
    expected = width * height * channels
    if mem.get("size") != expected:
        raise ContractValidationError("memory_size_mismatch", f"memory.size {mem.get('size')} != expected {expected}")

    # timestamp and ids
    if "frame_id" not in contract or not isinstance(contract.get("frame_id"), str):
        raise ContractValidationError("bad_frame_id", "frame_id must be a non-empty string")
    if "stream_id" not in contract or not isinstance(contract.get("stream_id"), str):
        raise ContractValidationError("bad_stream_id", "stream_id must be a non-empty string")

    # pts/timestamp types
    if "pts" in contract and not isinstance(contract.get("pts"), (int, float)):
        raise ContractValidationError("bad_pts", "pts must be numeric")
    if "timestamp_ms" not in contract or not isinstance(contract.get("timestamp_ms"), int):
        raise ContractValidationError("bad_timestamp_ms", "timestamp_ms must be int (ms)")
    if "mono_ms" not in contract or not isinstance(contract.get("mono_ms"), int):
        raise ContractValidationError("bad_mono_ms", "mono_ms must be int (ms)")

    # All checks passed
    return None

========================================================================================================================
FILE: ivis\common\time_utils.py
========================================================================================================================
# FILE: ivis/common/time_utils.py
# ------------------------------------------------------------------------------
import time


def wall_clock_ms() -> int:
    return int(time.time() * 1000)


def monotonic_ms() -> int:
    return int(time.monotonic() * 1000)


def latency_ms(now_ms: int, timestamp_ms: int) -> int:
    return int(now_ms - timestamp_ms)

========================================================================================================================
FILE: ivis\legacy\detection_ingest_consumer_legacy.py
========================================================================================================================
"""
Legacy detection consumers (TCP / ZMQ).
These implementations are isolated under `ivis.legacy` and are not used
in the default production path.
"""
import json
import socket

from detection.errors.fatal import FatalError


class TcpFrameConsumer:
    def __init__(self, host="localhost", port=5555):
        self.address = (host, port)
        self.sock = None
        self.buffer = ""

    def connect(self):
        if not self.sock:
            try:
                self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                self.sock.settimeout(5.0)
                self.sock.connect(self.address)
                self.sock.settimeout(None)
                print(f"[DETECTION] Connected to Bus at {self.address}")
            except Exception as e:
                raise FatalError(f"Failed to connect to Bus at {self.address}", context={"error": str(e)})

    def __iter__(self):
        self.connect()
        while True:
            try:
                data = self.sock.recv(4096)
                if not data:
                    raise FatalError("Bus connection lost (EOF)")

                self.buffer += data.decode("utf-8")

                while "\n" in self.buffer:
                    line, self.buffer = self.buffer.split("\n", 1)
                    if line.strip():
                        try:
                            contract = json.loads(line)
                            yield contract
                        except json.JSONDecodeError:
                            print("[Warn] Received malformed JSON from Bus")
                            continue
            except FatalError:
                raise
            except Exception as e:
                raise FatalError("Bus Consumer Error", context={"error": str(e)})


class ZmqFrameConsumer:
    def __init__(self, endpoint: str):
        try:
            import zmq
        except Exception as exc:
            raise FatalError("Missing ZeroMQ dependency", context={"error": str(exc)}) from exc
        self.zmq = zmq
        self.endpoint = endpoint
        self.socket = None

    def connect(self):
        ctx = self.zmq.Context.instance()
        self.socket = ctx.socket(self.zmq.SUB)
        self.socket.connect(self.endpoint)
        self.socket.setsockopt(self.zmq.SUBSCRIBE, b"")
        print(f"[DETECTION] ZMQ SUB connected to {self.endpoint}")

    def __iter__(self):
        if not self.socket:
            self.connect()
        while True:
            try:
                payload = self.socket.recv()
                contract = json.loads(payload.decode("utf-8"))
                yield contract
            except Exception as e:
                raise FatalError("ZMQ Consumer Error", context={"error": str(e)})



========================================================================================================================
FILE: ivis\legacy\infrastructure_bus.py
========================================================================================================================
"""
Legacy dev-only TCP message bus. Kept under ivis.legacy for clarity.
"""
import socket
import threading


class SimpleBus:
    """
    TCP Message Broker for local development (legacy).
    """
    def __init__(self, host="0.0.0.0", port=5555):
        self.server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.server.bind((host, port))
        self.server.listen(5)
        self.clients = []
        self.running = True
        try:
            from ivis_logging import setup_logging

            self.logger = setup_logging("bus")
        except Exception:
            import logging

            self.logger = logging.getLogger("bus")
        self.logger.info("[BUS] Listening on %s:%s", host, port)

    def broadcast(self, sender_socket, message):
        for client in self.clients:
            if client != sender_socket:
                try:
                    client.sendall(message)
                except:
                    self.remove(client)

    def remove(self, connection):
        if connection in self.clients:
            self.clients.remove(connection)

    def handle_client(self, conn, addr):
        self.logger.info("[BUS] New connection: %s", addr)
        self.clients.append(conn)
        while self.running:
            try:
                data = conn.recv(4096)
                if not data:
                    break
                self.broadcast(conn, data)
            except:
                break
        self.remove(conn)
        conn.close()

    def start(self):
        while self.running:
            try:
                conn, addr = self.server.accept()
                thread = threading.Thread(target=self.handle_client, args=(conn, addr))
                thread.daemon = True
                thread.start()
            except KeyboardInterrupt:
                self.stop()
                break

    def stop(self):
        self.running = False
        self.server.close()
        self.logger.info("[BUS] Stopped")


if __name__ == "__main__":
    bus = SimpleBus()
    bus.start()

========================================================================================================================
FILE: ivis\legacy\infrastructure_bus_zmq.py
========================================================================================================================
"""
Legacy ZeroMQ proxy bus (kept under ivis.legacy).
"""
import os
import sys


def main():
    try:
        import zmq
    except Exception as exc:
        print(f"Missing ZeroMQ dependency: {exc}")
        sys.exit(1)

    xsub_endpoint = os.getenv("ZMQ_XSUB_ENDPOINT", "tcp://*:5555")
    xpub_endpoint = os.getenv("ZMQ_XPUB_ENDPOINT", "tcp://*:5556")

    ctx = zmq.Context.instance()
    xsub = ctx.socket(zmq.XSUB)
    xsub.bind(xsub_endpoint)
    xpub = ctx.socket(zmq.XPUB)
    xpub.bind(xpub_endpoint)

    print(f"[BUS-ZMQ] XSUB {xsub_endpoint} | XPUB {xpub_endpoint}")
    try:
        zmq.proxy(xsub, xpub)
    except KeyboardInterrupt:
        print("[BUS-ZMQ] Stopped")
    finally:
        xsub.close(0)
        xpub.close(0)
        ctx.term()


if __name__ == "__main__":
    main()

========================================================================================================================
FILE: ivis\legacy\ingestion_ipc_legacy.py
========================================================================================================================
"""
Legacy ingestion IPC transports (kept for reference and optional backwards compatibility).
This module is intentionally isolated under `ivis.legacy` and is NOT part of the
default production path. It remains for reference when using legacy transports.
"""
import json
import socket

from ingestion.memory.ref import MemoryReference
from ivis.common.contracts.frame_contract import FrameContractV1, FrameMemoryRef


class SocketPublisher:
    """
    TCP publisher (legacy).
    """

    def __init__(self, config, host="localhost", port=5555):
        self.stream_id = config.stream_id
        self.camera_id = config.camera_id
        self.frame_width = config.frame_width
        self.frame_height = config.frame_height
        self.frame_color = config.frame_color
        self.address = (host, port)
        self.sock = None
        self._connect()

    def _connect(self):
        try:
            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.sock.connect(self.address)
        except Exception:
            self.sock = None

    def publish(self, frame_identity, packet_timestamp_ms, packet_mono_ms, memory_ref, roi_meta=None):
        gen = getattr(memory_ref, "generation", 0)
        contract = _build_contract(
            self.stream_id,
            self.camera_id,
            frame_identity,
            packet_timestamp_ms,
            packet_mono_ms,
            memory_ref,
            gen,
            self.frame_width,
            self.frame_height,
            self.frame_color,
            roi_meta=roi_meta,
        )
        payload = json.dumps(contract) + "\n"

        if self.sock:
            try:
                self.sock.sendall(payload.encode())
                return True
            except Exception:
                print("[PUB] Transport lost. Dropping msg.")
                self.sock.close()
                self._connect()
        else:
            self._connect()


class ZmqPublisher:
    def __init__(self, config, endpoint: str):
        try:
            import zmq
        except Exception as exc:
            raise RuntimeError(f"Missing ZeroMQ dependency: {exc}") from exc

        self.stream_id = config.stream_id
        self.camera_id = config.camera_id
        self.frame_width = config.frame_width
        self.frame_height = config.frame_height
        self.frame_color = config.frame_color
        self.endpoint = endpoint
        self.zmq = zmq
        self.socket = self.zmq.Context.instance().socket(self.zmq.PUB)
        self.socket.bind(self.endpoint)

    def publish(self, frame_identity, packet_timestamp_ms, packet_mono_ms, memory_ref, roi_meta=None):
        gen = getattr(memory_ref, "generation", 0)
        contract = _build_contract(
            self.stream_id,
            self.camera_id,
            frame_identity,
            packet_timestamp_ms,
            packet_mono_ms,
            memory_ref,
            gen,
            self.frame_width,
            self.frame_height,
            self.frame_color,
            roi_meta=roi_meta,
        )
        payload = json.dumps(contract).encode("utf-8")
        self.socket.send(payload)
        return True


def _build_contract(
    stream_id,
    camera_id,
    frame_identity,
    packet_timestamp_ms,
    packet_mono_ms,
    memory_ref,
    gen,
    frame_width,
    frame_height,
    frame_color,
    roi_meta=None,
):
    backend = getattr(memory_ref, "backend_type", "shm_ring_v1")
    memory = FrameMemoryRef(
        backend=backend,
        key=memory_ref.location,
        size=memory_ref.size,
        generation=gen,
    )
    output_color = "bgr"
    contract = FrameContractV1(
        contract_version=1,
        frame_id=frame_identity.frame_id,
        stream_id=stream_id,
        camera_id=camera_id,
        pts=frame_identity.pts,
        timestamp_ms=packet_timestamp_ms,
        mono_ms=packet_mono_ms,
        memory=memory,
        frame_width=frame_width,
        frame_height=frame_height,
        frame_channels=3,
        frame_dtype="uint8",
        frame_color_space=output_color,
    )
    payload = contract.to_dict()
    if roi_meta:
        payload["roi"] = roi_meta
    return payload

========================================================================================================================
FILE: ivis_health.py
========================================================================================================================
# ivis_health.py
import json
import logging
import threading
import time
import os
import traceback
from http.server import BaseHTTPRequestHandler, ThreadingHTTPServer
from typing import Any, Dict, Optional

logger = logging.getLogger("health")


class ServiceState:
    def __init__(self, service: str):
        self.service = service
        self.start_ts = time.time()
        self._lock = threading.Lock()

        self.ready: bool = False
        self.checks: Dict[str, Dict[str, Any]] = {}
        self.counters: Dict[str, int] = {}
        self.meta: Dict[str, Any] = {}

        self.last_loop_ts: Optional[float] = None
        self.last_error: Optional[Dict[str, Any]] = None

    def _calc_derived_checks(self) -> Dict[str, Dict[str, Any]]:
        now = time.time()
        derived = {}

        # 1. loop_recent
        max_idle = float(os.getenv("READY_MAX_IDLE_SEC", "5"))
        if self.last_loop_ts:
            age = now - self.last_loop_ts
            ok = age <= max_idle
            derived["loop_recent"] = {
                "ok": ok,
                "ts": now,
                "reason": "idle_too_long" if not ok else None,
                "details": {"age_sec": round(age, 3), "max_sec": max_idle}
            }
        else:
             derived["loop_recent"] = {
                "ok": False,
                "ts": now,
                "reason": "never_started",
                "details": {}
            }

        # 2. bus_active_recent
        bus_ok = True
        reason = None
        details = {}
        
        if self.service == "ingestion":
            max_no_pub = float(os.getenv("READY_MAX_NO_PUBLISH_SEC", "10"))
            last_pub = self.meta.get("last_publish_ts")
            if last_pub:
                age = now - float(last_pub)
                if age > max_no_pub:
                    bus_ok = False
                    reason = "no_publish_recent"
                details = {"age_sec": round(age, 3), "max_sec": max_no_pub}
            else:
                bus_ok = False
                reason = "never_published"

        elif self.service == "detection":
            max_no_contract = float(os.getenv("READY_MAX_NO_CONTRACT_SEC", "10"))
            last_contract = self.meta.get("last_contract_ts")
            if last_contract:
                age = now - float(last_contract)
                if age > max_no_contract:
                    bus_ok = False
                    reason = "no_contract_recent"
                details = {"age_sec": round(age, 3), "max_sec": max_no_contract}
            else:
                bus_ok = False
                reason = "never_received_contract"
        
        derived["bus_active_recent"] = {
            "ok": bus_ok,
            "ts": now,
            "reason": reason,
            "details": details
        }
        
        return derived

    def set_check(self, name: str, ok: bool, details: Optional[Dict[str, Any]] = None, reason: Optional[str] = None) -> None:
        with self._lock:
            self.checks[name] = {
                "ok": bool(ok),
                "ts": time.time(),
                "reason": reason,
                "details": details or {},
            }

    def get_check_ok(self, name: str) -> bool:
        with self._lock:
            return bool(self.checks.get(name, {}).get("ok", False))

    def inc(self, name: str, by: int = 1) -> None:
        if by == 0:
            return
        with self._lock:
            self.counters[name] = int(self.counters.get(name, 0)) + int(by)

    def set_meta(self, key: str, value: Any) -> None:
        with self._lock:
            self.meta[key] = value

    def touch_loop(self) -> None:
        with self._lock:
            self.last_loop_ts = time.time()

    def set_ready(self, ready: bool) -> None:
        with self._lock:
            self.ready = bool(ready)

    def compute_ready(self, required_checks: list) -> bool:
        ok = True
        for name in required_checks:
            if not self.get_check_ok(name):
                ok = False
                break
        self.set_ready(ok)
        return ok

    def set_error(self, reason: str, exc: Optional[BaseException] = None, context: Optional[Dict[str, Any]] = None) -> None:
        payload = {
            "ts": time.time(),
            "reason": reason,
            "context": context or {},
        }
        if exc is not None:
            payload["error"] = str(exc)
            payload["traceback"] = traceback.format_exc()
        with self._lock:
            self.last_error = payload

    def snapshot(self, include_debug: bool = False) -> Dict[str, Any]:
        with self._lock:
            uptime = max(0.0, time.time() - self.start_ts)
            derived = self._calc_derived_checks()
            
            # Merit state = ready AND derived checks OK
            runtime_ready = self.ready and derived["loop_recent"]["ok"] and derived["bus_active_recent"]["ok"]

            # Merge derived checks into the main checks dict for visibility
            all_checks = self.checks.copy()
            all_checks.update(derived)

            return {
                "service": self.service,
                "uptime_sec": uptime,
                "ready": runtime_ready,  # Computed runtime readiness
                "config_ready": self.ready, # Original startup readiness
                "checks": all_checks,
                "counters": self.counters,
                "meta": self.meta,
                "last_loop_ts": self.last_loop_ts,
                "meta": self.meta,
                "last_loop_ts": self.last_loop_ts,
                # Filter out traceback/full error details unless strictly requested (authenticated)
                "last_error": self.last_error if include_debug else (
                    {k: v for k, v in self.last_error.items() if k not in ("traceback", "context")} 
                    if self.last_error else None
                ),
            }


class _Handler(BaseHTTPRequestHandler):
    server_version = "IVISHealth/1.0"

    def _write_json(self, status: int, payload: Dict[str, Any]) -> None:
        data = json.dumps(payload, ensure_ascii=False).encode("utf-8")
        self.send_response(status)
        self.send_header("Content-Type", "application/json; charset=utf-8")
        self.send_header("Content-Length", str(len(data)))
        self.end_headers()
        self.wfile.write(data)

    def do_GET(self):  # noqa: N802
        state: ServiceState = self.server.state  # type: ignore[attr-defined]
        try:
            if self.path == "/health":
                snap = state.snapshot()
                self._write_json(200, snap)
                return

            if self.path == "/ready":
                snap = state.snapshot()
                status = 200 if snap.get("ready") else 503
                self._write_json(status, snap)
                return

            if self.path == "/state":
                # Strict Token Check for /state
                required_token = os.getenv("HEALTH_TOKEN")
                if not required_token:
                    self._write_json(403, {"error": "forbidden", "detail": "HEALTH_TOKEN not configured"})
                    return
                
                auth_header = self.headers.get("X-IVIS-Health-Token")
                if auth_header != required_token:
                    self._write_json(403, {"error": "forbidden", "detail": "invalid token"})
                    return

                self._write_json(200, state.snapshot(include_debug=True))
                return

            self._write_json(404, {"error": "not_found", "path": self.path})
        except Exception as exc:
            logger.exception("Health handler failed: %s", exc)
            self._write_json(500, {"error": "internal_error", "detail": str(exc)})

    def log_message(self, fmt: str, *args):  # silence default noisy logs
        return


class HealthServer:
    def __init__(self, state: ServiceState, host: str, port: int):
        self.state = state
        self.host = host
        self.port = int(port)
        if not os.getenv("HEALTH_TOKEN"):
            logger.warning("SECURITY WARNING: HEALTH_TOKEN is not set. /state endpoint will be inaccessible.")
        self._httpd: Optional[ThreadingHTTPServer] = None
        self._thread: Optional[threading.Thread] = None

    def start_in_thread(self) -> None:
        httpd = ThreadingHTTPServer((self.host, self.port), _Handler)
        httpd.state = self.state  # type: ignore[attr-defined]
        self._httpd = httpd

        t = threading.Thread(target=httpd.serve_forever, name=f"{self.state.service}-health", daemon=True)
        t.start()
        self._thread = t

    def stop(self) -> None:
        if self._httpd is None:
            return
        try:
            self._httpd.shutdown()
        except Exception:
            pass

========================================================================================================================
FILE: ivis_logging.py
========================================================================================================================
import json
import logging
import os
from logging.handlers import RotatingFileHandler

_STANDARD_ATTRS = {
    "name",
    "msg",
    "args",
    "levelname",
    "levelno",
    "pathname",
    "filename",
    "module",
    "exc_info",
    "exc_text",
    "stack_info",
    "lineno",
    "funcName",
    "created",
    "msecs",
    "relativeCreated",
    "thread",
    "threadName",
    "processName",
    "process",
    "message",
}


class JsonFormatter(logging.Formatter):
    def format(self, record: logging.LogRecord) -> str:
        payload = {
            "time": self.formatTime(record, datefmt="%Y-%m-%dT%H:%M:%S"),
            "level": record.levelname,
            "service": record.name,
            "message": record.getMessage(),
        }
        extras = {
            key: value
            for key, value in record.__dict__.items()
            if key not in _STANDARD_ATTRS
        }
        # Ensure mandatory structured fields are present (may be None)
        mandatory = ["stream_id", "frame_id", "generation", "latency_ms", "error_code"]
        for m in mandatory:
            payload[m] = extras.get(m) if extras.get(m) is not None else None

        # merge any other extras
        if extras:
            payload.update(extras)
        if record.exc_info:
            payload["exception"] = self.formatException(record.exc_info)
        return json.dumps(payload, ensure_ascii=True)


class TextFormatter(logging.Formatter):
    def format(self, record: logging.LogRecord) -> str:
        msg = super().format(record)
        extras = {
            key: value
            for key, value in record.__dict__.items()
            if key not in _STANDARD_ATTRS
        }
        if extras:
            extra_pairs = " ".join(f"{key}={value}" for key, value in extras.items())
            msg = f"{msg} | {extra_pairs}"
        return msg


def setup_logging(service_name: str = "ivis") -> logging.Logger:
    logs_dir = os.getenv("LOG_DIR") or os.path.join(os.getcwd(), "logs")
    os.makedirs(logs_dir, exist_ok=True)

    logger = logging.getLogger(service_name)
    if logger.handlers:
        return logger

    debug = os.getenv("DEBUG", "false").lower() == "true"
    level = logging.DEBUG if debug else logging.INFO

    fmt = "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
    log_format = os.getenv("LOG_FORMAT", "text").lower()
    if log_format == "json":
        formatter = JsonFormatter()
    else:
        formatter = TextFormatter(fmt)

    # Stream handler (stdout)
    sh = logging.StreamHandler()
    sh.setFormatter(formatter)
    sh.setLevel(level)
    logger.addHandler(sh)

    # Rotating file handler
    fh_path = os.path.join(logs_dir, f"{service_name}.log")
    fh = RotatingFileHandler(fh_path, maxBytes=5 * 1024 * 1024, backupCount=3)
    fh.setFormatter(formatter)
    fh.setLevel(level)
    logger.addHandler(fh)

    logger.setLevel(level)
    logger.propagate = False
    return logger

========================================================================================================================
FILE: ivis_metrics.py
========================================================================================================================
from prometheus_client import Counter, Histogram, Gauge, start_http_server, generate_latest, CollectorRegistry, CONTENT_TYPE_LATEST
from prometheus_client import REGISTRY
from flask import Response
import time

# Prometheus metrics (shared names across services - each service runs separately)
frames_in_total = Counter("frames_in_total", "Total frames entering the pipeline")
frames_out_total = Counter("frames_out_total", "Total frames successfully processed/published")
frames_dropped_total = Counter("frames_dropped_total", "Total frames dropped", ["reason"])
drops_total = Counter("drops_total", "Dropped frames", ["reason"])
service_errors_total = Counter("service_errors_total", "Service errors", ["service", "reason"])

# Latency metrics (measured in milliseconds)
shm_write_latency_ms = Histogram("shm_write_latency_ms", "SHM write latency (ms)")
shm_read_latency_ms = Histogram("shm_read_latency_ms", "SHM read latency (ms)")
shm_bytes_copied_total = Counter("shm_bytes_copied_total", "Total bytes copied via SHM")
inference_latency_ms = Histogram("inference_latency_ms", "Inference latency (ms)")
end_to_end_latency_ms = Histogram("end_to_end_latency_ms", "End-to-end latency (ms)")

# Gauges
fps_in = Gauge("fps_in", "Input frames per second (approx)")
fps_out = Gauge("fps_out", "Output frames per second (displayed)")
adaptive_fps_current = Gauge("adaptive_fps_current", "Current adaptive FPS target")
ui_results_cache_size = Gauge("ui_results_cache_size", "UI results cache size")
record_buffer_size = Gauge("record_buffer_size", "Recording buffer size (frames)")
record_buffer_drops = Counter("record_buffer_drops", "Recording buffer drops")


_server_started = False


def start_metrics_http_server(port: int = 8000):
    """Start the prometheus client HTTP server on the given port (no-op if already started)."""
    global _server_started
    if _server_started:
        return
    try:
        start_http_server(int(port))
        _server_started = True
    except Exception:
        # best-effort; services should continue even if metrics server fails to bind
        _server_started = False


def register_flask_metrics(app):
    """Register a /metrics route on a Flask app that exposes prometheus metrics."""
    @app.route("/metrics")
    def _metrics():
        data = generate_latest(REGISTRY)
        return Response(data, mimetype=CONTENT_TYPE_LATEST)

========================================================================================================================
FILE: ivis_tracing.py
========================================================================================================================
"""ivis_tracing: optional OpenTelemetry tracing helper.

Usage:
  from ivis_tracing import init_tracer, start_span
  init_tracer(service_name="ingestion")
  with start_span("capture", {"frame_id": fid, "stream_id": sid}):
      ...

This module is best-effort: if OpenTelemetry packages are not installed
or initialization fails, start_span becomes a no-op context manager so
tracing is optional and won't break runtime.
"""
import os
import contextlib
from typing import Optional, Mapping

_tracer = None
_enabled = False


def init_tracer(service_name: Optional[str] = None):
    """Initialize OpenTelemetry tracer using environment variables.

    Env vars used:
      OTEL_EXPORTER_OTLP_ENDPOINT - OTLP HTTP endpoint (e.g. http://collector:4318)
      OTEL_SERVICE_NAME - service.name override
      OTEL_SAMPLER - always_on | always_off | traceidratio
      OTEL_SAMPLE_RATE - for traceidratio, float between 0.0 and 1.0
    """
    global _tracer, _enabled
    try:
        from opentelemetry import trace
        from opentelemetry.sdk.trace import TracerProvider
        from opentelemetry.sdk.trace.export import BatchSpanProcessor
        from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
        from opentelemetry.sdk.trace.sampling import AlwaysOnSampler, AlwaysOffSampler, TraceIdRatioBased

        endpoint = os.getenv("OTEL_EXPORTER_OTLP_ENDPOINT")
        env_name = os.getenv("OTEL_SERVICE_NAME") or service_name or "ivis"
        sampler_mode = os.getenv("OTEL_SAMPLER", "always_on").lower()
        sample_rate = float(os.getenv("OTEL_SAMPLE_RATE", "1.0"))

        if sampler_mode == "always_off":
            sampler = AlwaysOffSampler()
        elif sampler_mode == "traceidratio":
            sampler = TraceIdRatioBased(sample_rate)
        else:
            sampler = AlwaysOnSampler()

        provider = TracerProvider(sampler=sampler)
        trace.set_tracer_provider(provider)

        if endpoint:
            exporter = OTLPSpanExporter(endpoint=endpoint)
            processor = BatchSpanProcessor(exporter)
            provider.add_span_processor(processor)

        _tracer = trace.get_tracer(env_name)
        _enabled = True
    except Exception:
        # tracing disabled; keep no-op behavior
        _tracer = None
        _enabled = False


@contextlib.contextmanager
def start_span(name: str, attributes: Optional[Mapping[str, object]] = None):
    """Context manager that starts a span if tracing is enabled, else no-op."""
    global _tracer, _enabled
    if not _enabled or _tracer is None:
        yield None
        return
    try:
        with _tracer.start_as_current_span(name) as span:
            if attributes:
                try:
                    for k, v in attributes.items():
                        if v is not None:
                            span.set_attribute(str(k), v)
                except Exception:
                    pass
            yield span
    except Exception:
        # swallow tracing errors
        yield None


def is_enabled() -> bool:
    return bool(_enabled)

========================================================================================================================
FILE: memory\__init__.py
========================================================================================================================


========================================================================================================================
FILE: memory\api\__init__.py
========================================================================================================================


========================================================================================================================
FILE: memory\api\health.py
========================================================================================================================
# FILE: memory/api/health.py
# ------------------------------------------------------------------------------
from memory.backend.base import MemoryBackend


class HealthAPI:
    def __init__(self, backend: MemoryBackend):
        self._backend = backend
    def is_alive(self) -> bool:
        return True 
    def stats(self) -> dict:
        return self._backend.stats()

========================================================================================================================
FILE: memory\api\read.py
========================================================================================================================
# FILE: memory/api/read.py
# ------------------------------------------------------------------------------
from typing import Optional

from memory.backend.base import MemoryBackend
from memory.buffer.layout import MemoryReference

class ReadAPI:
    def __init__(self, backend: MemoryBackend):
        self._backend = backend
    def get(self, key: str) -> Optional[bytes]:
        return self._backend.get(key)
    def get_reference(self, key: str) -> Optional[MemoryReference]:
        data = self._backend.get(key)
        if data:
            return MemoryReference(location="memory", size=len(data), generation=0, backend_type=self._backend.name)
        return None

========================================================================================================================
FILE: memory\api\write.py
========================================================================================================================
# FILE: memory/api/write.py
# ------------------------------------------------------------------------------
from memory.backend.base import MemoryBackend


class WriteAPI:
    def __init__(self, backend: MemoryBackend):
        self._backend = backend
    def put(self, key: str, data: bytes):
        if not key or not data: return False
        return self._backend.put(key, data)

========================================================================================================================
FILE: memory\backend\__init__.py
========================================================================================================================


========================================================================================================================
FILE: memory\backend\base.py
========================================================================================================================
# FILE: memory/backend/base.py
# ------------------------------------------------------------------------------
from abc import ABC, abstractmethod
from typing import Optional, Any

class MemoryBackend(ABC):
    name: str = "base"
    @abstractmethod
    def put(self, key: str, data: bytes) -> Any: pass
    @abstractmethod
    def get(self, key: str) -> Optional[bytes]: pass
    @abstractmethod
    def stats(self) -> dict: pass

========================================================================================================================
FILE: memory\backend\ring.py
========================================================================================================================
# FILE: memory/backend/ring.py
# ------------------------------------------------------------------------------
from typing import Union

from typing import Optional

from memory.backend.base import MemoryBackend
from memory.buffer.allocator import RingAllocator
from memory.buffer.index import BufferIndex
from memory.buffer.layout import MemoryReference
from memory.errors.fatal import BackendInitializationError
from memory.metrics.counters import Metrics

class RingBufferBackend(MemoryBackend):
    name = "ring_v1"
    def __init__(self, capacity_bytes: int):
        self.capacity = capacity_bytes
        try:
            self._buffer = bytearray(capacity_bytes)
        except MemoryError:
            raise BackendInitializationError("Failed to allocate raw memory buffer")
        self._allocator = RingAllocator(capacity_bytes)
        self._index = BufferIndex()
        self._metrics = Metrics.get()

    def put(self, key: str, data: bytes) -> Union[MemoryReference, bool]:
        data_len = len(data)
        alloc = self._allocator.allocate(data_len)
        if not alloc.success:
            self._metrics.inc_write_fail()
            return False

        try:
            end_pos = alloc.offset + data_len
            self._buffer[alloc.offset : end_pos] = data
        except Exception:
            self._metrics.inc_write_fail()
            return False

        self._index.update(key, alloc.offset, data_len, alloc.generation)
        self._metrics.inc_write_ok()
        
        return MemoryReference(location=key, size=data_len, generation=alloc.generation, backend_type=self.name)

    def get(self, key: str) -> Optional[bytes]:
        entry = self._index.lookup(key)
        if not entry:
            self._metrics.inc_read_miss()
            return None
        current_gen = self._allocator.current_generation()
        if entry.generation != current_gen:
            self._metrics.inc_read_miss()
            self._metrics.evictions += 1
            return None
        end_pos = entry.offset + entry.size
        data_copy = bytes(self._buffer[entry.offset : end_pos])
        self._metrics.inc_read_ok()
        return data_copy

    def stats(self) -> dict:
        base_stats = self._metrics.snapshot()
        base_stats["index_count"] = self._index.count()
        base_stats["backend"] = self.name
        return base_stats

========================================================================================================================
FILE: memory\buffer\__init__.py
========================================================================================================================


========================================================================================================================
FILE: memory\buffer\allocator.py
========================================================================================================================
# FILE: memory/buffer/allocator.py
# ------------------------------------------------------------------------------
from memory.buffer.layout import AllocationResult


class RingAllocator:
    def __init__(self, buffer_capacity: int):
        self.capacity = buffer_capacity
        self.write_offset = 0
        self.wrap_count = 0

    def allocate(self, size: int) -> AllocationResult:
        if size > self.capacity:
            return AllocationResult(0, 0, False)
        if self.write_offset + size > self.capacity:
            self.write_offset = 0
            self.wrap_count += 1
        
        allocated_offset = self.write_offset
        allocated_generation = self.wrap_count
        self.write_offset += size
        return AllocationResult(allocated_offset, allocated_generation, True)

    def current_generation(self) -> int:
        return self.wrap_count

========================================================================================================================
FILE: memory\buffer\index.py
========================================================================================================================
# FILE: memory/buffer/index.py
# ------------------------------------------------------------------------------
from dataclasses import dataclass
from typing import Optional

@dataclass
class IndexEntry:
    offset: int
    size: int
    generation: int

class BufferIndex:
    def __init__(self):
        self._map: dict[str, IndexEntry] = {}
    def update(self, key: str, offset: int, size: int, generation: int):
        self._map[key] = IndexEntry(offset, size, generation)
    def lookup(self, key: str) -> Optional[IndexEntry]:
        return self._map.get(key)
    def count(self) -> int:
        return len(self._map)

========================================================================================================================
FILE: memory\buffer\layout.py
========================================================================================================================
# FILE: memory/buffer/layout.py
# ------------------------------------------------------------------------------
from dataclasses import dataclass

@dataclass(frozen=True)
class MemoryReference:
    location: str
    size: int
    generation: int
    backend_type: str

@dataclass(frozen=True)
class AllocationResult:
    offset: int
    generation: int
    success: bool

========================================================================================================================
FILE: memory\config.py
========================================================================================================================
# FILE: memory/config.py
# ------------------------------------------------------------------------------
import os

from memory.errors.fatal import ConfigurationError

class Config:
    def __init__(self):
        self.backend_type = os.getenv("MEMORY_BACKEND")
        self.buffer_size_bytes = self._get_int("BUFFER_SIZE_BYTES")
        self.max_frame_size_bytes = self._get_int("MAX_FRAME_SIZE_BYTES")
        self._validate()

    def _get_int(self, key: str) -> int:
        val = os.getenv(key)
        if val is None:
            raise ConfigurationError(f"Missing mandatory config: {key}")
        try:
            return int(val)
        except ValueError:
            raise ConfigurationError(f"Config {key} must be an integer")

    def _validate(self):
        required_min_size = self.max_frame_size_bytes * 2
        if self.buffer_size_bytes < required_min_size:
            raise ConfigurationError(f"Buffer size too small.")
        if self.backend_type != "ring":
             raise ConfigurationError(f"Fatal: Only 'ring' backend is supported.")
try:
    config = Config()
except ConfigurationError:
    if os.getenv("MEMORY_STRICT_MODE", "1") == "1": raise
    config = None

========================================================================================================================
FILE: memory\errors\__init__.py
========================================================================================================================


========================================================================================================================
FILE: memory\errors\fatal.py
========================================================================================================================
# FILE: memory/errors/fatal.py
# ------------------------------------------------------------------------------
class MemoryFatalError(Exception):
    pass
class ConfigurationError(MemoryFatalError):
    pass
class BackendInitializationError(MemoryFatalError):
    pass

========================================================================================================================
FILE: memory\metrics\__init__.py
========================================================================================================================


========================================================================================================================
FILE: memory\metrics\counters.py
========================================================================================================================
# FILE: memory/metrics/counters.py
# ------------------------------------------------------------------------------
class Metrics:
    _instance = None
    def __init__(self):
        self.writes_ok = 0
        self.writes_failed = 0
        self.reads_ok = 0
        self.reads_miss = 0
        self.evictions = 0 

    @classmethod
    def get(cls):
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance

    def inc_write_ok(self): self.writes_ok += 1
    def inc_write_fail(self): self.writes_failed += 1
    def inc_read_ok(self): self.reads_ok += 1
    def inc_read_miss(self): self.reads_miss += 1
    def snapshot(self):
        return {
            "writes_ok": self.writes_ok,
            "writes_failed": self.writes_failed,
            "reads_ok": self.reads_ok,
            "reads_miss": self.reads_miss,
            "evictions": self.evictions
        }

========================================================================================================================
FILE: memory\runtime.py
========================================================================================================================
# FILE: memory/runtime.py
# ------------------------------------------------------------------------------

from memory.config import config
from memory.backend.ring import RingBufferBackend
from memory.errors.fatal import ConfigurationError, BackendInitializationError
from memory.errors.fatal import ConfigurationError


class Runtime:
    def __init__(self):
        self.backend = None
    def initialize(self):
        if not config: raise ConfigurationError("Config Error")
        print(f"Initializing Memory Backend: {config.backend_type}")
        if config.backend_type == "ring":
            self.backend = RingBufferBackend(config.buffer_size_bytes)
        else:
            raise ConfigurationError(f"Unsupported backend")
    def get_backend(self):
        if not self.backend: raise BackendInitializationError("Not Initialized")
        return self.backend

========================================================================================================================
FILE: memory\server.py
========================================================================================================================
# FILE: memory/server.py
# ------------------------------------------------------------------------------
import http.server
import socketserver
import sys
import os
import json

from memory.runtime import Runtime
from ivis_logging import setup_logging

logger = setup_logging("memory")



# Global Init - If this fails, script dies (Stage 2 compliant)
try:
    runtime = Runtime()
    runtime.initialize()
    backend = runtime.get_backend()
except Exception as e:
    logger.error("FATAL: Memory Service Init Failed - %s", str(e))
    sys.exit(1)

class MemoryRequestHandler(http.server.BaseHTTPRequestHandler):
    
    def do_PUT(self):
        try:
            key = self.path.strip("/")
            try:
                length = int(self.headers['Content-Length'])
                data = self.rfile.read(length)
            except (TypeError, ValueError):
                self.send_error(400, "Invalid Content-Length")
                return
            
            ref = backend.put(key, data)
            
            if ref:
                self.send_response(200)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                resp = {"size": ref.size, "generation": ref.generation}
                self.wfile.write(json.dumps(resp).encode())
            else:
                self.send_error(507, "Memory Write Failed")
                
        except Exception:
            self.send_error(500, "Internal Server Error")

    def do_GET(self):
        try:
            key = self.path.strip("/")
            data = backend.get(key)
            
            if data:
                self.send_response(200)
                self.send_header('Content-type', 'application/octet-stream')
                self.end_headers()
                self.wfile.write(data)
            else:
                self.send_error(404, "Frame not found")
        except Exception:
             self.send_error(500, "Internal Server Error")

    def do_HEAD(self):
        # Support simple health probes via HEAD /health
        if self.path.strip("/") == "health":
            self.send_response(200)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            return
        else:
            self.send_error(404)

    def do_POST(self):
        # Add a simple JSON health endpoint at POST /health (optional)
        if self.path.strip("/") == "health":
            self.send_response(200)
            self.send_header('Content-type', 'application/json')
            self.end_headers()
            self.wfile.write(json.dumps({"status": "ok"}).encode())
            return
        self.send_error(404)

    def log_message(self, format, *args):
        # suppress default http.server logging
        return

PORT = 6000

if __name__ == "__main__":
    socketserver.TCPServer.allow_reuse_address = True
    try:
        class ThreadingHTTPServer(socketserver.ThreadingTCPServer):
            daemon_threads = True
            allow_reuse_address = True

        with ThreadingHTTPServer(("", PORT), MemoryRequestHandler) as httpd:
            print(f"[MEMORY SERVER] Running on port {PORT} (Threaded)")
            httpd.serve_forever()
    except KeyboardInterrupt:
        sys.exit(0)
    except Exception as e:
        print(f"FATAL: Server Crash - {e}")
        sys.exit(1)

========================================================================================================================
FILE: memory\shm_ring.py
========================================================================================================================
# FILE: memory/shm_ring.py
# ------------------------------------------------------------------------------
import os
import struct
import time
import atexit
import tempfile
from typing import Optional
from multiprocessing import shared_memory
import logging

try:
    from memory.errors.fatal import BackendInitializationError
except Exception:
    class BackendInitializationError(Exception):
        pass


MAGIC = b"IVIS"
VERSION = 1
HEADER_FMT = "<4sIIII"
HEADER_SIZE = struct.calcsize(HEADER_FMT)
PAYLOAD_LEN_FMT = "<I"
PAYLOAD_LEN_SIZE = struct.calcsize(PAYLOAD_LEN_FMT)


class _Mutex:
    """Cross-platform mutex.

    On Windows uses a named mutex via ctypes. On POSIX platforms uses a file lock
    in the system temp directory (via fcntl.flock). The file-based lock keeps a
    file descriptor open for the lifetime of the mutex object.
    """

    def __init__(self, name: str):
        self.name = name
        self._handle = None
        self._is_windows = os.name == "nt"
        if self._is_windows:
            import ctypes

            self._ctypes = ctypes
            # Create a named mutex (NULL security, not owned initially)
            self._handle = self._ctypes.windll.kernel32.CreateMutexW(None, False, name)
        else:
            # POSIX: use a lock file in the temp directory
            self._lock_dir = tempfile.gettempdir()
            self._lock_path = os.path.join(self._lock_dir, f"{name}.lock")
            # open file in append+binary so it is shareable and persists
            # keep the file descriptor as the handle for fcntl locks
            self._handle = open(self._lock_path, "a+b")

    def __enter__(self):
        if self._is_windows and self._handle:
            # WAIT_INFINITE = 0xFFFFFFFF
            self._ctypes.windll.kernel32.WaitForSingleObject(self._handle, 0xFFFFFFFF)
        elif self._handle:
            # local import to avoid failing on Windows where fcntl is absent
            import fcntl

            fcntl.flock(self._handle, fcntl.LOCK_EX)
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self._is_windows and self._handle:
            self._ctypes.windll.kernel32.ReleaseMutex(self._handle)
        elif self._handle:
            import fcntl

            try:
                fcntl.flock(self._handle, fcntl.LOCK_UN)
            except Exception:
                # best-effort unlock
                pass

    def __del__(self):
        try:
            if not self._is_windows and self._handle:
                try:
                    self._handle.close()
                except Exception:
                    pass
        except Exception:
            pass


logger = logging.getLogger("ivis.shm_ring")


class ShmRing:
    def __init__(
        self,
        data_name: str,
        meta_name: str,
        slot_size: int,
        slot_count: int,
        create: bool = False,
        recreate_on_mismatch: bool = True,
    ):
        self.data_name = data_name
        self.meta_name = meta_name
        self.slot_size = slot_size
        self.slot_count = slot_count
        self._mutex = _Mutex(f"{data_name}_mutex")
        self._owner = create
        self._payload_offset = HEADER_SIZE + (slot_count * 4)
        self._has_payload_lengths = False

        meta_size = HEADER_SIZE + (slot_count * 4) + (slot_count * PAYLOAD_LEN_SIZE)
        if create:
            try:
                self.data = shared_memory.SharedMemory(name=data_name, create=True, size=slot_size * slot_count)
                self.meta = shared_memory.SharedMemory(name=meta_name, create=True, size=meta_size)
                self._has_payload_lengths = self.meta.size >= (self._payload_offset + (slot_count * PAYLOAD_LEN_SIZE))
                self._init_meta()
            except FileExistsError:
                self._warn_existing()
                self.data = shared_memory.SharedMemory(name=data_name, create=False)
                self.meta = shared_memory.SharedMemory(name=meta_name, create=False)
                self._has_payload_lengths = self.meta.size >= (self._payload_offset + (slot_count * PAYLOAD_LEN_SIZE))
                try:
                    self._validate_meta()
                except BackendInitializationError:
                    if not recreate_on_mismatch:
                        raise
                    self._warn_recreate()
                    self._cleanup()
                    self.data = shared_memory.SharedMemory(name=data_name, create=True, size=slot_size * slot_count)
                    self.meta = shared_memory.SharedMemory(name=meta_name, create=True, size=meta_size)
                    self._has_payload_lengths = self.meta.size >= (self._payload_offset + (slot_count * PAYLOAD_LEN_SIZE))
                    self._init_meta()
        else:
            self.data = shared_memory.SharedMemory(name=data_name, create=False)
            self.meta = shared_memory.SharedMemory(name=meta_name, create=False)
            self._has_payload_lengths = self.meta.size >= (self._payload_offset + (slot_count * PAYLOAD_LEN_SIZE))
            self._validate_meta()

        self.data_buf = self.data.buf
        self.meta_buf = self.meta.buf

        # If this process created the segments, try to unlink them on clean exit
        if self._owner:
            try:
                atexit.register(self.close_unlink, True)
            except Exception:
                logger.warning("Failed to register atexit handler for shm cleanup")

    def _init_meta(self):
        struct.pack_into(
            HEADER_FMT,
            self.meta.buf,
            0,
            MAGIC,
            VERSION,
            self.slot_size,
            self.slot_count,
            0,
        )
        for i in range(self.slot_count):
            struct.pack_into("<I", self.meta.buf, HEADER_SIZE + (i * 4), 0)
        if self._has_payload_lengths:
            for i in range(self.slot_count):
                struct.pack_into(PAYLOAD_LEN_FMT, self.meta.buf, self._payload_offset + (i * PAYLOAD_LEN_SIZE), 0)

    def _validate_meta(self):
        magic, version, slot_size, slot_count, _ = struct.unpack_from(HEADER_FMT, self.meta.buf, 0)
        if magic != MAGIC or version != VERSION:
            raise BackendInitializationError("Shared memory header mismatch")
        if slot_size != self.slot_size or slot_count != self.slot_count:
            raise BackendInitializationError("Shared memory layout mismatch")

    def _get_write_index(self) -> int:
        _, _, _, _, idx = struct.unpack_from(HEADER_FMT, self.meta_buf, 0)
        return idx

    def _set_write_index(self, idx: int) -> None:
        magic, version, slot_size, slot_count, _ = struct.unpack_from(HEADER_FMT, self.meta_buf, 0)
        struct.pack_into(HEADER_FMT, self.meta_buf, 0, magic, version, slot_size, slot_count, idx)

    def _get_generation(self, slot: int) -> int:
        return struct.unpack_from("<I", self.meta_buf, HEADER_SIZE + (slot * 4))[0]

    def _set_generation(self, slot: int, gen: int) -> None:
        struct.pack_into("<I", self.meta_buf, HEADER_SIZE + (slot * 4), gen)

    def _get_payload_length(self, slot: int) -> int:
        if not self._has_payload_lengths:
            return self.slot_size
        return struct.unpack_from(PAYLOAD_LEN_FMT, self.meta_buf, self._payload_offset + (slot * PAYLOAD_LEN_SIZE))[0]

    def _set_payload_length(self, slot: int, length: int) -> None:
        if not self._has_payload_lengths:
            return
        struct.pack_into(PAYLOAD_LEN_FMT, self.meta_buf, self._payload_offset + (slot * PAYLOAD_LEN_SIZE), length)

    def _record_bytes(self, count: int) -> None:
        try:
            import ivis_metrics
            ivis_metrics.shm_bytes_copied_total.inc(int(count))
        except Exception:
            pass

    def _record_latency(self, metric_name: str, value_ms: float) -> None:
        try:
            import ivis_metrics
            metric = getattr(ivis_metrics, metric_name, None)
            if metric is not None:
                metric.observe(float(value_ms))
        except Exception:
            pass

    def write(self, data):
        start_ts = time.perf_counter()
        view = memoryview(data)
        if view.ndim != 1:
            view = view.cast("B")
        payload_len = view.nbytes
        if payload_len > self.slot_size:
            raise ValueError(f"Invalid frame size: {payload_len} (expected <= {self.slot_size})")
        if not self._has_payload_lengths and payload_len != self.slot_size:
            raise ValueError(f"Invalid frame size: {payload_len} (expected {self.slot_size})")
        with self._mutex:
            slot = self._get_write_index() % self.slot_count
            gen = (self._get_generation(slot) + 1) & 0xFFFFFFFF
            start = slot * self.slot_size
            end = start + payload_len
            self.data_buf[start:end] = view
            self._set_generation(slot, gen)
            self._set_payload_length(slot, payload_len)
            self._set_write_index(slot + 1)
        self._record_bytes(payload_len)
        self._record_latency("shm_write_latency_ms", (time.perf_counter() - start_ts) * 1000.0)
        logger.debug("SHM write: data_name=%s slot=%s gen=%s bytes=%s", self.data_name, slot, gen, payload_len)
        return slot, gen

    def read(self, slot: int, gen: int, retries: int = 3):
        """
        Reads data from the specified slot securely using optimistic concurrency control.
        If the generation changes during the read (indicating a write occurred),
        it retries up to `retries` times.
        """
        start_ts = time.perf_counter()
        if slot < 0 or slot >= self.slot_count:
            return None

        # Try to read, retry if torn
        for _ in range(retries):
            # 1. Pre-check: Verify generation matches request
            # We don't need the mutex for reading if we use optimistic concurrency,
            # but we use it here to ensure we don't read completely garbage pointers if resizing.
            # However, for pure data consistency, the generation check is key.
            # Ideally, we read without lock for speed, but Python's shm access is safe enough.
            # We will use the mutex for metadata consistency but minimize holding it during copy if possible.
            # CAUTION: For maximum speed we might avoid mutex during copy, but let's stick to
            # the design: The mutex primarily protects metadata. The data buffer is just memory.
            
            with self._mutex:
                current_before = self._get_generation(slot)
            
            if current_before != gen:
                # Slot has already been overwritten before we started
                logger.debug(
                    "SHM read miss (pre-check): slot=%s expected_gen=%s current_gen=%s",
                    slot,
                    gen,
                    current_before,
                )
                return None

            # 2. Copy data
            # We calculate offsets. Note: The data might be changing RIGHT NOW.
            start = slot * self.slot_size
            # We must read the payload length carefully.
            # If payload length is being updated, we might get a wrong value.
            # But the generation check after will catch this.
            payload_len = self._get_payload_length(slot)
            if payload_len <= 0 or payload_len > self.slot_size:
                payload_len = self.slot_size
            
            end = start + payload_len
            # Validating bounds just in case
            if end > len(self.data_buf):
                # Should not happen if init is correct
                return None
                
            # PERFORM THE COPY
            # This is the critical section where a race can occur.
            data = bytes(self.data_buf[start:end])

            # 3. Post-check: Verify generation hasn't changed
            with self._mutex:
                current_after = self._get_generation(slot)

            if current_before == current_after:
                # Success! Consistent read.
                logger.debug("SHM read success: slot=%s gen=%s bytes=%s", slot, gen, len(data))
                self._record_bytes(payload_len)
                self._record_latency("shm_read_latency_ms", (time.perf_counter() - start_ts) * 1000.0)
                return data
            
            # If we are here, a write happened during our read. Retry.
            logger.debug("SHM torn read detected (retry): slot=%s gen=%s", slot, gen)
            continue
            
        # If we exhausted retries, it means the writer is lapping us very fast.
        return None

    def read_latest(self, retries: int = 3):
        """
        Reads the latest written slot. Retries if the slot is overwritten during read.
        """
        start_ts = time.perf_counter()
        
        for _ in range(retries):
            with self._mutex:
                # Find the latest written index
                write_idx = self._get_write_index()
                # The latest complete frame is at write_idx - 1
                idx = (write_idx - 1) % self.slot_count
                gen = self._get_generation(idx)
                payload_len = self._get_payload_length(idx)

            if payload_len <= 0 or payload_len > self.slot_size:
                payload_len = self.slot_size
                
            start = idx * self.slot_size
            end = start + payload_len

            # buffer copy
            data = bytes(self.data_buf[start:end])

            # Verify it's still the same frame
            with self._mutex:
                gen_after = self._get_generation(idx)
            
            if gen == gen_after:
                logger.debug("SHM read_latest success: slot=%s gen=%s bytes=%s", idx, gen, len(data))
                self._record_bytes(payload_len)
                self._record_latency("shm_read_latency_ms", (time.perf_counter() - start_ts) * 1000.0)
                return data, idx, gen
            
            # Retry
            logger.debug("SHM read_latest torn read (retry)")
        
        return None, -1, 0

    def close(self):
        self.close_unlink(unlink=False)

    def close_unlink(self, unlink: bool = False):
        try:
            self.data.close()
        except Exception:
            pass
        try:
            self.meta.close()
        except Exception:
            pass
        if unlink:
            try:
                self.data.unlink()
            except Exception:
                pass
            try:
                self.meta.unlink()
            except Exception:
                pass

    @staticmethod
    def exists(data_name: str, meta_name: str) -> bool:
        data = None
        meta = None
        try:
            data = shared_memory.SharedMemory(name=data_name, create=False)
            meta = shared_memory.SharedMemory(name=meta_name, create=False)
            return True
        except FileNotFoundError:
            return False
        finally:
            if data is not None:
                try:
                    data.close()
                except Exception:
                    pass
            if meta is not None:
                try:
                    meta.close()
                except Exception:
                    pass

    def _warn_existing(self) -> None:
        logger.warning("Existing shared memory detected: %s, %s", self.data_name, self.meta_name)

    def _warn_recreate(self) -> None:
        logger.warning(
            "Recreating shared memory due to mismatch: %s, %s", self.data_name, self.meta_name
        )

    def _cleanup(self):
        try:
            self.data.close()
        except Exception:
            pass
        try:
            self.meta.close()
        except Exception:
            pass
        try:
            self.data.unlink()
        except Exception:
            pass
        try:
            self.meta.unlink()
        except Exception:
            pass

========================================================================================================================
FILE: pyproject.toml
========================================================================================================================
[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "ivisv"
version = "0.1.0"
description = "IVISv video analytics system"
readme = "README.md"
requires-python = ">=3.8"

[project.optional-dependencies]
dev = [
    "ruff>=0.4.0",
    "mypy>=1.8.0",
    "pytest>=7.0",
]

[tool.setuptools]
[tool.setuptools.packages.find]
where = ["src"]
include = ["ivis*"]

[project.scripts]
ivis-run-system = "ivis.run_system:main"
ivis-ingestion = "ivis.ingestion.main:main"
ivis-detection = "ivis.detection.main:main"
ivis-ui = "ivis.ui.live_view:main"
lint = "ivis.devtools:lint"
typecheck = "ivis.devtools:typecheck"
test = "ivis.devtools:test"

[tool.ruff]
target-version = "py38"
select = ["E9", "F63", "F7", "F82"]

[tool.mypy]
python_version = "3.8"
ignore_missing_imports = true
check_untyped_defs = false
exclude = "^(ivis/|src/ivis/legacy/)"
mypy_path = "src"
follow_imports = "skip"

========================================================================================================================
FILE: requirements.txt
========================================================================================================================
numpy
opencv-python
requests
ultralytics
torch
torchvision
deep_sort_realtime
torchreid
pyzmq
psycopg2-binary
flask
PyYAML==6.0.3
prometheus_client
opentelemetry-api
opentelemetry-sdk
opentelemetry-exporter-otlp-proto-http
opentelemetry-instrumentation

========================================================================================================================
FILE: run_system.original.py
========================================================================================================================
# ------------------------------------------------------------------------------
# FILE: run_system.py
# ------------------------------------------------------------------------------
import argparse
import json
import os
import platform
import subprocess
import sys
import time
from ivis_logging import setup_logging
from common.settings import SETTINGS

# ------------------------------------------------------------------------------
# Project Root (IMPORTANT)
# ------------------------------------------------------------------------------
PROJECT_ROOT = os.path.abspath(os.path.dirname(__file__))

# ------------------------------------------------------------------------------
# Ensure logs directory exists
# ------------------------------------------------------------------------------
LOG_DIR = os.path.join(PROJECT_ROOT, "logs")
os.makedirs(LOG_DIR, exist_ok=True)

# Always use the current interpreter to avoid mismatched environments.
PYTHON_EXE = sys.executable
logger = setup_logging("orchestrator")
logger.info("Using Python executable for services: %s", PYTHON_EXE)


class ServiceProcess:
    def __init__(self, name, command, env):
        self.name = name
        self.command = command
        self.env = env
        self.process = None
        self.out_file = None
        self.err_file = None
        self.restarts = 0
        self.max_restarts = 5
        self.last_restart_time = 0
    
    def start(self):
        logger.info(f"Starting service: {self.name}")
        self.out_file = open(os.path.join(LOG_DIR, f"{self.name}.out"), "a") # append mode for restarts
        self.err_file = open(os.path.join(LOG_DIR, f"{self.name}.err"), "a")
        
        # Ensure child processes can import project-top-level modules
        process_env = os.environ.copy()
        if self.env:
            process_env.update(self.env)
        existing = process_env.get("PYTHONPATH")
        if existing:
            process_env["PYTHONPATH"] = PROJECT_ROOT + os.pathsep + existing
        else:
            process_env["PYTHONPATH"] = PROJECT_ROOT
            
        try:
            self.process = subprocess.Popen(
                self.command,
                env=process_env,
                cwd=PROJECT_ROOT,
                stdout=self.out_file,
                stderr=self.err_file,
            )
            return True
        except Exception as e:
            logger.error(f"Failed to start {self.name}: {e}")
            return False

    def is_alive(self):
        return self.process is not None and self.process.poll() is None

    def stop(self):
        if self.process:
            try:
                self.process.terminate()
                self.process.wait(timeout=2)
            except Exception:
                try:
                    self.process.kill()
                except Exception:
                    pass
        self._close_files()

    def _close_files(self):
        try:
            if self.out_file: self.out_file.close()
            if self.err_file: self.err_file.close()
        except Exception:
            pass
        self.out_file = None
        self.err_file = None

    def check_and_restart(self):
        if self.process is None:
            return # Not started yet
        
        ret_code = self.process.poll()
        if ret_code is not None:
            logger.warning(f"Service {self.name} died with return code {ret_code}")
            
            # Reset restart count if it's been alive for a while (> 60s)
            now = time.time()
            if now - self.last_restart_time > 60:
                self.restarts = 0
            
            if self.restarts < self.max_restarts:
                self.restarts += 1
                wait_time = min(self.restarts * 2, 30)
                logger.info(f"Restarting {self.name} in {wait_time}s (Attempt {self.restarts}/{self.max_restarts})")
                self._close_files()
                time.sleep(wait_time)
                self.last_restart_time = time.time()
                self.start()
            else:
                logger.error(f"Service {self.name} failed too many times. Giving up.")
                return False # Failed permanently
        return True # Alive or successfully restarted


def _resolve_source(args, base_env):
    if args.webcam is not None:
        source = str(args.webcam)
        source_type = "webcam"
    else:
        source = args.source or base_env.get("RTSP_URL") or "0"
        source_type = args.source_type or "auto"

    source = source.strip()
    expanded = os.path.abspath(os.path.expanduser(source))
    is_url = source.lower().startswith(("rtsp://", "http://", "https://"))
    file_exists = os.path.isfile(expanded)

    if source_type == "file":
        if not file_exists:
            raise ValueError(f"Source file not found: {expanded}")
        return expanded, "file"
    if source_type == "webcam":
        if not source.isdigit():
            raise ValueError("Webcam source must be a numeric index (e.g. 0)")
        return source, "webcam"
    if source_type == "rtsp":
        return source, "rtsp"

    # auto detection
    if file_exists:
        return expanded, "file"
    if source.isdigit():
        return source, "webcam"
    if is_url:
        return source, "rtsp"
    # Fall back to raw string; ingestion will validate.
    return source, "rtsp"

def _load_config_file(path: str) -> dict:
    if not os.path.exists(path):
        raise ValueError(f"Config file not found: {path}")
    _, ext = os.path.splitext(path)
    ext = ext.lower()
    with open(path, "r", encoding="utf-8") as handle:
        if ext in (".json",):
            return json.load(handle)
        if ext in (".yaml", ".yml"):
            try:
                import yaml
            except Exception as exc:
                raise ValueError("PyYAML is required to load YAML config files") from exc
            return yaml.safe_load(handle) or {}
    raise ValueError("Unsupported config file format (use .json or .yaml)")


def _apply_env_map(target_env: dict, values: dict):
    for key, value in values.items():
        if value is None:
            continue
        target_env[key] = str(value)


def main(argv=None):
    print("=== Starting Video Analytics System (v1.1 Robust - Patched) ===")

    # ------------------------------------------------------------------------------
    # Base Environment (Clean)
    # ------------------------------------------------------------------------------
    parser = argparse.ArgumentParser(description="IVISv system launcher")
    parser.add_argument("--source", help="Video source (file path, RTSP URL, or webcam index)")
    parser.add_argument("--source-type", choices=["auto", "file", "webcam", "rtsp"], default="auto")
    parser.add_argument("--webcam", type=int, help="Webcam index (overrides --source)")
    parser.add_argument("--target-fps", type=int, default=15)
    parser.add_argument("--width", type=int, default=640)
    parser.add_argument("--height", type=int, default=480)
    parser.add_argument("--frame-color", choices=["bgr", "rgb"], default="bgr")
    parser.add_argument("--bus", choices=["zmq", "tcp"], default="zmq")
    parser.add_argument("--config", help="Path to JSON/YAML config file")
    loop_group = parser.add_mutually_exclusive_group()
    loop_group.add_argument("--loop", action="store_true", help="Loop local video files")
    loop_group.add_argument("--no-loop", action="store_true", help="Disable looping for local video files")
    args = parser.parse_args()

    base_env = os.environ.copy()
    # seed environment from centralized settings where appropriate
    try:
        base_env.update(SETTINGS.as_env())
    except Exception:
        pass
    config_data = None
    if args.config:
        config_data = _load_config_file(args.config)
        if isinstance(config_data, dict):
            if "env" in config_data and isinstance(config_data["env"], dict):
                _apply_env_map(base_env, config_data["env"])
            elif "ingestion" not in config_data and "detection" not in config_data and "ui" not in config_data:
                _apply_env_map(base_env, config_data)

    services = []

    # ------------------------------------------------------------------------------
    # 2. Ingestion Service
    # ------------------------------------------------------------------------------
    env_ingestion = base_env.copy()
    env_ingestion["MEMORY_BACKEND"] = "shm"
    env_ingestion["SHM_CACHE_SECONDS"] = "30"
    env_ingestion["SHM_OWNER"] = "1"
    if isinstance(config_data, dict) and isinstance(config_data.get("ingestion"), dict):
        _apply_env_map(env_ingestion, config_data["ingestion"])

    try:
        source, source_type = _resolve_source(args, base_env)
    except ValueError as exc:
        print(f"[ERROR] {exc}")
        sys.exit(1)
    env_ingestion["RTSP_URL"] = source
    env_ingestion["STREAM_ID"] = "cam_01_main"
    env_ingestion["CAMERA_ID"] = "cam_01"
    env_ingestion["TARGET_FPS"] = str(args.target_fps)

    env_ingestion["BUS_TRANSPORT"] = args.bus
    env_ingestion["ZMQ_PUB_ENDPOINT"] = "tcp://localhost:5555"
    env_ingestion["ZMQ_RESULTS_SUB_ENDPOINT"] = "tcp://localhost:5557"
    env_ingestion["FRAME_WIDTH"] = str(args.width)
    env_ingestion["FRAME_HEIGHT"] = str(args.height)
    source_color = args.frame_color or base_env.get("SOURCE_COLOR") or "bgr"
    env_ingestion["SOURCE_COLOR"] = source_color
    env_ingestion["FRAME_COLOR_SPACE"] = base_env.get("FRAME_COLOR_SPACE", "bgr")
    env_ingestion["SELECTOR_MODE"] = "clock"
    env_ingestion["ADAPTIVE_FPS"] = "true"
    env_ingestion["ADAPTIVE_MIN_FPS"] = "5"
    env_ingestion["ADAPTIVE_MAX_FPS"] = env_ingestion["TARGET_FPS"]
    env_ingestion["ADAPTIVE_SAFETY"] = "1.3"
    if args.loop:
        loop_enabled = True
    elif args.no_loop:
        loop_enabled = False
    else:
        loop_enabled = source_type == "file"
    if loop_enabled:
        env_ingestion["VIDEO_LOOP"] = "true"

    slot_size = int(env_ingestion["FRAME_WIDTH"]) * int(env_ingestion["FRAME_HEIGHT"]) * 3
    cache_seconds = float(env_ingestion.get("SHM_CACHE_SECONDS", "30"))
    cache_fps = float(env_ingestion["TARGET_FPS"])
    slot_count = max(1, int(cache_fps * cache_seconds))
    env_ingestion["SHM_CACHE_FPS"] = env_ingestion["TARGET_FPS"]
    env_ingestion["SHM_BUFFER_BYTES"] = str(slot_size * slot_count)
    env_ingestion["SHM_NAME"] = f"ivis_shm_data_{slot_size}_{slot_count}"
    env_ingestion["SHM_META_NAME"] = f"ivis_shm_meta_{slot_size}_{slot_count}"

    ingestion_svc = ServiceProcess(
        "ingestion",
        [PYTHON_EXE, "-m", "ingestion.main"],
        env=env_ingestion,
    )
    services.append(ingestion_svc)

    # ------------------------------------------------------------------------------
    # 3. Detection Service
    # ------------------------------------------------------------------------------
    env_detection = base_env.copy()
    env_detection["MODEL_NAME"] = "YOLO11"
    env_detection["MODEL_VERSION"] = "v11"
    env_detection["MODEL_HASH"] = "yolo11"
    default_model = os.path.join(PROJECT_ROOT, "models", "yolo.pt")
    shipped_model = os.path.join(PROJECT_ROOT, "yolo11n.pt")
    if os.path.exists(default_model):
        env_detection["MODEL_PATH"] = default_model
    elif os.path.exists(shipped_model):
        env_detection["MODEL_PATH"] = os.path.abspath(shipped_model)
    else:
        env_detection["MODEL_PATH"] = default_model
        print(f"[WARN] No model file found at '{default_model}' or '{shipped_model}'.")
    env_detection["INFERENCE_TIMEOUT"] = "2"
    env_detection["DEBUG"] = "true"
    env_detection["MODEL_DEVICE"] = "auto"
    env_detection["MODEL_HALF"] = "false"
    env_detection["MODEL_IMG_SIZE"] = "640"
    env_detection["MODEL_CONF"] = "0.25"
    env_detection["MODEL_IOU"] = "0.5"
    reid_default = os.path.join(PROJECT_ROOT, "models", "reid", "osnet_x0_25.pth")
    if os.path.exists(reid_default):
        env_detection["REID_MODEL_PATH"] = reid_default
    else:
        env_detection["REID_ALLOW_FALLBACK"] = "true"
        print(f"[WARN] ReID weights not found at '{reid_default}'. Falling back without custom weights.")
    env_detection["BUS_TRANSPORT"] = args.bus
    env_detection["ZMQ_SUB_ENDPOINT"] = env_ingestion.get("ZMQ_PUB_ENDPOINT", "tcp://localhost:5555")
    env_detection["ZMQ_RESULTS_PUB_ENDPOINT"] = "tcp://localhost:5557"
    env_detection["MEMORY_BACKEND"] = "shm"
    env_detection["SHM_OWNER"] = "0"
    env_detection["SHM_NAME"] = env_ingestion["SHM_NAME"]
    env_detection["SHM_META_NAME"] = env_ingestion["SHM_META_NAME"]
    env_detection["SHM_BUFFER_BYTES"] = env_ingestion["SHM_BUFFER_BYTES"]
    env_detection["SHM_CACHE_SECONDS"] = env_ingestion.get("SHM_CACHE_SECONDS", "30")
    env_detection["SHM_CACHE_FPS"] = env_ingestion.get("SHM_CACHE_FPS", env_ingestion["TARGET_FPS"])
    env_detection["FRAME_WIDTH"] = env_ingestion["FRAME_WIDTH"]
    env_detection["FRAME_HEIGHT"] = env_ingestion["FRAME_HEIGHT"]
    env_detection["KMP_DUPLICATE_LIB_OK"] = "TRUE"
    env_detection["FRAME_COLOR_SPACE"] = env_ingestion["FRAME_COLOR_SPACE"]
    env_detection["MAX_FRAME_AGE_MS"] = "1000"
    env_detection["TORCH_NUM_THREADS"] = "4"
    env_detection["TORCH_NUM_INTEROP_THREADS"] = "2"
    if isinstance(config_data, dict) and isinstance(config_data.get("detection"), dict):
        _apply_env_map(env_detection, config_data["detection"])

    detection_svc = ServiceProcess(
        "detection",
        [PYTHON_EXE, "-m", "detection.main"],
        env=env_detection,
    )
    services.append(detection_svc)

    # --------------------------------------------------------------------------
    # 4. UI Service (Live View)
    # --------------------------------------------------------------------------
    env_ui = base_env.copy()
    env_ui["DEBUG"] = "true"
    env_ui["ZMQ_SUB_ENDPOINT"] = env_ingestion.get("ZMQ_PUB_ENDPOINT", "tcp://localhost:5555")
    env_ui["ZMQ_RESULTS_SUB_ENDPOINT"] = env_detection.get("ZMQ_RESULTS_PUB_ENDPOINT", "tcp://localhost:5557")
    env_ui["SHM_OWNER"] = "0"
    env_ui["STREAM_ID"] = env_ingestion["STREAM_ID"]
    env_ui["CAMERA_ID"] = env_ingestion["CAMERA_ID"]
    env_ui["SHM_NAME"] = env_ingestion["SHM_NAME"]
    env_ui["SHM_META_NAME"] = env_ingestion["SHM_META_NAME"]
    env_ui["SHM_BUFFER_BYTES"] = env_ingestion["SHM_BUFFER_BYTES"]
    env_ui["SHM_CACHE_SECONDS"] = env_ingestion.get("SHM_CACHE_SECONDS", "30")
    env_ui["SHM_CACHE_FPS"] = env_ingestion.get("SHM_CACHE_FPS", env_ingestion["TARGET_FPS"])
    env_ui["FRAME_WIDTH"] = env_ingestion["FRAME_WIDTH"]
    env_ui["FRAME_HEIGHT"] = env_ingestion["FRAME_HEIGHT"]
    env_ui["FRAME_COLOR_SPACE"] = env_ingestion["FRAME_COLOR_SPACE"]
    if isinstance(config_data, dict) and isinstance(config_data.get("ui"), dict):
        _apply_env_map(env_ui, config_data["ui"])

    ui_svc = ServiceProcess(
        "ui",
        [PYTHON_EXE, "-m", "ui.live_view"],
        env=env_ui,
    )
    services.append(ui_svc)

    # ------------------------------------------------------------------------------
    # Start All
    # ------------------------------------------------------------------------------
    for svc in services:
        svc.start()

    print("\nSystem Running!")
    print(f"   Logs are being written to: {os.path.abspath('logs/')}")
    print("   UI is available at: http://127.0.0.1:8080")
    print("   Press Ctrl+C to stop all services.\n")

    # ------------------------------------------------------------------------------
    # Monitor Loop
    # ------------------------------------------------------------------------------
    try:
        while True:
            time.sleep(1)
            active_count = 0
            for svc in services:
                if not svc.check_and_restart():
                    logger.error(f"Service {svc.name} has failed permanently.")
                else:
                    active_count += 1
            
            if active_count == 0:
                print("All services have failed. Exiting.")
                break
                
    except KeyboardInterrupt:
        print("\nStopping System...")
    finally:
        for svc in services:
            svc.stop()
        print("All processes terminated.")

if __name__ == "__main__":
    main()

========================================================================================================================
FILE: run_system.py
========================================================================================================================
# ------------------------------------------------------------------------------
# FILE: run_system.py
# ------------------------------------------------------------------------------
import argparse
import json
import os
import platform
import subprocess
import sys
import time
from ivis_logging import setup_logging
from common.settings import SETTINGS

# ------------------------------------------------------------------------------
# Project Root (IMPORTANT)
# ------------------------------------------------------------------------------
PROJECT_ROOT = os.path.abspath(os.path.dirname(__file__))

# ------------------------------------------------------------------------------
# Ensure logs directory exists
# ------------------------------------------------------------------------------
LOG_DIR = os.path.join(PROJECT_ROOT, "logs")
os.makedirs(LOG_DIR, exist_ok=True)

# Always use the current interpreter to avoid mismatched environments.
PYTHON_EXE = sys.executable
logger = setup_logging("orchestrator")
logger.info("Using Python executable for services: %s", PYTHON_EXE)


class ServiceProcess:
    def __init__(self, name, command, env):
        self.name = name
        self.command = command
        self.env = env
        self.process = None
        self.out_file = None
        self.err_file = None
        self.restarts = 0
        self.max_restarts = 5
        self.last_restart_time = 0
    
    def start(self):
        logger.info(f"Starting service: {self.name}")
        self.out_file = open(os.path.join(LOG_DIR, f"{self.name}.out"), "a") # append mode for restarts
        self.err_file = open(os.path.join(LOG_DIR, f"{self.name}.err"), "a")
        
        # Ensure child processes can import project-top-level modules
        process_env = os.environ.copy()
        if self.env:
            process_env.update(self.env)
        existing = process_env.get("PYTHONPATH")
        if existing:
            process_env["PYTHONPATH"] = PROJECT_ROOT + os.pathsep + existing
        else:
            process_env["PYTHONPATH"] = PROJECT_ROOT
            
        try:
            self.process = subprocess.Popen(
                self.command,
                env=process_env,
                cwd=PROJECT_ROOT,
                stdout=self.out_file,
                stderr=self.err_file,
            )
            return True
        except Exception as e:
            logger.error(f"Failed to start {self.name}: {e}")
            return False

    def is_alive(self):
        return self.process is not None and self.process.poll() is None

    def stop(self):
        if self.process:
            try:
                self.process.terminate()
                self.process.wait(timeout=2)
            except Exception:
                try:
                    self.process.kill()
                except Exception:
                    pass
        self._close_files()

    def _close_files(self):
        try:
            if self.out_file: self.out_file.close()
            if self.err_file: self.err_file.close()
        except Exception:
            pass
        self.out_file = None
        self.err_file = None

    def check_and_restart(self):
        if self.process is None:
            return # Not started yet
        
        ret_code = self.process.poll()
        if ret_code is not None:
            logger.warning(f"Service {self.name} died with return code {ret_code}")
            
            # Reset restart count if it's been alive for a while (> 60s)
            now = time.time()
            if now - self.last_restart_time > 60:
                self.restarts = 0
            
            if self.restarts < self.max_restarts:
                self.restarts += 1
                wait_time = min(self.restarts * 2, 60)
                logger.info(f"Restarting {self.name} in {wait_time}s (Attempt {self.restarts}/{self.max_restarts})")
                self._close_files()
                time.sleep(wait_time)
                self.last_restart_time = time.time()
                self.start()
            else:
                logger.error(f"Service {self.name} failed too many times. Giving up.")
                return False # Failed permanently
        return True # Alive or successfully restarted


def _resolve_source(args, base_env):
    if args.webcam is not None:
        source = str(args.webcam)
        source_type = "webcam"
    else:
        source = args.source or base_env.get("RTSP_URL") or "0"
        source_type = args.source_type or "auto"

    source = source.strip()
    expanded = os.path.abspath(os.path.expanduser(source))
    is_url = source.lower().startswith(("rtsp://", "http://", "https://"))
    file_exists = os.path.isfile(expanded)

    if source_type == "file":
        if not file_exists:
            raise ValueError(f"Source file not found: {expanded}")
        return expanded, "file"
    if source_type == "webcam":
        if not source.isdigit():
            raise ValueError("Webcam source must be a numeric index (e.g. 0)")
        return source, "webcam"
    if source_type == "rtsp":
        return source, "rtsp"

    # auto detection
    if file_exists:
        return expanded, "file"
    if source.isdigit():
        return source, "webcam"
    if is_url:
        return source, "rtsp"
    # Fall back to raw string; ingestion will validate.
    return source, "rtsp"

def _load_config_file(path: str) -> dict:
    if not os.path.exists(path):
        raise ValueError(f"Config file not found: {path}")
    _, ext = os.path.splitext(path)
    ext = ext.lower()
    with open(path, "r", encoding="utf-8") as handle:
        if ext in (".json",):
            return json.load(handle)
        if ext in (".yaml", ".yml"):
            try:
                import yaml
            except Exception as exc:
                raise ValueError("PyYAML is required to load YAML config files") from exc
            return yaml.safe_load(handle) or {}
    raise ValueError("Unsupported config file format (use .json or .yaml)")


def _apply_env_map(target_env: dict, values: dict):
    for key, value in values.items():
        if value is None:
            continue
        target_env[key] = str(value)

def _wait_ready(service_name: str, url: str, timeout_sec: float = 15.0) -> bool:
    import urllib.request
    import urllib.error
    deadline = time.time() + timeout_sec
    while time.time() < deadline:
        try:
            with urllib.request.urlopen(url, timeout=1.0) as resp:
                if getattr(resp, "status", 200) == 200:
                    return True
        except Exception:
            pass
        time.sleep(0.5)
    
    # Diagnostics on failure
    print(f"[{service_name}] Readiness check failed after {timeout_sec}s.")
    state_url = url.replace("/ready", "/state")
    try:
        with urllib.request.urlopen(state_url, timeout=1.0) as resp:
            data = json.loads(resp.read().decode("utf-8"))
            checks = data.get("checks", {})
            print(f"[{service_name}] State Diagnostics:")
            for k, v in checks.items():
                if not v.get("ok"):
                    print(f"  - {k}: FAILED | Reason: {v.get('reason')} | Details: {v.get('details')}")
    except Exception as exc:
        print(f"[{service_name}] Could not fetch diagnostics from {state_url}: {exc}")

    return False


def main(argv=None):
    print("=== Starting Video Analytics System (v1.1 Robust - Patched) ===")

    # ------------------------------------------------------------------------------
    # Base Environment (Clean)
    # ------------------------------------------------------------------------------
    parser = argparse.ArgumentParser(description="IVISv system launcher")
    parser.add_argument("--source", help="Video source (file path, RTSP URL, or webcam index)")
    parser.add_argument("--source-type", choices=["auto", "file", "webcam", "rtsp"], default="auto")
    parser.add_argument("--webcam", type=int, help="Webcam index (overrides --source)")
    parser.add_argument("--target-fps", type=int, default=5)
    parser.add_argument("--width", type=int, default=640)
    parser.add_argument("--height", type=int, default=480)
    parser.add_argument("--frame-color", choices=["bgr", "rgb"], default="bgr")
    parser.add_argument("--bus", choices=["zmq", "tcp"], default="zmq")
    parser.add_argument("--config", help="Path to JSON/YAML config file")
    loop_group = parser.add_mutually_exclusive_group()
    loop_group.add_argument("--loop", action="store_true", help="Loop local video files")
    loop_group.add_argument("--no-loop", action="store_true", help="Disable looping for local video files")
    args = parser.parse_args()

    base_env = os.environ.copy()
    # seed environment from centralized settings where appropriate
    try:
        base_env.update(SETTINGS.as_env())
    except Exception:
        pass
    config_data = None
    if args.config:
        config_data = _load_config_file(args.config)
        if isinstance(config_data, dict):
            if "env" in config_data and isinstance(config_data["env"], dict):
                _apply_env_map(base_env, config_data["env"])
            elif "ingestion" not in config_data and "detection" not in config_data and "ui" not in config_data:
                _apply_env_map(base_env, config_data)

    services = []

    # ------------------------------------------------------------------------------
    # 2. Ingestion Service
    # ------------------------------------------------------------------------------
    env_ingestion = base_env.copy()
    env_ingestion["MEMORY_BACKEND"] = "shm"
    env_ingestion["SHM_CACHE_SECONDS"] = "30"
    env_ingestion["SHM_OWNER"] = "1"
    if isinstance(config_data, dict) and isinstance(config_data.get("ingestion"), dict):
        _apply_env_map(env_ingestion, config_data["ingestion"])

    env_ingestion["HEALTH_BIND"] = env_ingestion.get("HEALTH_BIND", "127.0.0.1")
    env_ingestion["INGESTION_HEALTH_PORT"] = env_ingestion.get("INGESTION_HEALTH_PORT", "9001")

    try:
        source, source_type = _resolve_source(args, base_env)
    except ValueError as exc:
        print(f"[ERROR] {exc}")
        sys.exit(1)
    env_ingestion["RTSP_URL"] = source
    env_ingestion["STREAM_ID"] = "cam_01_main"
    env_ingestion["CAMERA_ID"] = "cam_01"
    env_ingestion["TARGET_FPS"] = str(args.target_fps)

    env_ingestion["BUS_TRANSPORT"] = args.bus
    env_ingestion["ZMQ_PUB_ENDPOINT"] = "tcp://localhost:5555"
    env_ingestion["ZMQ_RESULTS_SUB_ENDPOINT"] = "tcp://localhost:5557"
    env_ingestion["FRAME_WIDTH"] = str(args.width)
    env_ingestion["FRAME_HEIGHT"] = str(args.height)
    source_color = args.frame_color or base_env.get("SOURCE_COLOR") or "bgr"
    env_ingestion["SOURCE_COLOR"] = source_color
    env_ingestion["FRAME_COLOR_SPACE"] = base_env.get("FRAME_COLOR_SPACE", "bgr")
    env_ingestion["SELECTOR_MODE"] = "clock"
    env_ingestion["ADAPTIVE_FPS"] = "true"
    env_ingestion["ADAPTIVE_MIN_FPS"] = "5"
    env_ingestion["ADAPTIVE_MAX_FPS"] = env_ingestion["TARGET_FPS"]
    env_ingestion["ADAPTIVE_SAFETY"] = "1.3"
    if args.loop:
        loop_enabled = True
    elif args.no_loop:
        loop_enabled = False
    else:
        loop_enabled = source_type == "file"
    if loop_enabled:
        env_ingestion["VIDEO_LOOP"] = "true"

    slot_size = int(env_ingestion["FRAME_WIDTH"]) * int(env_ingestion["FRAME_HEIGHT"]) * 3
    cache_seconds = float(env_ingestion.get("SHM_CACHE_SECONDS", "30"))
    cache_fps = float(env_ingestion["TARGET_FPS"])
    slot_count = max(1, int(cache_fps * cache_seconds))
    env_ingestion["SHM_CACHE_FPS"] = env_ingestion["TARGET_FPS"]
    env_ingestion["SHM_BUFFER_BYTES"] = str(slot_size * slot_count)
    env_ingestion["SHM_NAME"] = f"ivis_shm_data_{slot_size}_{slot_count}"
    env_ingestion["SHM_META_NAME"] = f"ivis_shm_meta_{slot_size}_{slot_count}"

    ingestion_svc = ServiceProcess(
        "ingestion",
        [PYTHON_EXE, "-m", "ingestion.main"],
        env=env_ingestion,
    )
    services.append(ingestion_svc)

    # ------------------------------------------------------------------------------
    # 3. Detection Service
    # ------------------------------------------------------------------------------
    env_detection = base_env.copy()
    env_detection["MODEL_NAME"] = "YOLO11"
    env_detection["MODEL_VERSION"] = "v11"
    env_detection["MODEL_HASH"] = "yolo11"
    default_model = os.path.join(PROJECT_ROOT, "models", "yolo.pt")
    shipped_model = os.path.join(PROJECT_ROOT, "yolo11n.pt")
    if os.path.exists(default_model):
        env_detection["MODEL_PATH"] = default_model
    elif os.path.exists(shipped_model):
        env_detection["MODEL_PATH"] = os.path.abspath(shipped_model)
    else:
        env_detection["MODEL_PATH"] = default_model
        print(f"[WARN] No model file found at '{default_model}' or '{shipped_model}'.")
    env_detection["INFERENCE_TIMEOUT"] = "2"
    env_detection["DEBUG"] = "true"
    env_detection["MODEL_DEVICE"] = "auto"
    env_detection["MODEL_HALF"] = "false"
    env_detection["MODEL_IMG_SIZE"] = "640"
    env_detection["MODEL_CONF"] = "0.25"
    env_detection["MODEL_IOU"] = "0.5"
    reid_default = os.path.join(PROJECT_ROOT, "models", "reid", "osnet_x0_25.pth")
    if os.path.exists(reid_default):
        env_detection["REID_MODEL_PATH"] = reid_default
    else:
        env_detection["REID_ALLOW_FALLBACK"] = "true"
        print(f"[WARN] ReID weights not found at '{reid_default}'. Falling back without custom weights.")
    env_detection["BUS_TRANSPORT"] = args.bus
    env_detection["ZMQ_SUB_ENDPOINT"] = env_ingestion.get("ZMQ_PUB_ENDPOINT", "tcp://localhost:5555")
    env_detection["ZMQ_RESULTS_PUB_ENDPOINT"] = "tcp://localhost:5557"
    env_detection["MEMORY_BACKEND"] = "shm"
    env_detection["SHM_OWNER"] = "0"
    env_detection["SHM_NAME"] = env_ingestion["SHM_NAME"]
    env_detection["SHM_META_NAME"] = env_ingestion["SHM_META_NAME"]
    env_detection["SHM_BUFFER_BYTES"] = env_ingestion["SHM_BUFFER_BYTES"]
    env_detection["SHM_CACHE_SECONDS"] = env_ingestion.get("SHM_CACHE_SECONDS", "30")
    env_detection["SHM_CACHE_FPS"] = env_ingestion.get("SHM_CACHE_FPS", env_ingestion["TARGET_FPS"])
    env_detection["FRAME_WIDTH"] = env_ingestion["FRAME_WIDTH"]
    env_detection["FRAME_HEIGHT"] = env_ingestion["FRAME_HEIGHT"]
    env_detection["KMP_DUPLICATE_LIB_OK"] = "TRUE"
    env_detection["FRAME_COLOR_SPACE"] = env_ingestion["FRAME_COLOR_SPACE"]
    env_detection["MAX_FRAME_AGE_MS"] = "5000"
    env_detection["TORCH_NUM_THREADS"] = "4"
    env_detection["TORCH_NUM_INTEROP_THREADS"] = "2"
    if isinstance(config_data, dict) and isinstance(config_data.get("detection"), dict):
        _apply_env_map(env_detection, config_data["detection"])

    env_detection["HEALTH_BIND"] = env_detection.get("HEALTH_BIND", "127.0.0.1")
    env_detection["DETECTION_HEALTH_PORT"] = env_detection.get("DETECTION_HEALTH_PORT", "9002")

    detection_svc = ServiceProcess(
        "detection",
        [PYTHON_EXE, "-m", "detection.main"],
        env=env_detection,
    )
    services.append(detection_svc)

    # --------------------------------------------------------------------------
    # 4. UI Service (Live View)
    # --------------------------------------------------------------------------
    env_ui = base_env.copy()
    env_ui["DEBUG"] = "true"
    env_ui["ZMQ_SUB_ENDPOINT"] = env_ingestion.get("ZMQ_PUB_ENDPOINT", "tcp://localhost:5555")
    env_ui["ZMQ_RESULTS_SUB_ENDPOINT"] = env_detection.get("ZMQ_RESULTS_PUB_ENDPOINT", "tcp://localhost:5557")
    env_ui["SHM_OWNER"] = "0"
    env_ui["STREAM_ID"] = env_ingestion["STREAM_ID"]
    env_ui["CAMERA_ID"] = env_ingestion["CAMERA_ID"]
    env_ui["SHM_NAME"] = env_ingestion["SHM_NAME"]
    env_ui["SHM_META_NAME"] = env_ingestion["SHM_META_NAME"]
    env_ui["SHM_BUFFER_BYTES"] = env_ingestion["SHM_BUFFER_BYTES"]
    env_ui["SHM_CACHE_SECONDS"] = env_ingestion.get("SHM_CACHE_SECONDS", "30")
    env_ui["SHM_CACHE_FPS"] = env_ingestion.get("SHM_CACHE_FPS", env_ingestion["TARGET_FPS"])
    env_ui["FRAME_WIDTH"] = env_ingestion["FRAME_WIDTH"]
    env_ui["FRAME_HEIGHT"] = env_ingestion["FRAME_HEIGHT"]
    env_ui["FRAME_COLOR_SPACE"] = env_ingestion["FRAME_COLOR_SPACE"]
    if isinstance(config_data, dict) and isinstance(config_data.get("ui"), dict):
        _apply_env_map(env_ui, config_data["ui"])

    ui_svc = ServiceProcess(
        "ui",
        [PYTHON_EXE, "-m", "ui.live_view"],
        env=env_ui,
    )
    services.append(ui_svc)

    # ------------------------------------------------------------------------------
    # Start All
    # ------------------------------------------------------------------------------
    for svc in services:
        svc.start()

    ingestion_ready_url = f"http://{env_ingestion['HEALTH_BIND']}:{env_ingestion['INGESTION_HEALTH_PORT']}/ready"
    detection_ready_url = f"http://{env_detection['HEALTH_BIND']}:{env_detection['DETECTION_HEALTH_PORT']}/ready"

    if not _wait_ready("ingestion", ingestion_ready_url, 60.0):
        logger.warning("Ingestion not ready within timeout: %s", ingestion_ready_url)
    if not _wait_ready("detection", detection_ready_url, 120.0):
        logger.warning("Detection not ready within timeout: %s", detection_ready_url)


    print("\nSystem Running!")
    print(f"   Logs are being written to: {os.path.abspath('logs/')}")
    print("   UI is available at: http://127.0.0.1:8080")
    print(f"   Ingestion health: http://{env_ingestion['HEALTH_BIND']}:{env_ingestion['INGESTION_HEALTH_PORT']}/health")
    print(f"   Detection health: http://{env_detection['HEALTH_BIND']}:{env_detection['DETECTION_HEALTH_PORT']}/health")
    print("   Press Ctrl+C to stop all services.\n")

    # ------------------------------------------------------------------------------
    # Monitor Loop
    # ------------------------------------------------------------------------------
    try:
        while True:
            time.sleep(1)
            active_count = 0
            for svc in services:
                if not svc.check_and_restart():
                    logger.error(f"Service {svc.name} has failed permanently.")
                else:
                    active_count += 1
            
            if active_count == 0:
                print("All services have failed. Exiting.")
                break
                
    except KeyboardInterrupt:
        print("\nStopping System...")
    finally:
        for svc in services:
            svc.stop()
        print("All processes terminated.")

if __name__ == "__main__":
    main()

========================================================================================================================
FILE: scripts\create_sample_video.py
========================================================================================================================
import cv2
import numpy as np
w,h=640,480
fourcc=cv2.VideoWriter_fourcc(*'mp4v')
out=cv2.VideoWriter('sample.mp4', fourcc, 15.0, (w,h))
for i in range(60):
    frame = np.zeros((h,w,3), dtype='uint8')
    cv2.putText(frame, f'frame {i}', (50,100), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,255,0), 3)
    out.write(frame)
out.release()
print('WROTE sample.mp4')

========================================================================================================================
FILE: scripts\regression_smoke.py
========================================================================================================================

import unittest
import sys
import os
import json
from unittest.mock import MagicMock, patch

# Adjust path to include project root
sys.path.append(os.path.abspath(os.path.dirname(__file__) + "/.."))

from detection.ingest.consumer import ZmqFrameConsumer
from detection.postprocess.parse import parse_output

class TestRegression(unittest.TestCase):
    def test_zmq_consumer_connect_idempotent(self):
        """Test that ZmqFrameConsumer.connect() is idempotent."""
        consumer = ZmqFrameConsumer(endpoint="tcp://localhost:5555")
        consumer.zmq = MagicMock()
        mock_ctx = MagicMock()
        consumer.zmq.Context.instance.return_value = mock_ctx
        mock_socket = MagicMock()
        mock_ctx.socket.return_value = mock_socket

        # First connect
        consumer.connect()
        mock_socket.connect.assert_called_once_with("tcp://localhost:5555")
        
        # Second connect
        consumer.connect()
        # Should still be called only once
        mock_socket.connect.assert_called_once_with("tcp://localhost:5555")
        
        print("\n[PASS] test_zmq_consumer_connect_idempotent")

    def test_track_id_one_to_one_matching(self):
        """Test global one-to-one matching for track_id assignment."""
        # Setup: 2 tracks, 2 detections.
        # Track 0 (ID 100) overlaps Det 0 (IoU 0.9) and Det 1 (IoU 0.5)
        # Track 1 (ID 101) overlaps Det 1 (IoU 0.9)
        # Old greedy logic might assign Track 0 to Det 1 if processed first? 
        # Actually greedy logic usually assigns best IoU first if sorted? 
        # Or simple iteration: for det in dets: find best track.
        # If Det 1 comes first, it sees Track 0 (0.5) and Track 1 (0.9). Picks Track 1.
        # If Det 0 comes next, it sees Track 0 (0.9). Picks Track 0.
        # Result: T1->D1, T0->D0. Correct.
        
        # Let's try ambiguous case:
        # T0 (ID 100) overlaps D0 (0.4)
        # T1 (ID 101) overlaps D0 (0.5 - better)
        # D1 overlaps T1 (0.9 - best for T1)
        # Greedy per detection (D0 then D1):
        # D0 looks at T0(0.4), T1(0.5). Picks T1.
        # D1 looks at T1(0.9) -> T1 ALREADY USED (if flag set).
        # If logic is: "for det... unused.discard(best_idx)".
        # D0 picks T1. D1 finds T1 used. D1 gets NOTHING (or T0 if overlaps).
        # Global optimal: D1-T1 (0.9) is strongest match. D0 should get T0 (0.4).
        
        frame_contract = {
            "frame_id": "f1", "stream_id": "s1", "camera_id": "c1", 
            "timestamp_ms": 1000, "mono_ms": 1000, "memory": "shm://1"
        }
        
        # BBox format: [x1, y1, x2, y2]
        # D0: [0, 0, 100, 100]
        # D1: [100, 0, 200, 100]
        
        # T0: [0, 0, 100, 100] (IoU 1.0 with D0)
        # T1: [100, 0, 200, 100] (IoU 1.0 with D1)
        # Let's make it tricky.
        
        # Case: D0 overlaps T0(0.4) and T1(0.6)
        #       D1 overlaps T1(0.9)
        # Expectation: T1 matches D1 (0.9 > 0.6). T0 matches D0.
        
        # D0: [0,0, 100,100] Area 10000
        # T0: [0,0, 60, 60] Area 3600. Intersection [0,0,60,60]=3600. IoU = 3600 / (10000+3600-3600) = 0.36
        
        # Let's just mock exact IoU logic behavior by using non-overlapping boxes in space 
        # but overlapping logic? No, must be real geometry.
        
        raw_results = {
            "timing": {},
            "detections": [
                [[0,0,100,100], 0.9, 1], # D0
                [[200,0,300,100], 0.9, 1], # D1
            ],
            "tracks": []
        }
        
        # We need specific overlaps.
        # T0 overlaps D0 (0.4), T1 overlaps D0 (0.5), T1 overlaps D1 (0.9)
        # Impossible geometry? 
        # Only if T1 covers D0 and D1? BBox can be large.
        
        # Let's use simple logic check:
        # D0 is a small box inside T1.
        # D1 is the main match for T1.
        
        # T1: [0,0, 300,100] (Large box covering D0 and D1)
        # D0: [10,10, 50,50] (Inside T1)
        # D1: [200,10, 290,90] (Inside T1, better fit?)
        # Let's just create raw tracks.
        
        # We will trust the implementation to use IoU.
        # Let's use exact coordinates.
        
        # D0 at 10,10, 20,20. 10x10=100.
        # D1 at 30,10, 40,20. 10x10=100.
        
        # T0 overlaps D0 perfectly. [10,10,20,20]. ID=100.
        # T1 overlaps D0 perfectly also? No duplicate tracks usually.
        
        # Scenario from prompt: "One-to-one... IoU-based but globally consistent"
        # D0 overlaps T0 (0.8). D1 overlaps T0 (0.9).
        # Greedy D0 first: Picks T0. D1 gets nothing.
        # Global: D1 picks T0 (0.9 > 0.8). D0 gets nothing.
        
        raw_results["detections"] = [
            [[10,10,20,20], 0.9, 1], # D0
            [[11,11,21,21], 0.9, 1], # D1 (Shifted by 1, matches T0 very well)
        ]
        
        # T0 matches D1 better than D0?
        # T0: [11,11,21,21]. IoU(D1, T0) = 1.0. IoU(D0, T0) > 0.
        # D0 [10,10,20,20] vs T0 [11,11,21,21]. Inter [11,11,20,20] (9x9=81). Union 100+100-81 = 119. IoU=0.68.
        
        raw_results["tracks"] = [
            {"bbox": [11,11,4,4], "bbox_xyxy": [11,11,21,21], "track_id": 999} 
        ]
        
        # Greedy loop (D0 then D1):
        # D0 sees T0 (IoU 0.68). Matches! T0 used.
        # D1 sees T0 (IoU 1.0). T0 already used. D1 gets nothing.
        
        # Global matching:
        # Pairs: (D1,T0, 1.0), (D0,T0, 0.68).
        # Sort -> D1,T0 first. Assigned.
        # D0,T0 -> T0 used. Skipped.
        # Result: D1 has track_id 999. D0 has None.
        
        res = parse_output(frame_contract, raw_results)
        dets = res["detections"]
        
        # Verify D1 got the track
        d0 = dets[0] # [10,10,20,20]
        d1 = dets[1] # [11,11,21,21]
        
        self.assertNotIn("track_id", d0, "D0 should not get track_id (was stolen by better match D1)")
        self.assertEqual(d1.get("track_id"), 999, "D1 should get track_id 999")
        
        print("\n[PASS] test_track_id_one_to_one_matching")

if __name__ == "__main__":
    unittest.main()

========================================================================================================================
FILE: scripts\shm_cleanup.py
========================================================================================================================
#!/usr/bin/env python
"""
Best-effort cleanup utility for IVIS shared memory segments.

Usage:
  python scripts/shm_cleanup.py <shm_name> <shm_meta_name>
"""
import sys
from multiprocessing import shared_memory


def _unlink(name: str) -> bool:
    if not name:
        return False
    shm = None
    try:
        shm = shared_memory.SharedMemory(name=name, create=False)
    except FileNotFoundError:
        return False
    except Exception as exc:
        print(f"[SHM] Failed to attach {name}: {exc}")
        return False
    try:
        shm.unlink()
        print(f"[SHM] Unlinked {name}")
        return True
    except FileNotFoundError:
        return False
    except Exception as exc:
        print(f"[SHM] Failed to unlink {name}: {exc}")
        return False
    finally:
        try:
            shm.close()
        except Exception:
            pass


def main(argv):
    if len(argv) < 3:
        print("Usage: python scripts/shm_cleanup.py <shm_name> <shm_meta_name>")
        return 2
    data_name = argv[1]
    meta_name = argv[2]
    _unlink(data_name)
    _unlink(meta_name)
    return 0


if __name__ == "__main__":
    raise SystemExit(main(sys.argv))

========================================================================================================================
FILE: src\ivis\__init__.py
========================================================================================================================
"""Top-level ivis package (shims to existing project layout).

This package exposes the existing top-level packages under the
`ivis.` namespace so the project can be installed with a `src/` layout
without requiring extensive file moves. Each subpackage `ivis.<name>` is
implemented as a thin shim that delegates to the existing top-level package
with the same name by forwarding the import path.
"""

__all__ = ["ingestion", "detection", "ui", "common", "memory", "infrastructure"]

========================================================================================================================
FILE: src\ivis\common\__init__.py
========================================================================================================================
import importlib

# Delegate package imports to the existing top-level `common` package.
_pkg = importlib.import_module("common")
__path__ = getattr(_pkg, "__path__", [])
__all__ = getattr(_pkg, "__all__", [])

========================================================================================================================
FILE: src\ivis\detection\__init__.py
========================================================================================================================
import importlib

# Delegate package imports to the existing top-level `detection` package.
_pkg = importlib.import_module("detection")
__path__ = getattr(_pkg, "__path__", [])
__all__ = getattr(_pkg, "__all__", [])

========================================================================================================================
FILE: src\ivis\devtools.py
========================================================================================================================
# FILE: src/ivis/devtools.py
# ------------------------------------------------------------------------------
import subprocess
import sys


def _run(args):
    cmd = [sys.executable] + args
    raise SystemExit(subprocess.call(cmd))


def lint() -> None:
    _run(["-m", "ruff", "check", "."])


def typecheck() -> None:
    _run(["-m", "mypy", "src"])


def test() -> None:
    _run(["-m", "pytest", "-q"])

========================================================================================================================
FILE: src\ivis\infrastructure\__init__.py
========================================================================================================================
import importlib

# Delegate package imports to the existing top-level `infrastructure` package.
_pkg = importlib.import_module("infrastructure")
__path__ = getattr(_pkg, "__path__", [])
__all__ = getattr(_pkg, "__all__", [])

========================================================================================================================
FILE: src\ivis\ingestion\__init__.py
========================================================================================================================
import importlib

# Delegate package imports to the existing top-level `ingestion` package.
_pkg = importlib.import_module("ingestion")
__path__ = getattr(_pkg, "__path__", [])
__all__ = getattr(_pkg, "__all__", [])

========================================================================================================================
FILE: src\ivis\legacy\detection_ingest_consumer_legacy.py
========================================================================================================================
"""
Legacy consumers exposed through the installable `ivis` package.
"""
import json
import socket

from detection.errors.fatal import FatalError


class TcpFrameConsumer:
    def __init__(self, host="localhost", port=5555):
        self.address = (host, port)
        self.sock = None
        self.buffer = ""

    def connect(self):
        if not self.sock:
            try:
                self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                self.sock.settimeout(5.0)
                self.sock.connect(self.address)
                self.sock.settimeout(None)
                print(f"[DETECTION] Connected to Bus at {self.address}")
            except Exception as e:
                raise FatalError(f"Failed to connect to Bus at {self.address}", context={"error": str(e)})

    def __iter__(self):
        self.connect()
        while True:
            try:
                data = self.sock.recv(4096)
                if not data:
                    raise FatalError("Bus connection lost (EOF)")

                self.buffer += data.decode("utf-8")

                while "\n" in self.buffer:
                    line, self.buffer = self.buffer.split("\n", 1)
                    if line.strip():
                        try:
                            contract = json.loads(line)
                            yield contract
                        except json.JSONDecodeError:
                            print("[Warn] Received malformed JSON from Bus")
                            continue
            except FatalError:
                raise
            except Exception as e:
                raise FatalError("Bus Consumer Error", context={"error": str(e)})


class ZmqFrameConsumer:
    def __init__(self, endpoint: str):
        try:
            import zmq
        except Exception as exc:
            raise FatalError("Missing ZeroMQ dependency", context={"error": str(exc)}) from exc
        self.zmq = zmq
        self.endpoint = endpoint
        self.socket = None

    def connect(self):
        ctx = self.zmq.Context.instance()
        self.socket = ctx.socket(self.zmq.SUB)
        self.socket.connect(self.endpoint)
        self.socket.setsockopt(self.zmq.SUBSCRIBE, b"")
        print(f"[DETECTION] ZMQ SUB connected to {self.endpoint}")

    def __iter__(self):
        if not self.socket:
            self.connect()
        while True:
            try:
                payload = self.socket.recv()
                contract = json.loads(payload.decode("utf-8"))
                yield contract
            except Exception as e:
                raise FatalError("ZMQ Consumer Error", context={"error": str(e)})



========================================================================================================================
FILE: src\ivis\legacy\infrastructure_bus.py
========================================================================================================================
"""Installable legacy SimpleBus shim under ivis.legacy."""
import socket
import threading


class SimpleBus:
    def __init__(self, host="0.0.0.0", port=5555):
        self.server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        self.server.bind((host, port))
        self.server.listen(5)
        self.clients = []
        self.running = True
        try:
            from ivis_logging import setup_logging

            self.logger = setup_logging("bus")
        except Exception:
            import logging

            self.logger = logging.getLogger("bus")
        self.logger.info("[BUS] Listening on %s:%s", host, port)

    def broadcast(self, sender_socket, message):
        for client in self.clients:
            if client != sender_socket:
                try:
                    client.sendall(message)
                except:
                    self.remove(client)

    def remove(self, connection):
        if connection in self.clients:
            self.clients.remove(connection)

    def handle_client(self, conn, addr):
        self.logger.info("[BUS] New connection: %s", addr)
        self.clients.append(conn)
        while self.running:
            try:
                data = conn.recv(4096)
                if not data:
                    break
                self.broadcast(conn, data)
            except:
                break
        self.remove(conn)
        conn.close()

    def start(self):
        while self.running:
            try:
                conn, addr = self.server.accept()
                thread = threading.Thread(target=self.handle_client, args=(conn, addr))
                thread.daemon = True
                thread.start()
            except KeyboardInterrupt:
                self.stop()
                break

    def stop(self):
        self.running = False
        self.server.close()
        self.logger.info("[BUS] Stopped")


if __name__ == "__main__":
    bus = SimpleBus()
    bus.start()

========================================================================================================================
FILE: src\ivis\legacy\infrastructure_bus_zmq.py
========================================================================================================================
"""Installable legacy ZMQ bus shim under ivis.legacy."""
import os
import sys


def main():
    try:
        import zmq
    except Exception as exc:
        print(f"Missing ZeroMQ dependency: {exc}")
        sys.exit(1)

    xsub_endpoint = os.getenv("ZMQ_XSUB_ENDPOINT", "tcp://*:5555")
    xpub_endpoint = os.getenv("ZMQ_XPUB_ENDPOINT", "tcp://*:5556")

    ctx = zmq.Context.instance()
    xsub = ctx.socket(zmq.XSUB)
    xsub.bind(xsub_endpoint)
    xpub = ctx.socket(zmq.XPUB)
    xpub.bind(xpub_endpoint)

    print(f"[BUS-ZMQ] XSUB {xsub_endpoint} | XPUB {xpub_endpoint}")
    try:
        zmq.proxy(xsub, xpub)
    except KeyboardInterrupt:
        print("[BUS-ZMQ] Stopped")
    finally:
        xsub.close(0)
        xpub.close(0)
        ctx.term()


if __name__ == "__main__":
    main()

========================================================================================================================
FILE: src\ivis\legacy\ingestion_ipc_legacy.py
========================================================================================================================
"""
Legacy ingestion IPC transports (shims inside the installed `ivis` package).
"""
import json
import socket

from ingestion.memory.ref import MemoryReference
from ivis.common.contracts.frame_contract import FrameContractV1, FrameMemoryRef


class SocketPublisher:
    def __init__(self, config, host="localhost", port=5555):
        self.stream_id = config.stream_id
        self.camera_id = config.camera_id
        self.frame_width = config.frame_width
        self.frame_height = config.frame_height
        self.frame_color = config.frame_color
        self.address = (host, port)
        self.sock = None
        self._connect()

    def _connect(self):
        try:
            self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.sock.connect(self.address)
        except Exception:
            self.sock = None

    def publish(self, frame_identity, packet_timestamp_ms, packet_mono_ms, memory_ref, roi_meta=None):
        gen = getattr(memory_ref, "generation", 0)
        contract = _build_contract(
            self.stream_id,
            self.camera_id,
            frame_identity,
            packet_timestamp_ms,
            packet_mono_ms,
            memory_ref,
            gen,
            self.frame_width,
            self.frame_height,
            self.frame_color,
            roi_meta=roi_meta,
        )
        payload = json.dumps(contract) + "\n"

        if self.sock:
            try:
                self.sock.sendall(payload.encode())
            except Exception:
                print("[PUB] Transport lost. Dropping msg.")
                self.sock.close()
                self._connect()
        else:
            self._connect()


class ZmqPublisher:
    def __init__(self, config, endpoint: str):
        try:
            import zmq
        except Exception as exc:
            raise RuntimeError(f"Missing ZeroMQ dependency: {exc}") from exc

        self.stream_id = config.stream_id
        self.camera_id = config.camera_id
        self.frame_width = config.frame_width
        self.frame_height = config.frame_height
        self.frame_color = config.frame_color
        self.endpoint = endpoint
        self.zmq = zmq
        self.socket = self.zmq.Context.instance().socket(self.zmq.PUB)
        self.socket.bind(self.endpoint)

    def publish(self, frame_identity, packet_timestamp_ms, packet_mono_ms, memory_ref, roi_meta=None):
        gen = getattr(memory_ref, "generation", 0)
        contract = _build_contract(
            self.stream_id,
            self.camera_id,
            frame_identity,
            packet_timestamp_ms,
            packet_mono_ms,
            memory_ref,
            gen,
            self.frame_width,
            self.frame_height,
            self.frame_color,
            roi_meta=roi_meta,
        )
        payload = json.dumps(contract).encode("utf-8")
        self.socket.send(payload)


def _build_contract(
    stream_id,
    camera_id,
    frame_identity,
    packet_timestamp_ms,
    packet_mono_ms,
    memory_ref,
    gen,
    frame_width,
    frame_height,
    frame_color,
    roi_meta=None,
):
    backend = getattr(memory_ref, "backend_type", "shm_ring_v1")
    memory = FrameMemoryRef(
        backend=backend,
        key=memory_ref.location,
        size=memory_ref.size,
        generation=gen,
    )
    output_color = "bgr"
    contract = FrameContractV1(
        contract_version="v1",
        frame_id=frame_identity.frame_id,
        stream_id=stream_id,
        camera_id=camera_id,
        pts=frame_identity.pts,
        timestamp_ms=packet_timestamp_ms,
        mono_ms=packet_mono_ms,
        memory=memory,
        frame_width=frame_width,
        frame_height=frame_height,
        frame_channels=3,
        frame_dtype="uint8",
        frame_color_space=output_color,
    )
    payload = contract.to_dict()
    if roi_meta:
        payload["roi"] = roi_meta
    return payload

========================================================================================================================
FILE: src\ivis\memory\__init__.py
========================================================================================================================
import importlib

# Delegate package imports to the existing top-level `memory` package.
_pkg = importlib.import_module("memory")
__path__ = getattr(_pkg, "__path__", [])
__all__ = getattr(_pkg, "__all__", [])

========================================================================================================================
FILE: src\ivis\run_system.py
========================================================================================================================
"""Shim module to expose top-level `run_system` as `ivis.run_system`.

This imports the top-level `run_system` module and exposes its `main`
callable so entry points can reference `ivis.run_system:main`.
"""
from importlib import import_module

_mod = import_module("run_system")

def main(argv=None):
    return _mod.main(argv=argv)

========================================================================================================================
FILE: src\ivis\ui\__init__.py
========================================================================================================================
import importlib

# Delegate package imports to the existing top-level `ui` package.
_pkg = importlib.import_module("ui")
__path__ = getattr(_pkg, "__path__", [])
__all__ = getattr(_pkg, "__all__", [])

========================================================================================================================
FILE: src\ivisv.egg-info\SOURCES.txt
========================================================================================================================
README.md
pyproject.toml
src/ivis/__init__.py
src/ivis/devtools.py
src/ivis/run_system.py
src/ivis/common/__init__.py
src/ivis/detection/__init__.py
src/ivis/infrastructure/__init__.py
src/ivis/ingestion/__init__.py
src/ivis/legacy/detection_ingest_consumer_legacy.py
src/ivis/legacy/infrastructure_bus.py
src/ivis/legacy/infrastructure_bus_zmq.py
src/ivis/legacy/ingestion_ipc_legacy.py
src/ivis/memory/__init__.py
src/ivis/ui/__init__.py
src/ivisv.egg-info/PKG-INFO
src/ivisv.egg-info/SOURCES.txt
src/ivisv.egg-info/dependency_links.txt
src/ivisv.egg-info/entry_points.txt
src/ivisv.egg-info/requires.txt
src/ivisv.egg-info/top_level.txt
tests/test_color_standard.py
tests/test_e2e_pipeline.py
tests/test_latency_ms.py
tests/test_namespace_imports.py
tests/test_no_silent_excepts.py

========================================================================================================================
FILE: src\ivisv.egg-info\dependency_links.txt
========================================================================================================================


========================================================================================================================
FILE: src\ivisv.egg-info\entry_points.txt
========================================================================================================================
[console_scripts]
ivis-detection = ivis.detection.main:main
ivis-ingestion = ivis.ingestion.main:main
ivis-run-system = ivis.run_system:main
ivis-ui = ivis.ui.live_view:main
lint = ivis.devtools:lint
test = ivis.devtools:test
typecheck = ivis.devtools:typecheck

========================================================================================================================
FILE: src\ivisv.egg-info\requires.txt
========================================================================================================================

[dev]
ruff>=0.4.0
mypy>=1.8.0
pytest>=7.0

========================================================================================================================
FILE: src\ivisv.egg-info\top_level.txt
========================================================================================================================
ivis

========================================================================================================================
FILE: tests\contracts\test_ingestion_contract_version.py
========================================================================================================================
from ingestion.frame.id import FrameIdentity
from ingestion.ipc import _build_contract


class DummyMemoryRef:
    def __init__(self):
        self.backend_type = "shm"
        self.location = "1"
        self.size = 640 * 480 * 3


def test_ingestion_builds_contract_version_int():
    identity = FrameIdentity("s1", 0.0, "fp")
    contract = _build_contract(
        stream_id="s1",
        camera_id="c1",
        frame_identity=identity,
        packet_timestamp_ms=1000,
        packet_mono_ms=2000,
        memory_ref=DummyMemoryRef(),
        gen=1,
        frame_width=640,
        frame_height=480,
        frame_color="bgr",
    )
    assert contract["contract_version"] == 1
    assert isinstance(contract["contract_version"], int)
    assert contract["timestamp_ms"] == 1000
    assert contract["mono_ms"] == 2000

========================================================================================================================
FILE: tests\contracts\test_validators.py
========================================================================================================================
import warnings

import pytest

from ivis.common.contracts.validators import validate_frame_contract_v1, ContractValidationError


def base_contract():
    return {
        "contract_version": 1,
        "frame_id": "f1",
        "stream_id": "s1",
        "camera_id": "c1",
        "pts": 0.0,
        "timestamp_ms": 1000,
        "mono_ms": 2000,
        "memory": {"backend": "shm", "key": "1", "size": 640 * 480 * 3, "generation": 1},
        "frame_width": 640,
        "frame_height": 480,
        "frame_channels": 3,
        "frame_dtype": "uint8",
        "frame_color_space": "bgr",
    }


def test_missing_memory_field_triggers_error():
    c = base_contract()
    del c["memory"]["key"]
    with pytest.raises(ContractValidationError) as exc:
        validate_frame_contract_v1(c)
    assert exc.value.reason_code == "missing_memory_field"


def test_wrong_dtype_triggers_error():
    c = base_contract()
    c["frame_dtype"] = "float32"
    with pytest.raises(ContractValidationError) as exc:
        validate_frame_contract_v1(c)
    assert exc.value.reason_code == "unsupported_dtype"


def test_size_mismatch_triggers_error():
    c = base_contract()
    c["memory"]["size"] = 12345
    with pytest.raises(ContractValidationError) as exc:
        validate_frame_contract_v1(c)
    assert exc.value.reason_code == "memory_size_mismatch"


def test_missing_frame_id_triggers_error():
    c = base_contract()
    del c["frame_id"]
    with pytest.raises(ContractValidationError) as exc:
        validate_frame_contract_v1(c)
    assert exc.value.reason_code == "bad_frame_id"


def test_missing_timestamp_ms_triggers_error():
    c = base_contract()
    del c["timestamp_ms"]
    with pytest.raises(ContractValidationError) as exc:
        validate_frame_contract_v1(c)
    assert exc.value.reason_code == "bad_timestamp_ms"


def test_wrong_timestamp_ms_type_triggers_error():
    c = base_contract()
    c["timestamp_ms"] = "1000"
    with pytest.raises(ContractValidationError) as exc:
        validate_frame_contract_v1(c)
    assert exc.value.reason_code == "bad_timestamp_ms"


def test_wrong_mono_ms_type_triggers_error():
    c = base_contract()
    c["mono_ms"] = "2000"
    with pytest.raises(ContractValidationError) as exc:
        validate_frame_contract_v1(c)
    assert exc.value.reason_code == "bad_mono_ms"


@pytest.mark.parametrize("legacy_value", ["1", "v1", "V1"])
def test_contract_version_normalizes_legacy_strings(legacy_value):
    c = base_contract()
    c["contract_version"] = legacy_value
    with warnings.catch_warnings(record=True) as caught:
        warnings.simplefilter("always", DeprecationWarning)
        validate_frame_contract_v1(c)
    assert c["contract_version"] == 1
    assert any(item.category is DeprecationWarning for item in caught)


@pytest.mark.parametrize("bad_value", ["v2", 2, 0, None])
def test_contract_version_rejects_invalid_values(bad_value):
    c = base_contract()
    c["contract_version"] = bad_value
    with pytest.raises(ContractValidationError) as exc:
        validate_frame_contract_v1(c)
    assert exc.value.reason_code == "contract_version_mismatch"

========================================================================================================================
FILE: tests\detection\test_track_id_mapping.py
========================================================================================================================
from detection.postprocess.parse import parse_output


def test_track_id_association_tolerates_float_jitter():
    frame_contract = {
        "contract_version": 1,
        "frame_id": "f1",
        "stream_id": "s1",
        "camera_id": "c1",
        "timestamp_ms": 1000,
        "mono_ms": 2000,
        "pts": 0.0,
    }
    raw_results = {
        "detections": [([10.0, 20.0, 50.0, 60.0], 0.9, 1)],
        "tracks": [
            {
                "track_id": 42,
                "bbox_xyxy": [10.15, 19.85, 50.05, 60.1],
            }
        ],
        "timing": {"inference_ms": 1.0},
    }

    result = parse_output(frame_contract, raw_results)
    assert result["detections"][0]["track_id"] == 42


def test_track_id_one_to_one_matching():
    frame_contract = {
        "contract_version": 1,
        "frame_id": "f2",
        "stream_id": "s1",
        "camera_id": "c1",
        "timestamp_ms": 1001,
        "mono_ms": 2001,
        "pts": 0.0,
    }
    raw_results = {
        "detections": [
            ([0.0, 0.0, 10.0, 10.0], 0.9, 1),
            ([1.0, 1.0, 9.0, 9.0], 0.8, 1),
        ],
        "tracks": [
            {
                "track_id": 7,
                "bbox_xyxy": [0.0, 0.0, 10.0, 10.0],
            }
        ],
        "timing": {"inference_ms": 1.0},
    }

    result = parse_output(frame_contract, raw_results)
    track_ids = [det.get("track_id") for det in result["detections"] if "track_id" in det]
    assert track_ids.count(7) == 1

========================================================================================================================
FILE: tests\detection\test_zmq_consumer.py
========================================================================================================================
import importlib
import sys
import types


def _set_required_env(monkeypatch):
    monkeypatch.setenv("MODEL_NAME", "test-model")
    monkeypatch.setenv("MODEL_VERSION", "0")
    monkeypatch.setenv("MODEL_HASH", "hash")
    monkeypatch.setenv("MODEL_PATH", "path")


def test_zmq_consumer_connect_idempotent(monkeypatch):
    _set_required_env(monkeypatch)

    class FakeSocket:
        def __init__(self):
            self.connect_calls = []
            self.opts = []

        def setsockopt(self, opt, value):
            self.opts.append((opt, value))

        def connect(self, endpoint):
            self.connect_calls.append(endpoint)

        def close(self):
            return None

    fake_socket = FakeSocket()

    class FakeContext:
        def socket(self, sock_type):
            return fake_socket

    class FakeContextWrapper:
        @staticmethod
        def instance():
            return FakeContext()

    fake_zmq = types.SimpleNamespace(
        SUB=1,
        SUBSCRIBE=2,
        RCVHWM=3,
        LINGER=4,
        CONFLATE=5,
        Context=FakeContextWrapper,
    )

    monkeypatch.setitem(sys.modules, "zmq", fake_zmq)

    if "detection.config" in sys.modules:
        importlib.reload(sys.modules["detection.config"])
    if "detection.ingest.consumer" in sys.modules:
        consumer = importlib.reload(sys.modules["detection.ingest.consumer"])
    else:
        import detection.ingest.consumer as consumer

    sub = consumer.ZmqFrameConsumer("tcp://example:5555")
    sub.connect()
    sub.connect()

    assert fake_socket.connect_calls == ["tcp://example:5555"]

========================================================================================================================
FILE: tests\stress_shm.py
========================================================================================================================
import multiprocessing
import time
import os
import sys
import numpy as np
import logging

# Add project root to path
sys.path.append(os.path.abspath(os.path.dirname(__file__)))

from memory.shm_ring import ShmRing

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(message)s')
logger = logging.getLogger("stress_test")

SLOT_SIZE = 1024 * 1024  # 1 MB
SLOT_COUNT = 10
SHM_NAME = "stress_test_shm"
SHM_META = "stress_test_meta"
DURATION = 5  # seconds

def writer_process(stop_event):
    ring = ShmRing(SHM_NAME, SHM_META, SLOT_SIZE, SLOT_COUNT, create=True, recreate_on_mismatch=True)
    counter = 0
    # Create a pattern we can verify: Fill buffer with a single byte value that increments
    try:
        while not stop_event.is_set():
            val = counter % 255
            # Create a 1MB buffer filled with 'val'
            data = bytes([val]) * SLOT_SIZE
            ring.write(data)
            counter += 1
            if counter % 100 == 0:
                time.sleep(0.001) # Slight pause to let reader catch up occasionally
    except Exception as e:
        logger.error(f"Writer failed: {e}")
    finally:
        ring.close()

def reader_process(stop_event, error_queue):
    # giving writer a moment to start
    time.sleep(0.5)
    try:
        ring = ShmRing(SHM_NAME, SHM_META, SLOT_SIZE, SLOT_COUNT, create=False)
    except FileNotFoundError:
        logger.error("Reader could not find SHM")
        error_queue.put("SHM not found")
        return

    reads = 0
    torn_reads = 0
    
    try:
        while not stop_event.is_set():
            # Use read_latest
            data, idx, gen = ring.read_latest()
            if data is None:
                continue
                
            reads += 1
            # Verify data integrity
            # We expect all bytes to be the same
            first_byte = data[0]
            # Fast check using numpy or just list slicing if simple
            # Since we used bytes([val]) * size, every byte must be 'first_byte'
            # Check the last byte and middle byte to be sure
            if data[-1] != first_byte or data[len(data)//2] != first_byte:
                logger.error(f"TORN READ DETECTED! Gen={gen}, Index={idx}")
                torn_reads += 1
                error_queue.put(f"Torn read at gen {gen}")
            
            # Additional check: convert to numpy to check all? (Expensive but accurate)
            # arr = np.frombuffer(data, dtype=np.uint8)
            # if not np.all(arr == first_byte):
            #    logger.error("Numpy check mismatch")
            
    except Exception as e:
        logger.error(f"Reader failed: {e}")
        error_queue.put(str(e))
    finally:
        ring.close()
        logger.info(f"Reader finished. Total reads: {reads}, Torn reads: {torn_reads}")

if __name__ == "__main__":
    multiprocessing.freeze_support()
    logger.info("Starting SHM Stress Test...")
    
    stop_event = multiprocessing.Event()
    error_queue = multiprocessing.Queue()
    
    p_writer = multiprocessing.Process(target=writer_process, args=(stop_event,))
    p_reader = multiprocessing.Process(target=reader_process, args=(stop_event, error_queue))
    
    p_writer.start()
    p_reader.start()
    
    time.sleep(DURATION)
    stop_event.set()
    
    p_writer.join()
    p_reader.join()
    
    errors = []
    while not error_queue.empty():
        errors.append(error_queue.get())
        
    if errors:
        logger.error(f"Test FAILED with {len(errors)} errors:")
        for e in errors:
            logger.error(f" - {e}")
        sys.exit(1)
    else:
        logger.info("Test PASSED: No torn reads detected.")

========================================================================================================================
FILE: tests\test_color_standard.py
========================================================================================================================
import unittest

import numpy as np

from ingestion.frame.anchor import Anchor
from ingestion.frame.normalizer import Normalizer


class TestColorStandard(unittest.TestCase):
    def test_normalizer_rgb_input_to_bgr_output(self):
        frame_rgb = np.zeros((2, 2, 3), dtype=np.uint8)
        frame_rgb[0, 0] = [10, 20, 30]  # RGB
        normalizer = Normalizer((2, 2), frame_color="rgb")
        out = normalizer.process(frame_rgb)
        self.assertEqual(out[0, 0].tolist(), [30, 20, 10])

    def test_anchor_color_conversion_differs(self):
        frame = np.zeros((8, 8, 3), dtype=np.uint8)
        frame[:, :4] = [255, 0, 0]  # Red in RGB
        frame[:, 4:] = [0, 0, 255]  # Blue in RGB
        anchor = Anchor()
        rgb_hash = anchor.generate(frame, frame_color="rgb")
        bgr_hash = anchor.generate(frame, frame_color="bgr")
        self.assertNotEqual(rgb_hash, bgr_hash)


if __name__ == "__main__":
    unittest.main()

========================================================================================================================
FILE: tests\test_detection_frame_decoder.py
========================================================================================================================
import os

# Ensure required detection config vars exist BEFORE importing FrameDecoder (Config loads at import time).
os.environ.setdefault("MODEL_NAME", "stub")
os.environ.setdefault("MODEL_VERSION", "0")
os.environ.setdefault("MODEL_HASH", "stub")
os.environ.setdefault("MODEL_PATH", "stub.pt")

from detection.config import Config
from detection.errors.fatal import NonFatalError
from detection.frame.decoder import FrameDecoder  # noqa: E402
import numpy as np


def test_decoder_uses_contract_metadata_when_present():
    dec = FrameDecoder()
    w, h, c = 4, 3, 3
    data = bytes(range(w * h * c))
    contract = {
        "frame_width": w,
        "frame_height": h,
        "frame_channels": c,
        "frame_dtype": "uint8",
        "memory": {"size": len(data)},
    }
    arr = dec.decode(data, contract)
    assert arr.shape == (h, w, c)


def test_decoder_accepts_memory_size_as_string():
    dec = FrameDecoder()
    w, h, c = 2, 2, 3
    data = bytes(range(w * h * c))
    contract = {
        "frame_width": w,
        "frame_height": h,
        "frame_channels": c,
        "frame_dtype": "uint8",
        "memory": {"size": str(len(data))},
    }
    arr = dec.decode(data, contract)
    assert arr.shape == (h, w, c)


def test_decoder_rejects_wrong_size():
    dec = FrameDecoder()
    w, h, c = 2, 2, 3
    data = bytes(range((w * h * c) - 1))  # wrong
    contract = {
        "frame_width": w,
        "frame_height": h,
        "frame_channels": c,
        "frame_dtype": "uint8",
        "memory": {"size": w * h * c},
    }
    try:
        dec.decode(data, contract)
        assert False, "Expected size mismatch error"
    except Exception:
        assert True


def test_decoder_missing_metadata_fails_in_strict_mode():
    Config.DECODER_ALLOW_CONFIG_FALLBACK = False
    dec = FrameDecoder()
    # Contract missing geometry
    contract = {"memory": {"size": 0}} # dummy
    try:
        dec._resolve_metadata(contract)
        assert False, "Should fail in strict mode"
    except NonFatalError:
        assert True


def test_decoder_missing_metadata_works_in_fallback_mode():
    Config.DECODER_ALLOW_CONFIG_FALLBACK = True
    # Ensure config has known defaults for test
    Config.FRAME_WIDTH = 100
    Config.FRAME_HEIGHT = 100
    
    dec = FrameDecoder()
    contract = {"memory": {"size": 0}}
    w, h, c, dt, fallback = dec._resolve_metadata(contract)
    assert w == 100
    assert h == 100
    assert fallback is True

========================================================================================================================
FILE: tests\test_e2e_pipeline.py
========================================================================================================================
# FILE: tests/test_e2e_pipeline.py
# ------------------------------------------------------------------------------
from detection.postprocess.parse import parse_output
from ingestion.frame.id import FrameIdentity
from ingestion.ipc import _build_contract
from ingestion.memory.ref import MemoryReference
from ivis.common.contracts.result_contract import validate_result_contract_v1
from ivis.common.contracts.validators import validate_frame_contract_v1


def _make_frame_contract(index: int) -> dict:
    stream_id = "stream-1"
    camera_id = "cam-1"
    width = 32
    height = 32
    channels = 3
    size = width * height * channels
    identity = FrameIdentity(stream_id, 0.1 * index, f"fp-{index}")
    memory = MemoryReference("memkey", size, "shm_ring_v1", generation=index)
    return _build_contract(
        stream_id,
        camera_id,
        identity,
        1000 + index,
        2000 + index,
        memory,
        memory.generation,
        width,
        height,
        "bgr",
    )


def _make_raw_results() -> dict:
    return {
        "detections": [([1.0, 2.0, 10.0, 20.0], 0.9, 1)],
        "tracks": [{"bbox_xyxy": [1.0, 2.0, 10.0, 20.0], "track_id": 42}],
        "timing": {"inference_ms": 1.2},
    }


def _attach_model(result: dict) -> None:
    result["model"] = {
        "name": "stub-model",
        "version": "0",
        "threshold": 0.5,
        "input_size": [32, 32],
    }


def test_e2e_pipeline_contracts() -> None:
    contracts = [_make_frame_contract(i) for i in range(3)]

    for contract in contracts:
        validate_frame_contract_v1(contract)
        result = parse_output(contract, _make_raw_results())
        _attach_model(result)
        validate_result_contract_v1(result)
        assert result["contract_version"] == 1
        assert result["frame_id"] == contract["frame_id"]

========================================================================================================================
FILE: tests\test_latency_ms.py
========================================================================================================================
from ivis.common.time_utils import latency_ms


def test_latency_ms_simple_difference():
    assert latency_ms(1500, 1000) == 500


def test_latency_ms_zero():
    assert latency_ms(1000, 1000) == 0

========================================================================================================================
FILE: tests\test_monotonic_ms.py
========================================================================================================================
# FILE: tests/test_monotonic_ms.py
# ------------------------------------------------------------------------------
from ivis.common.time_utils import monotonic_ms


def test_monotonic_ms_non_decreasing():
    last = monotonic_ms()
    for _ in range(500):
        current = monotonic_ms()
        assert current >= last
        last = current

========================================================================================================================
FILE: tests\test_namespace_imports.py
========================================================================================================================
import re
from pathlib import Path


IMPORT_RE = re.compile(r"^\s*(from|import)\s+common\b")


def _is_excluded(path: Path) -> bool:
    normalized = str(path).replace("\\", "/")
    if "/ivis/common/" in normalized:
        return True
    if "/src/ivis/common/" in normalized:
        return True
    return False


def test_no_common_imports_in_official_paths():
    root = Path(__file__).resolve().parents[1]
    search_dirs = [
        "src",
        "ingestion",
        "detection",
        "ui",
        "memory",
        "infrastructure",
        "ivis",
    ]
    violations = []
    for rel in search_dirs:
        base = root / rel
        if not base.exists():
            continue
        for path in base.rglob("*.py"):
            if _is_excluded(path):
                continue
            text = path.read_text(encoding="utf-8", errors="ignore")
            for lineno, line in enumerate(text.splitlines(), 1):
                if IMPORT_RE.search(line):
                    violations.append(f"{path}:{lineno}: {line.strip()}")
                    break
    assert not violations, "common.* imports detected:\n" + "\n".join(violations)

========================================================================================================================
FILE: tests\test_no_silent_excepts.py
========================================================================================================================
import re
from pathlib import Path


SILENT_EXCEPT_RE = re.compile(r"except Exception:\s*\n\s*pass")


def test_no_silent_exception_pass_in_main_paths():
    root = Path(__file__).resolve().parents[1]
    for rel in ("ingestion", "detection", "ui"):
        base = root / rel
        if not base.exists():
            continue
        for path in base.rglob("*.py"):
            text = path.read_text(encoding="utf-8", errors="ignore")
            assert not SILENT_EXCEPT_RE.search(text), f"Silent except/pass found in {path}"

========================================================================================================================
FILE: tests\test_shm_ring_payload.py
========================================================================================================================
# FILE: tests/test_shm_ring_payload.py
# ------------------------------------------------------------------------------
import uuid

from memory.shm_ring import ShmRing


def test_shm_ring_payload_length_roundtrip():
    name = f"ivis_test_shm_{uuid.uuid4().hex[:8]}"
    meta = f"{name}_meta"
    ring = ShmRing(name, meta, slot_size=16, slot_count=2, create=True, recreate_on_mismatch=True)
    try:
        payload = b"hello"
        slot, gen = ring.write(payload)
        data = ring.read(slot, gen)
        assert data == payload
        latest, idx, gen_latest = ring.read_latest()
        assert idx == slot
        assert gen_latest == gen
        assert latest == payload
    finally:
        ring.close_unlink(True)

========================================================================================================================
FILE: tests\ui\test_results_cache.py
========================================================================================================================
from ui.results_cache import ResultsCache


class FakeTime:
    def __init__(self, value: float = 0.0):
        self.value = value

    def __call__(self) -> float:
        return self.value

    def advance(self, delta: float) -> None:
        self.value += delta


def test_results_cache_lru_eviction():
    clock = FakeTime()
    cache = ResultsCache(max_entries=2, ttl_seconds=60, time_fn=clock)
    cache.put("a", 1)
    cache.put("b", 2)
    assert len(cache) == 2
    cache.get("a")
    cache.put("c", 3)
    assert len(cache) == 2
    assert cache.get("b") is None
    assert cache.get("a") == 1


def test_results_cache_ttl_expiry():
    clock = FakeTime()
    cache = ResultsCache(max_entries=10, ttl_seconds=1, time_fn=clock)
    cache.put("a", 1)
    clock.advance(2)
    assert cache.get("a") is None
    assert len(cache) == 0

========================================================================================================================
FILE: ui\__init__.py
========================================================================================================================
# IVIS UI package

========================================================================================================================
FILE: ui\live_view.py
========================================================================================================================
# FILE: ui/live_view.py
# ------------------------------------------------------------------------------
import json
import os
import threading
import time

import cv2
import numpy as np
from flask import Flask, Response, render_template_string

from ivis.common.config.base import redact_config
from ivis_logging import setup_logging
from memory.shm_ring import ShmRing
from ivis.common.contracts.validators import validate_frame_contract_v1, ContractValidationError
from ivis.common.contracts.result_contract import validate_result_contract_v1
from detection.metrics.counters import metrics as detection_metrics
from ui.results_cache import ResultsCache
import ivis_metrics
import ivis_tracing


ZMQ_SUB_ENDPOINT = os.getenv("ZMQ_SUB_ENDPOINT", "tcp://localhost:5555")
ZMQ_RESULTS_SUB_ENDPOINT = os.getenv("ZMQ_RESULTS_SUB_ENDPOINT", "tcp://localhost:5557")

SHM_NAME = os.getenv("SHM_NAME", "ivis_shm_data")
SHM_META_NAME = os.getenv("SHM_META_NAME", "ivis_shm_meta")
SHM_BUFFER_BYTES = int(os.getenv("SHM_BUFFER_BYTES", "50000000"))
SHM_CACHE_SECONDS = float(os.getenv("SHM_CACHE_SECONDS", "0"))
SHM_CACHE_FPS = float(os.getenv("SHM_CACHE_FPS", "0"))

FRAME_WIDTH = int(os.getenv("FRAME_WIDTH", "640"))
FRAME_HEIGHT = int(os.getenv("FRAME_HEIGHT", "480"))
# FRAME_COLOR_SPACE is fixed to 'bgr' for v1 contract; downstream code
# should assume frames are in this colorspace and avoid conversions.
FRAME_COLOR_SPACE = os.getenv("FRAME_COLOR_SPACE", "bgr").lower()

app = Flask(__name__)
logger = setup_logging("ui")

_warned = set()


def _log_once(key: str, message: str, exc: Exception = None) -> None:
    if key in _warned:
        return
    _warned.add(key)
    if exc is not None:
        logger.warning("%s: %s", message, exc)
    else:
        logger.warning("%s", message)


def _record_issue(reason: str, message: str, exc: Exception = None) -> None:
    _log_once(reason, message, exc)
    try:
        ivis_metrics.service_errors_total.labels(service="ui", reason=reason).inc()
    except Exception as metric_exc:
        _log_once(f"{reason}_metric", "Failed to record service error metric", metric_exc)


def _safe_metric(reason: str, fn) -> None:
    try:
        fn()
    except Exception as exc:
        _record_issue(reason, "Metrics update failed", exc)

RESULTS_CACHE_MAX = int(os.getenv("UI_RESULTS_CACHE_MAX", "2000"))
RESULTS_CACHE_TTL_SEC = float(os.getenv("UI_RESULTS_CACHE_TTL_SEC", "60"))

latest_lock = threading.Lock()
latest_frame = None
latest_meta = {}
results_cache = ResultsCache(max_entries=RESULTS_CACHE_MAX, ttl_seconds=RESULTS_CACHE_TTL_SEC)
results_cache_lock = threading.Lock()
shm_ring = None
last_shm_error = None
active_shm_name = None
last_frame_ts = 0.0
fps_ema = 0.0
last_contract_ts = 0.0
last_result = {}
last_shm_ts = 0.0
_threads_started = False
_threads_lock = threading.Lock()

def _update_cache_metric():
    _safe_metric("metrics_ui_cache_size_failed", lambda: ivis_metrics.ui_results_cache_size.set(len(results_cache)))


def _cache_set(frame_id: str, result: dict):
    with results_cache_lock:
        results_cache.put(frame_id, result)
        _update_cache_metric()


def _cache_get(frame_id: str):
    with results_cache_lock:
        result = results_cache.get(frame_id)
        _update_cache_metric()
        return result


def _start_background_threads():
    global _threads_started
    with _threads_lock:
        if _threads_started:
            return
        threading.Thread(target=_frame_loop, daemon=True).start()
        threading.Thread(target=_results_loop, daemon=True).start()
        threading.Thread(target=_shm_fallback_loop, daemon=True).start()
        _threads_started = True
        logger.info("Background threads started.")


def _get_ring():
    global shm_ring, last_shm_error, active_shm_name
    if shm_ring is None:
        slot_size = FRAME_WIDTH * FRAME_HEIGHT * 3
        if SHM_CACHE_SECONDS > 0 and SHM_CACHE_FPS > 0:
            slot_count = max(1, int(SHM_CACHE_SECONDS * SHM_CACHE_FPS))
        else:
            slot_count = max(1, SHM_BUFFER_BYTES // slot_size)
        candidates = [
            (SHM_NAME, SHM_META_NAME),
            (f"ivis_shm_data_{slot_size}_{slot_count}", f"ivis_shm_meta_{slot_size}_{slot_count}"),
            ("ivis_shm_data", "ivis_shm_meta"),
        ]
        last_error = None
        for data_name, meta_name in candidates:
            try:
                shm_ring = ShmRing(data_name, meta_name, slot_size, slot_count, create=False)
                active_shm_name = data_name
                last_shm_error = None
                break
            except Exception as exc:
                last_error = exc
                shm_ring = None
        if shm_ring is None and last_error is not None:
            last_shm_error = str(last_error)
    return shm_ring


def _overlay(frame_bgr: np.ndarray, result: dict, fps_value: float) -> np.ndarray:
    if not result.get("detections") and not result.get("tracks"):
         pass # logger.debug("Overlay: No detections/tracks in result for overlay")
    timing = result.get("timing", {})
    inference_ms = timing.get("inference_ms")
    model_ms = timing.get("model_ms")
    track_ms = timing.get("track_ms")
    # Expect ResultContractV1: detections is a list of dicts
    detections = result.get("detections", []) if isinstance(result.get("detections", []), list) else []
    # Tracks derived from detections that include a track_id
    tracks = [{"bbox": d.get("bbox"), "track_id": d.get("track_id")} for d in detections if d.get("track_id") is not None]
    info_lines = [f"FPS: {fps_value:.1f}", f"DET: {len(detections)} | TRK: {len(tracks)}"]
    if inference_ms is not None:
        info_lines.append(f"INF: {inference_ms:.1f} ms")
    if model_ms is not None and track_ms is not None:
        info_lines.append(f"DET: {model_ms:.1f} ms | TRK: {track_ms:.1f} ms")
    y = 20
    for line in info_lines:
        cv2.putText(
            frame_bgr,
            line,
            (10, y),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.6,
            (0, 255, 255),
            2,
            cv2.LINE_AA,
        )
        y += 22
    for det in detections:
        try:
            bbox = det.get("bbox")
            conf = float(det.get("conf", 0.0))
            cls_id = det.get("class_id")
            if not bbox or len(bbox) != 4:
                continue
            x1, y1, x2, y2 = map(int, map(round, bbox))
        except Exception:
            continue
        color = (0, 200, 255)
        cv2.rectangle(frame_bgr, (int(x1), int(y1)), (int(x2), int(y2)), color, 2)
        label = f"C{int(cls_id)} {conf:.2f}" if cls_id is not None else f"{conf:.2f}"
        if det.get("class_name"):
            label = f"{det.get('class_name')} {conf:.2f}"
        cv2.putText(
            frame_bgr,
            label,
            (int(x1), max(0, int(y1) - 4)),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            color,
            1,
            cv2.LINE_AA,
        )

    frame_h, frame_w = frame_bgr.shape[:2]
    for track in tracks:
        bbox = track.get("bbox", [0, 0, 0, 0])
        if len(bbox) != 4:
            continue
        x1, y1, x2, y2 = bbox
        # Accept either [x1, y1, x2, y2] or [x, y, w, h].
        if x2 > x1 and y2 > y1 and x2 <= frame_w and y2 <= frame_h:
            x, y, w, h = x1, y1, x2 - x1, y2 - y1
        else:
            x, y, w, h = x1, y1, x2, y2
        track_id = track.get("track_id", -1)
        color = (0, 255, 0)
        cv2.rectangle(frame_bgr, (int(x), int(y)), (int(x + w), int(y + h)), color, 2)
        cv2.putText(
            frame_bgr,
            f"ID {track_id}",
            (int(x), max(0, int(y) - 4)),
            cv2.FONT_HERSHEY_SIMPLEX,
            0.5,
            color,
            1,
            cv2.LINE_AA,
        )
    return frame_bgr


def _frame_loop():
    try:
        import zmq
    except Exception as exc:
        raise RuntimeError(f"Missing ZeroMQ dependency: {exc}") from exc

    ctx = zmq.Context.instance()
    socket = ctx.socket(zmq.SUB)
    socket.connect(ZMQ_SUB_ENDPOINT)
    socket.setsockopt(zmq.SUBSCRIBE, b"")
    while True:
        try:
            payload = socket.recv()
            contract = json.loads(payload.decode("utf-8"))
            logger.debug("Received contract via ZMQ: %s", contract.get("frame_id"))
            try:
                with ivis_tracing.start_span("ui.consume", {"frame_id": contract.get("frame_id"), "stream_id": contract.get("stream_id")}):
                    _handle_contract(contract)
            except Exception:
                _handle_contract(contract)
        except Exception as exc:
            _record_issue("ui_frame_loop_failed", "Frame loop error", exc)
            time.sleep(0.1)


def _results_loop():
    try:
        import zmq
    except Exception as exc:
        raise RuntimeError(f"Missing ZeroMQ dependency: {exc}") from exc

    global last_result
    ctx = zmq.Context.instance()
    socket = ctx.socket(zmq.SUB)
    socket.connect(ZMQ_RESULTS_SUB_ENDPOINT)
    socket.setsockopt(zmq.SUBSCRIBE, b"")
    while True:
        try:
            payload = socket.recv()
            result = json.loads(payload.decode("utf-8"))
            try:
                validate_result_contract_v1(result)
            except ContractValidationError as exc:
                detection_metrics.inc_dropped_reason(getattr(exc, "reason_code", "result_validation_failed"))
                logger.debug("Dropped result from ZMQ: %s", getattr(exc, "message", str(exc)))
                continue
            frame_id = result.get("frame_id")
            if frame_id:
                _cache_set(frame_id, result)
                last_result = result
                logger.debug("DEBUG: Cached result for frame %s (ts=%s)", frame_id, result.get("timestamp_ms"))
        except Exception as exc:
            _record_issue("ui_results_loop_failed", "Results loop error", exc)
            time.sleep(0.1)
            



def _handle_contract(contract: dict):
    global last_contract_ts, last_shm_ts
    mem = contract.get("memory", {})
    key = mem.get("key")
    gen = mem.get("generation", 0)
    if not key:
        return
    # Strict validation: fail-fast and drop invalid contracts
    try:
        validate_frame_contract_v1(contract)
    except ContractValidationError as exc:
        try:
            detection_metrics.inc_dropped_reason(getattr(exc, "reason_code", "validation_failed"))
        except Exception as metric_exc:
            _record_issue("ui_dropped_reason_failed", "Failed to update dropped reason metric", metric_exc)
        logger.debug("Dropped contract in UI due to validation: %s", getattr(exc, "message", str(exc)))
        return
    try:
        slot = int(key)
    except ValueError:
        return
    try:
        ring = _get_ring()
        # measure SHM read latency
        rr_start = time.time()
        # trace SHM read in UI
        try:
            with ivis_tracing.start_span("ui.shm_read", {"frame_id": contract.get("frame_id"), "stream_id": contract.get("stream_id")}):
                data = ring.read(slot, gen)
        except Exception as exc:
            _record_issue("tracing_span_shm_read_failed", "Tracing span failed (ui shm_read)", exc)
            data = ring.read(slot, gen)
        rr_ms = (time.time() - rr_start) * 1000.0
        _safe_metric("metrics_shm_read_latency_failed", lambda: ivis_metrics.shm_read_latency_ms.observe(rr_ms))
        if not data:
            return
    except Exception:
        logger.exception("Error reading from SHM ring for slot=%s gen=%s", slot, gen)
        return
    logger.debug("SHM read returned %s bytes for slot=%s gen=%s", None if data is None else len(data), slot, gen)
    arr = np.frombuffer(data, dtype=np.uint8)
    arr = arr.reshape((FRAME_HEIGHT, FRAME_WIDTH, 3))
    # Make a writable copy - buffers from shared memory are readonly in NumPy
    # Ingestion ensures the frame is in FRAME_COLOR_SPACE (bgr v1); no downstream conversion.
    frame_bgr = arr.copy()
    # ensure contiguous writable image for OpenCV
    frame_bgr = np.ascontiguousarray(frame_bgr, dtype=np.uint8)
    frame_id = contract.get("frame_id")
    # Prefer the exact ResultContractV1 for this frame_id; fall back to last_result only
    # if it's recent to avoid drawing stale tracks for long periods.
    result = _cache_get(frame_id)
    if result is None:
        # Use last_result only when it was updated within 0.5s
        if time.perf_counter() - last_shm_ts < float(os.getenv("MAX_RESULT_AGE_SEC", "0.5")):
            result = last_result
        else:
            result = {"detections": [], "tracks": [], "timing": {}}
    else:
        # Ensure result is recent relative to this frame's timestamp
        try:
            res_ts = int(result.get("timestamp_ms", 0))
            frame_ts = int(contract.get("timestamp_ms", 0))
            max_age_ms = int(os.getenv("MAX_RESULT_AGE_MS", "500"))
            if abs(res_ts - frame_ts) > max_age_ms:
                detection_metrics.inc_dropped_reason("result_lag")
                logger.debug("Dropping result for frame %s due to result lag (res_ts=%s frame_ts=%s)", frame_id, res_ts, frame_ts)
                result = {"detections": [], "tracks": [], "timing": {}}
        except Exception:
            # If timestamps malformed, drop the result
            detection_metrics.inc_dropped_reason("result_malformed_timestamp")
            result = {"detections": [], "tracks": [], "timing": {}}
    global last_frame_ts, fps_ema
    now = time.perf_counter()
    if last_frame_ts > 0:
        fps = 1.0 / max(1e-6, (now - last_frame_ts))
        fps_ema = fps if fps_ema == 0.0 else (0.9 * fps_ema + 0.1 * fps)
    last_frame_ts = now
    _safe_metric("metrics_fps_out_failed", lambda: ivis_metrics.fps_out.set(fps_ema))
    # overlay span (drawing + composite)
    try:
        with ivis_tracing.start_span("ui.overlay", {"frame_id": frame_id, "stream_id": contract.get("stream_id")}):
            frame_bgr = _overlay(frame_bgr, result, fps_ema)
    except Exception as exc:
        _record_issue("tracing_span_overlay_failed", "Tracing span failed (ui overlay)", exc)
        frame_bgr = _overlay(frame_bgr, result, fps_ema)
    with latest_lock:
        global latest_frame, latest_meta
        latest_frame = frame_bgr
        latest_meta = contract
        last_contract_ts = time.perf_counter()
        last_shm_ts = time.perf_counter()


def _shm_fallback_loop():
    while True:
        try:
            now = time.perf_counter()
            if now - last_contract_ts < 0.5:
                time.sleep(0.1)
                continue
            # globals used/updated in this loop
            global last_frame_ts, fps_ema, latest_frame, latest_meta, last_shm_ts
            ring = _get_ring()
            if ring is None:
                time.sleep(0.1)
                continue
            data, _, _ = ring.read_latest()
            if not data:
                time.sleep(0.1)
                continue
            # logger.debug("SHM fallback read %s bytes", len(data))
            arr = np.frombuffer(data, dtype=np.uint8)
            arr = arr.reshape((FRAME_HEIGHT, FRAME_WIDTH, 3))
            # Make writable copy for OpenCV drawing
            frame_bgr = arr.copy()
            # Ingestion guarantees FRAME_COLOR_SPACE == bgr; no color conversion required.
            frame_bgr = np.ascontiguousarray(frame_bgr, dtype=np.uint8)
            # (globals declared above)
            now = time.perf_counter()
            if last_frame_ts > 0:
                fps = 1.0 / max(1e-6, (now - last_frame_ts))
                fps_ema = fps if fps_ema == 0.0 else (0.9 * fps_ema + 0.1 * fps)
            last_frame_ts = now
            frame_bgr = _overlay(frame_bgr, last_result if (time.perf_counter() - last_shm_ts) < 0.5 else {"detections": [], "tracks": [], "timing": {}}, fps_ema)
            with latest_lock:
                latest_frame = frame_bgr
                latest_meta = {
                    "stream_id": os.getenv("STREAM_ID"),
                    "camera_id": os.getenv("CAMERA_ID"),
                }
                last_shm_ts = time.perf_counter()
        except Exception as exc:
            _record_issue("ui_shm_fallback_failed", "SHM fallback loop error", exc)
            time.sleep(0.1)


@app.route("/")
def index():
    _start_background_threads()
    html = """
    <!DOCTYPE html>
    <html>
    <head>
      <title>IVIS Live View</title>
      <style>
        body { font-family: Arial, sans-serif; background: #111; color: #eee; text-align: center; }
        .wrap { max-width: 960px; margin: 20px auto; }
        img { width: 100%; border: 1px solid #333; }
        .meta { margin-top: 8px; font-size: 14px; color: #aaa; }
        .note { margin-top: 6px; font-size: 12px; color: #777; }
      </style>
    </head>
    <body>
      <div class="wrap">
        <h2>IVIS Live View</h2>
        <img src="/stream" />
        <div class="meta">Overlay shows FPS and inference time</div>
        <div class="note">Metrics: /metrics</div>
      </div>
    </body>
    </html>
    """
    return render_template_string(html)


@app.route("/stream")
def stream():
    _start_background_threads()
    def gen():
        while True:
            with latest_lock:
                frame = None if latest_frame is None else latest_frame.copy()
            if frame is None:
                try:
                    ring = _get_ring()
                    data, _, _ = ring.read_latest()
                    if data:
                        arr = np.frombuffer(data, dtype=np.uint8)
                        arr = arr.reshape((FRAME_HEIGHT, FRAME_WIDTH, 3))
                        frame_bgr = arr.copy()
                        frame_bgr = np.ascontiguousarray(frame_bgr, dtype=np.uint8)
                        frame = _overlay(frame_bgr, last_result, fps_ema)
                        # logger.debug("Stream generated frame from SHM latest")
                except Exception:
                    logger.exception("Error generating frame from SHM in stream()")
                    frame = None
            if frame is None:
                time.sleep(0.05)
                continue
            ok, jpeg = cv2.imencode(".jpg", frame)
            if not ok:
                continue
            yield (b"--frame\r\n"
                   b"Content-Type: image/jpeg\r\n\r\n" + jpeg.tobytes() + b"\r\n")
    return Response(gen(), mimetype="multipart/x-mixed-replace; boundary=frame")


@app.route("/health")
def health():
    _start_background_threads()
    return {"status": "ok"}


@app.route("/json_metrics")
def json_metrics():
    _start_background_threads()
    with latest_lock:
        meta = dict(latest_meta) if latest_meta else {}
    return {
        "fps": fps_ema,
        "last_frame_id": meta.get("frame_id"),
        "stream_id": meta.get("stream_id"),
        "camera_id": meta.get("camera_id"),
        "last_contract_age_ms": int((time.perf_counter() - last_contract_ts) * 1000) if last_contract_ts else None,
        "last_shm_age_ms": int((time.perf_counter() - last_shm_ts) * 1000) if last_shm_ts else None,
        "shm_name": active_shm_name,
        "shm_error": last_shm_error,
        "threads_started": _threads_started,
    }


def main():
    logger.info(
        "Config summary: %s",
        redact_config(
            {
                "ZMQ_SUB_ENDPOINT": ZMQ_SUB_ENDPOINT,
                "ZMQ_RESULTS_SUB_ENDPOINT": ZMQ_RESULTS_SUB_ENDPOINT,
                "SHM_NAME": SHM_NAME,
                "SHM_META_NAME": SHM_META_NAME,
                "SHM_BUFFER_BYTES": SHM_BUFFER_BYTES,
                "SHM_CACHE_SECONDS": SHM_CACHE_SECONDS,
                "SHM_CACHE_FPS": SHM_CACHE_FPS,
                "FRAME_WIDTH": FRAME_WIDTH,
                "FRAME_HEIGHT": FRAME_HEIGHT,
                "FRAME_COLOR_SPACE": FRAME_COLOR_SPACE,
            }
        ),
    )
    _start_background_threads()
    # Register Prometheus /metrics endpoint on Flask app
    try:
        ivis_metrics.register_flask_metrics(app)
    except Exception:
        logger.exception("Failed to register Prometheus metrics route")
    app.run(host="0.0.0.0", port=8080, debug=False, threaded=True)


if __name__ == "__main__":
    main()

========================================================================================================================
FILE: ui\results_cache.py
========================================================================================================================
# FILE: ui/results_cache.py
# ------------------------------------------------------------------------------
import time
from collections import OrderedDict
from typing import Any, Callable, Optional


class ResultsCache:
    def __init__(
        self,
        max_entries: int = 2000,
        ttl_seconds: float = 60.0,
        time_fn: Optional[Callable[[], float]] = None,
    ) -> None:
        self._max_entries = max(1, int(max_entries))
        self._ttl_seconds = float(ttl_seconds)
        self._time_fn = time_fn or time.monotonic
        self._data = OrderedDict()

    def __len__(self) -> int:
        return len(self._data)

    def _is_expired(self, now: float, timestamp: float) -> bool:
        if self._ttl_seconds <= 0:
            return False
        return (now - timestamp) > self._ttl_seconds

    def _purge_expired(self, now: float) -> None:
        if self._ttl_seconds <= 0 or not self._data:
            return
        expired_keys = [key for key, (ts, _) in self._data.items() if self._is_expired(now, ts)]
        for key in expired_keys:
            self._data.pop(key, None)

    def get(self, key: str) -> Optional[Any]:
        now = self._time_fn()
        entry = self._data.get(key)
        if entry is None:
            return None
        ts, value = entry
        if self._is_expired(now, ts):
            self._data.pop(key, None)
            return None
        self._data.pop(key, None)
        self._data[key] = (now, value)
        return value

    def put(self, key: str, value: Any) -> None:
        now = self._time_fn()
        if key in self._data:
            self._data.pop(key, None)
        self._data[key] = (now, value)
        self._purge_expired(now)
        while len(self._data) > self._max_entries:
            self._data.popitem(last=False)

